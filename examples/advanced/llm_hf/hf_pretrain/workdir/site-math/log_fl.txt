2025-05-20 23:14:30,997 - ModelDequantizer - INFO - Using model dequantizator.
2025-05-20 23:14:30,998 - ModelQuantizer - INFO - Using model quantizator.
2025-05-20 23:14:31,510 - TaskScriptRunner - INFO - start task run() with full path: /workspace/NVFlare/examples/advanced/llm_hf/hf_pretrain/workdir/site-math/simulate_job/app_site-math/custom/src/pretrain_nvflare.py
2025-05-20 23:14:31,628 - TaskScriptRunner - INFO -     smart_open supports the following transport mechanisms:
2025-05-20 23:14:31,628 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,628 - TaskScriptRunner - INFO -     file (smart_open/local_file.py)
2025-05-20 23:14:31,628 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-20 23:14:31,629 - TaskScriptRunner - INFO -     Implements the transport for the file:// schema.
2025-05-20 23:14:31,629 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,629 - TaskScriptRunner - INFO -     ftp (smart_open/ftp.py)
2025-05-20 23:14:31,629 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~~
2025-05-20 23:14:31,629 - TaskScriptRunner - INFO -     Implements I/O streams over FTP.
2025-05-20 23:14:31,629 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,630 - TaskScriptRunner - INFO -     gs (smart_open/gcs.py)
2025-05-20 23:14:31,630 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~
2025-05-20 23:14:31,630 - TaskScriptRunner - INFO -     Implements file-like objects for reading and writing to/from GCS.
2025-05-20 23:14:31,630 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,630 - TaskScriptRunner - INFO -     min_part_size: int, optional
        The minimum part size for multipart uploads. For writing only.
    client: google.cloud.storage.Client, optional
        The GCS client to use when working with google-cloud-storage.
    blob_properties: dict, optional
        Set properties on blob before writing. For writing only.
    blob_open_kwargs: dict, optional
        Additional keyword arguments to propagate to the blob.open method
        of the google-cloud-storage library.

2025-05-20 23:14:31,631 - TaskScriptRunner - INFO -     hdfs (smart_open/hdfs.py)
2025-05-20 23:14:31,631 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-20 23:14:31,631 - TaskScriptRunner - INFO -     Implements reading and writing to/from HDFS.
2025-05-20 23:14:31,631 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,631 - TaskScriptRunner - INFO -     http (smart_open/http.py)
2025-05-20 23:14:31,631 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-20 23:14:31,632 - TaskScriptRunner - INFO -     Implements file-like objects for reading from http.
2025-05-20 23:14:31,632 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,632 - TaskScriptRunner - INFO -     kerberos: boolean, optional
        If True, will attempt to use the local Kerberos credentials
    user: str, optional
        The username for authenticating over HTTP
    password: str, optional
        The password for authenticating over HTTP
    cert: str/tuple, optional
        if String, path to ssl client cert file (.pem). If Tuple, (‘cert’, ‘key’)
    headers: dict, optional
        Any headers to send in the request. If ``None``, the default headers are sent:
        ``{'Accept-Encoding': 'identity'}``. To use no headers at all,
        set this variable to an empty dict, ``{}``.
    buffer_size: int, optional
        The buffer size to use when performing I/O.

2025-05-20 23:14:31,632 - TaskScriptRunner - INFO -     s3 (smart_open/s3.py)
2025-05-20 23:14:31,632 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~
2025-05-20 23:14:31,632 - TaskScriptRunner - INFO -     Implements file-like objects for reading and writing from/to AWS S3.
2025-05-20 23:14:31,633 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,633 - TaskScriptRunner - INFO -     buffer_size: int, optional
        The buffer size to use when performing I/O.
    min_part_size: int, optional
        The minimum part size for multipart uploads.  For writing only.
    multipart_upload: bool, optional
        Default: `True`
        If set to `True`, will use multipart upload for writing to S3. If set
        to `False`, S3 upload will use the S3 Single-Part Upload API, which
        is more ideal for small file sizes.
        For writing only.
    version_id: str, optional
        Version of the object, used when reading object.
        If None, will fetch the most recent version.
    defer_seek: boolean, optional
        Default: `False`
        If set to `True` on a file opened for reading, GetObject will not be
        called until the first seek() or read().
        Avoids redundant API queries when seeking before reading.
    client: object, optional
        The S3 client to use when working with boto3.
        If you don't specify this, then smart_open will create a new client for you.
    client_kwargs: dict, optional
        Additional parameters to pass to the relevant functions of the client.
        The keys are fully qualified method names, e.g. `S3.Client.create_multipart_upload`.
        The values are kwargs to pass to that method each time it is called.
    writebuffer: IO[bytes], optional
        By default, this module will buffer data in memory using io.BytesIO
        when writing. Pass another binary IO instance here to use it instead.
        For example, you may pass a file object to buffer to local disk instead
        of in RAM. Use this to keep RAM usage low at the expense of additional
        disk IO. If you pass in an open file, then you are responsible for
        cleaning it up after writing completes.

2025-05-20 23:14:31,633 - TaskScriptRunner - INFO -     scp (smart_open/ssh.py)
2025-05-20 23:14:31,633 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~~
2025-05-20 23:14:31,633 - TaskScriptRunner - INFO -     Implements I/O streams over SSH.
2025-05-20 23:14:31,634 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,634 - TaskScriptRunner - INFO -     mode: str, optional
        The mode to use for opening the file.
    host: str, optional
        The hostname of the remote machine.  May not be None.
    user: str, optional
        The username to use to login to the remote machine.
        If None, defaults to the name of the current user.
    password: str, optional
        The password to use to login to the remote machine.
    port: int, optional
        The port to connect to.
    transport_params: dict, optional
        Any additional settings to be passed to paramiko.SSHClient.connect

2025-05-20 23:14:31,634 - TaskScriptRunner - INFO -     webhdfs (smart_open/webhdfs.py)
2025-05-20 23:14:31,634 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-20 23:14:31,634 - TaskScriptRunner - INFO -     Implements reading and writing to/from WebHDFS.
2025-05-20 23:14:31,634 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,635 - TaskScriptRunner - INFO -     min_part_size: int, optional
        For writing only.

2025-05-20 23:14:31,635 - TaskScriptRunner - INFO -     Examples
2025-05-20 23:14:31,635 - TaskScriptRunner - INFO -     --------
2025-05-20 23:14:31,635 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,635 - TaskScriptRunner - INFO -     See README.rst
2025-05-20 23:14:31,635 - TaskScriptRunner - INFO -     This function also supports transparent compression and decompression 
2025-05-20 23:14:31,636 - TaskScriptRunner - INFO -     using the following codecs:
2025-05-20 23:14:31,636 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,636 - TaskScriptRunner - INFO -     * .bz2
2025-05-20 23:14:31,636 - TaskScriptRunner - INFO -     * .gz
2025-05-20 23:14:31,636 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,636 - TaskScriptRunner - INFO -     The function depends on the file extension to determine the appropriate codec.
2025-05-20 23:14:31,637 - TaskScriptRunner - INFO -     Supported URI schemes are:
2025-05-20 23:14:31,637 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,637 - TaskScriptRunner - INFO -     * file
2025-05-20 23:14:31,637 - TaskScriptRunner - INFO -     * ftp
2025-05-20 23:14:31,637 - TaskScriptRunner - INFO -     * gs
2025-05-20 23:14:31,637 - TaskScriptRunner - INFO -     * hdfs
2025-05-20 23:14:31,638 - TaskScriptRunner - INFO -     * http
2025-05-20 23:14:31,638 - TaskScriptRunner - INFO -     * s3
2025-05-20 23:14:31,638 - TaskScriptRunner - INFO -     * scp
2025-05-20 23:14:31,638 - TaskScriptRunner - INFO -     * webhdfs
2025-05-20 23:14:31,638 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,638 - TaskScriptRunner - INFO -     Valid URI examples::
2025-05-20 23:14:31,639 - TaskScriptRunner - INFO - 
2025-05-20 23:14:31,639 - TaskScriptRunner - INFO -     * ./local/path/file
2025-05-20 23:14:31,639 - TaskScriptRunner - INFO -     * ~/local/path/file
2025-05-20 23:14:31,639 - TaskScriptRunner - INFO -     * local/path/file
2025-05-20 23:14:31,639 - TaskScriptRunner - INFO -     * ./local/path/file.gz
2025-05-20 23:14:31,639 - TaskScriptRunner - INFO -     * file:///home/user/file
2025-05-20 23:14:31,640 - TaskScriptRunner - INFO -     * file:///home/user/file.bz2
2025-05-20 23:14:31,640 - TaskScriptRunner - INFO -     * ftp://username@host/path/file
2025-05-20 23:14:31,640 - TaskScriptRunner - INFO -     * ftp://username:password@host/path/file
2025-05-20 23:14:31,640 - TaskScriptRunner - INFO -     * ftp://username:password@host:port/path/file
2025-05-20 23:14:31,640 - TaskScriptRunner - INFO -     * ftps://username@host/path/file
2025-05-20 23:14:31,640 - TaskScriptRunner - INFO -     * ftps://username:password@host/path/file
2025-05-20 23:14:31,641 - TaskScriptRunner - INFO -     * ftps://username:password@host:port/path/file
2025-05-20 23:14:31,641 - TaskScriptRunner - INFO -     * hdfs:///path/file
2025-05-20 23:14:31,641 - TaskScriptRunner - INFO -     * hdfs://path/file
2025-05-20 23:14:31,641 - TaskScriptRunner - INFO -     * viewfs:///path/file
2025-05-20 23:14:31,641 - TaskScriptRunner - INFO -     * viewfs://path/file
2025-05-20 23:14:31,641 - TaskScriptRunner - INFO -     * s3://my_bucket/my_key
2025-05-20 23:14:31,642 - TaskScriptRunner - INFO -     * s3://my_key:my_secret@my_bucket/my_key
2025-05-20 23:14:31,642 - TaskScriptRunner - INFO -     * s3://my_key:my_secret@my_server:my_port@my_bucket/my_key
2025-05-20 23:14:31,642 - TaskScriptRunner - INFO -     * ssh://username@host/path/file
2025-05-20 23:14:31,642 - TaskScriptRunner - INFO -     * ssh://username@host//path/file
2025-05-20 23:14:31,642 - TaskScriptRunner - INFO -     * scp://username@host/path/file
2025-05-20 23:14:31,642 - TaskScriptRunner - INFO -     * sftp://username@host/path/file
2025-05-20 23:14:31,643 - TaskScriptRunner - INFO -     * webhdfs://host:port/path/file
2025-05-20 23:14:34,437 - TaskScriptRunner - INFO - Attempting to load training data from: /workspace/NVFlare/examples/advanced/llm_hf/data/math/train.npy
2025-05-20 23:14:34,437 - TaskScriptRunner - INFO - Loading data from /workspace/NVFlare/examples/advanced/llm_hf/data/math/train.npy...
2025-05-20 23:14:34,438 - TaskScriptRunner - INFO - data_array shape: (100644201,)
2025-05-20 23:14:34,438 - TaskScriptRunner - INFO - data_array dtype: uint32
2025-05-20 23:14:34,438 - TaskScriptRunner - INFO - data_array size: 100644201
2025-05-20 23:14:36,268 - TaskScriptRunner - INFO - 100644201 len text_list
2025-05-20 23:14:37,159 - TaskScriptRunner - INFO - 10000 len text_list
2025-05-20 23:14:37,168 - TaskScriptRunner - INFO - Validation data path is same as train or not specified separately. Splitting training data (from /workspace/NVFlare/examples/advanced/llm_hf/data/math/train.npy) for validation (1% test size).
2025-05-20 23:14:37,172 - TaskScriptRunner - INFO - Dataset size: training 9900, validation 100
2025-05-20 23:14:37,173 - TaskScriptRunner - INFO - Raw dataset structure after loading: DatasetDict({
    train: Dataset({
        features: ['text'],
        num_rows: 9900
    })
    validation: Dataset({
        features: ['text'],
        num_rows: 100
    })
})
2025-05-20 23:14:37,173 - TaskScriptRunner - INFO - 102           0 LOAD_GLOBAL              0 (isinstance)
2025-05-20 23:14:37,173 - TaskScriptRunner - INFO -               2 LOAD_FAST                0 (examples)
2025-05-20 23:14:37,174 - TaskScriptRunner - INFO -               4 LOAD_CONST               1 ('text')
2025-05-20 23:14:37,174 - TaskScriptRunner - INFO -               6 BINARY_SUBSCR
2025-05-20 23:14:37,174 - TaskScriptRunner - INFO -               8 LOAD_CONST               2 (0)
2025-05-20 23:14:37,174 - TaskScriptRunner - INFO -              10 BINARY_SUBSCR
2025-05-20 23:14:37,174 - TaskScriptRunner - INFO -              12 LOAD_GLOBAL              1 (int)
2025-05-20 23:14:37,175 - TaskScriptRunner - INFO -              14 CALL_FUNCTION            2
2025-05-20 23:14:37,175 - TaskScriptRunner - INFO -              16 POP_JUMP_IF_FALSE       14 (to 28)
2025-05-20 23:14:37,175 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,175 - TaskScriptRunner - INFO - 104          18 LOAD_FAST                0 (examples)
2025-05-20 23:14:37,175 - TaskScriptRunner - INFO -              20 LOAD_CONST               1 ('text')
2025-05-20 23:14:37,175 - TaskScriptRunner - INFO -              22 BINARY_SUBSCR
2025-05-20 23:14:37,176 - TaskScriptRunner - INFO -              24 STORE_DEREF              0 (all_tokens)
2025-05-20 23:14:37,176 - TaskScriptRunner - INFO -              26 JUMP_FORWARD             9 (to 46)
2025-05-20 23:14:37,176 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,176 - TaskScriptRunner - INFO - 107     >>   28 LOAD_GLOBAL              2 (list)
2025-05-20 23:14:37,176 - TaskScriptRunner - INFO -              30 LOAD_GLOBAL              3 (chain)
2025-05-20 23:14:37,176 - TaskScriptRunner - INFO -              32 LOAD_METHOD              4 (from_iterable)
2025-05-20 23:14:37,177 - TaskScriptRunner - INFO -              34 LOAD_FAST                0 (examples)
2025-05-20 23:14:37,177 - TaskScriptRunner - INFO -              36 LOAD_CONST               1 ('text')
2025-05-20 23:14:37,177 - TaskScriptRunner - INFO -              38 BINARY_SUBSCR
2025-05-20 23:14:37,177 - TaskScriptRunner - INFO -              40 CALL_METHOD              1
2025-05-20 23:14:37,177 - TaskScriptRunner - INFO -              42 CALL_FUNCTION            1
2025-05-20 23:14:37,177 - TaskScriptRunner - INFO -              44 STORE_DEREF              0 (all_tokens)
2025-05-20 23:14:37,178 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,178 - TaskScriptRunner - INFO - 110     >>   46 LOAD_GLOBAL              5 (len)
2025-05-20 23:14:37,178 - TaskScriptRunner - INFO -              48 LOAD_DEREF               0 (all_tokens)
2025-05-20 23:14:37,178 - TaskScriptRunner - INFO -              50 CALL_FUNCTION            1
2025-05-20 23:14:37,178 - TaskScriptRunner - INFO -              52 LOAD_DEREF               1 (block_size)
2025-05-20 23:14:37,178 - TaskScriptRunner - INFO -              54 BINARY_FLOOR_DIVIDE
2025-05-20 23:14:37,179 - TaskScriptRunner - INFO -              56 LOAD_DEREF               1 (block_size)
2025-05-20 23:14:37,179 - TaskScriptRunner - INFO -              58 BINARY_MULTIPLY
2025-05-20 23:14:37,179 - TaskScriptRunner - INFO -              60 STORE_FAST               2 (total_len)
2025-05-20 23:14:37,179 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,179 - TaskScriptRunner - INFO - 114          62 LOAD_CONST               3 ('input_ids')
2025-05-20 23:14:37,179 - TaskScriptRunner - INFO -              64 LOAD_CLOSURE             0 (all_tokens)
2025-05-20 23:14:37,180 - TaskScriptRunner - INFO -              66 LOAD_CLOSURE             1 (block_size)
2025-05-20 23:14:37,180 - TaskScriptRunner - INFO -              68 BUILD_TUPLE              2
2025-05-20 23:14:37,180 - TaskScriptRunner - INFO -              70 LOAD_CONST               4 (<code object <listcomp> at 0x7fee2a513ec0, file "/workspace/NVFlare/examples/advanced/llm_hf/hf_pretrain/workdir/site-math/simulate_job/app_site-math/custom/src/pretrain_nvflare.py", line 114>)
2025-05-20 23:14:37,180 - TaskScriptRunner - INFO -              72 LOAD_CONST               5 ('group_tokens.<locals>.<listcomp>')
2025-05-20 23:14:37,180 - TaskScriptRunner - INFO -              74 MAKE_FUNCTION            8 (closure)
2025-05-20 23:14:37,181 - TaskScriptRunner - INFO -              76 LOAD_GLOBAL              6 (range)
2025-05-20 23:14:37,181 - TaskScriptRunner - INFO -              78 LOAD_CONST               2 (0)
2025-05-20 23:14:37,181 - TaskScriptRunner - INFO -              80 LOAD_FAST                2 (total_len)
2025-05-20 23:14:37,181 - TaskScriptRunner - INFO -              82 LOAD_DEREF               1 (block_size)
2025-05-20 23:14:37,181 - TaskScriptRunner - INFO -              84 CALL_FUNCTION            3
2025-05-20 23:14:37,181 - TaskScriptRunner - INFO -              86 GET_ITER
2025-05-20 23:14:37,182 - TaskScriptRunner - INFO -              88 CALL_FUNCTION            1
2025-05-20 23:14:37,182 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,182 - TaskScriptRunner - INFO - 113          90 BUILD_MAP                1
2025-05-20 23:14:37,182 - TaskScriptRunner - INFO -              92 STORE_FAST               3 (result)
2025-05-20 23:14:37,182 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,182 - TaskScriptRunner - INFO - 118          94 LOAD_FAST                3 (result)
2025-05-20 23:14:37,183 - TaskScriptRunner - INFO -              96 LOAD_CONST               3 ('input_ids')
2025-05-20 23:14:37,183 - TaskScriptRunner - INFO -              98 BINARY_SUBSCR
2025-05-20 23:14:37,183 - TaskScriptRunner - INFO -             100 LOAD_METHOD              7 (copy)
2025-05-20 23:14:37,183 - TaskScriptRunner - INFO -             102 CALL_METHOD              0
2025-05-20 23:14:37,183 - TaskScriptRunner - INFO -             104 LOAD_FAST                3 (result)
2025-05-20 23:14:37,183 - TaskScriptRunner - INFO -             106 LOAD_CONST               6 ('labels')
2025-05-20 23:14:37,184 - TaskScriptRunner - INFO -             108 STORE_SUBSCR
2025-05-20 23:14:37,184 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,184 - TaskScriptRunner - INFO - 120         110 LOAD_FAST                3 (result)
2025-05-20 23:14:37,184 - TaskScriptRunner - INFO -             112 RETURN_VALUE
2025-05-20 23:14:37,184 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,184 - TaskScriptRunner - INFO - Disassembly of <code object <listcomp> at 0x7fee2a513ec0, file "/workspace/NVFlare/examples/advanced/llm_hf/hf_pretrain/workdir/site-math/simulate_job/app_site-math/custom/src/pretrain_nvflare.py", line 114>:
2025-05-20 23:14:37,185 - TaskScriptRunner - INFO - 114           0 BUILD_LIST               0
2025-05-20 23:14:37,185 - TaskScriptRunner - INFO -               2 LOAD_FAST                0 (.0)
2025-05-20 23:14:37,185 - TaskScriptRunner - INFO -         >>    4 FOR_ITER                10 (to 26)
2025-05-20 23:14:37,185 - TaskScriptRunner - INFO -               6 STORE_FAST               1 (i)
2025-05-20 23:14:37,185 - TaskScriptRunner - INFO -               8 LOAD_DEREF               0 (all_tokens)
2025-05-20 23:14:37,185 - TaskScriptRunner - INFO -              10 LOAD_FAST                1 (i)
2025-05-20 23:14:37,186 - TaskScriptRunner - INFO -              12 LOAD_FAST                1 (i)
2025-05-20 23:14:37,186 - TaskScriptRunner - INFO -              14 LOAD_DEREF               1 (block_size)
2025-05-20 23:14:37,186 - TaskScriptRunner - INFO -              16 BINARY_ADD
2025-05-20 23:14:37,186 - TaskScriptRunner - INFO -              18 BUILD_SLICE              2
2025-05-20 23:14:37,186 - TaskScriptRunner - INFO -              20 BINARY_SUBSCR
2025-05-20 23:14:37,186 - TaskScriptRunner - INFO -              22 LIST_APPEND              2
2025-05-20 23:14:37,187 - TaskScriptRunner - INFO -              24 JUMP_ABSOLUTE            2 (to 4)
2025-05-20 23:14:37,187 - TaskScriptRunner - INFO -         >>   26 RETURN_VALUE
2025-05-20 23:14:37,187 - TaskScriptRunner - INFO - 114           0 BUILD_LIST               0
2025-05-20 23:14:37,187 - TaskScriptRunner - INFO -               2 LOAD_FAST                0 (.0)
2025-05-20 23:14:37,188 - TaskScriptRunner - INFO -         >>    4 FOR_ITER                10 (to 26)
2025-05-20 23:14:37,188 - TaskScriptRunner - INFO -               6 STORE_FAST               1 (i)
2025-05-20 23:14:37,188 - TaskScriptRunner - INFO -               8 LOAD_DEREF               0 (all_tokens)
2025-05-20 23:14:37,188 - TaskScriptRunner - INFO -              10 LOAD_FAST                1 (i)
2025-05-20 23:14:37,188 - TaskScriptRunner - INFO -              12 LOAD_FAST                1 (i)
2025-05-20 23:14:37,188 - TaskScriptRunner - INFO -              14 LOAD_DEREF               1 (block_size)
2025-05-20 23:14:37,189 - TaskScriptRunner - INFO -              16 BINARY_ADD
2025-05-20 23:14:37,189 - TaskScriptRunner - INFO -              18 BUILD_SLICE              2
2025-05-20 23:14:37,189 - TaskScriptRunner - INFO -              20 BINARY_SUBSCR
2025-05-20 23:14:37,189 - TaskScriptRunner - INFO -              22 LIST_APPEND              2
2025-05-20 23:14:37,189 - TaskScriptRunner - INFO -              24 JUMP_ABSOLUTE            2 (to 4)
2025-05-20 23:14:37,190 - TaskScriptRunner - INFO -         >>   26 RETURN_VALUE
2025-05-20 23:14:37,232 - TaskScriptRunner - INFO - 102           0 LOAD_GLOBAL              0 (isinstance)
2025-05-20 23:14:37,233 - TaskScriptRunner - INFO -               2 LOAD_FAST                0 (examples)
2025-05-20 23:14:37,233 - TaskScriptRunner - INFO -               4 LOAD_CONST               1 ('text')
2025-05-20 23:14:37,233 - TaskScriptRunner - INFO -               6 BINARY_SUBSCR
2025-05-20 23:14:37,233 - TaskScriptRunner - INFO -               8 LOAD_CONST               2 (0)
2025-05-20 23:14:37,233 - TaskScriptRunner - INFO -              10 BINARY_SUBSCR
2025-05-20 23:14:37,234 - TaskScriptRunner - INFO -              12 LOAD_GLOBAL              1 (int)
2025-05-20 23:14:37,234 - TaskScriptRunner - INFO -              14 CALL_FUNCTION            2
2025-05-20 23:14:37,234 - TaskScriptRunner - INFO -              16 POP_JUMP_IF_FALSE       14 (to 28)
2025-05-20 23:14:37,234 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,234 - TaskScriptRunner - INFO - 104          18 LOAD_FAST                0 (examples)
2025-05-20 23:14:37,234 - TaskScriptRunner - INFO -              20 LOAD_CONST               1 ('text')
2025-05-20 23:14:37,235 - TaskScriptRunner - INFO -              22 BINARY_SUBSCR
2025-05-20 23:14:37,235 - TaskScriptRunner - INFO -              24 STORE_DEREF              0 (all_tokens)
2025-05-20 23:14:37,235 - TaskScriptRunner - INFO -              26 JUMP_FORWARD             9 (to 46)
2025-05-20 23:14:37,235 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,235 - TaskScriptRunner - INFO - 107     >>   28 LOAD_GLOBAL              2 (list)
2025-05-20 23:14:37,235 - TaskScriptRunner - INFO -              30 LOAD_GLOBAL              3 (chain)
2025-05-20 23:14:37,236 - TaskScriptRunner - INFO -              32 LOAD_METHOD              4 (from_iterable)
2025-05-20 23:14:37,236 - TaskScriptRunner - INFO -              34 LOAD_FAST                0 (examples)
2025-05-20 23:14:37,236 - TaskScriptRunner - INFO -              36 LOAD_CONST               1 ('text')
2025-05-20 23:14:37,236 - TaskScriptRunner - INFO -              38 BINARY_SUBSCR
2025-05-20 23:14:37,236 - TaskScriptRunner - INFO -              40 CALL_METHOD              1
2025-05-20 23:14:37,236 - TaskScriptRunner - INFO -              42 CALL_FUNCTION            1
2025-05-20 23:14:37,237 - TaskScriptRunner - INFO -              44 STORE_DEREF              0 (all_tokens)
2025-05-20 23:14:37,237 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,237 - TaskScriptRunner - INFO - 110     >>   46 LOAD_GLOBAL              5 (len)
2025-05-20 23:14:37,237 - TaskScriptRunner - INFO -              48 LOAD_DEREF               0 (all_tokens)
2025-05-20 23:14:37,237 - TaskScriptRunner - INFO -              50 CALL_FUNCTION            1
2025-05-20 23:14:37,237 - TaskScriptRunner - INFO -              52 LOAD_DEREF               1 (block_size)
2025-05-20 23:14:37,238 - TaskScriptRunner - INFO -              54 BINARY_FLOOR_DIVIDE
2025-05-20 23:14:37,238 - TaskScriptRunner - INFO -              56 LOAD_DEREF               1 (block_size)
2025-05-20 23:14:37,238 - TaskScriptRunner - INFO -              58 BINARY_MULTIPLY
2025-05-20 23:14:37,238 - TaskScriptRunner - INFO -              60 STORE_FAST               2 (total_len)
2025-05-20 23:14:37,238 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,238 - TaskScriptRunner - INFO - 114          62 LOAD_CONST               3 ('input_ids')
2025-05-20 23:14:37,239 - TaskScriptRunner - INFO -              64 LOAD_CLOSURE             0 (all_tokens)
2025-05-20 23:14:37,239 - TaskScriptRunner - INFO -              66 LOAD_CLOSURE             1 (block_size)
2025-05-20 23:14:37,239 - TaskScriptRunner - INFO -              68 BUILD_TUPLE              2
2025-05-20 23:14:37,239 - TaskScriptRunner - INFO -              70 LOAD_CONST               4 (<code object <listcomp> at 0x7fee2a513ec0, file "/workspace/NVFlare/examples/advanced/llm_hf/hf_pretrain/workdir/site-math/simulate_job/app_site-math/custom/src/pretrain_nvflare.py", line 114>)
2025-05-20 23:14:37,239 - TaskScriptRunner - INFO -              72 LOAD_CONST               5 ('group_tokens.<locals>.<listcomp>')
2025-05-20 23:14:37,239 - TaskScriptRunner - INFO -              74 MAKE_FUNCTION            8 (closure)
2025-05-20 23:14:37,240 - TaskScriptRunner - INFO -              76 LOAD_GLOBAL              6 (range)
2025-05-20 23:14:37,240 - TaskScriptRunner - INFO -              78 LOAD_CONST               2 (0)
2025-05-20 23:14:37,240 - TaskScriptRunner - INFO -              80 LOAD_FAST                2 (total_len)
2025-05-20 23:14:37,240 - TaskScriptRunner - INFO -              82 LOAD_DEREF               1 (block_size)
2025-05-20 23:14:37,240 - TaskScriptRunner - INFO -              84 CALL_FUNCTION            3
2025-05-20 23:14:37,240 - TaskScriptRunner - INFO -              86 GET_ITER
2025-05-20 23:14:37,241 - TaskScriptRunner - INFO -              88 CALL_FUNCTION            1
2025-05-20 23:14:37,241 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,241 - TaskScriptRunner - INFO - 113          90 BUILD_MAP                1
2025-05-20 23:14:37,241 - TaskScriptRunner - INFO -              92 STORE_FAST               3 (result)
2025-05-20 23:14:37,241 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,241 - TaskScriptRunner - INFO - 118          94 LOAD_FAST                3 (result)
2025-05-20 23:14:37,242 - TaskScriptRunner - INFO -              96 LOAD_CONST               3 ('input_ids')
2025-05-20 23:14:37,242 - TaskScriptRunner - INFO -              98 BINARY_SUBSCR
2025-05-20 23:14:37,242 - TaskScriptRunner - INFO -             100 LOAD_METHOD              7 (copy)
2025-05-20 23:14:37,242 - TaskScriptRunner - INFO -             102 CALL_METHOD              0
2025-05-20 23:14:37,242 - TaskScriptRunner - INFO -             104 LOAD_FAST                3 (result)
2025-05-20 23:14:37,242 - TaskScriptRunner - INFO -             106 LOAD_CONST               6 ('labels')
2025-05-20 23:14:37,243 - TaskScriptRunner - INFO -             108 STORE_SUBSCR
2025-05-20 23:14:37,243 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,243 - TaskScriptRunner - INFO - 120         110 LOAD_FAST                3 (result)
2025-05-20 23:14:37,243 - TaskScriptRunner - INFO -             112 RETURN_VALUE
2025-05-20 23:14:37,243 - TaskScriptRunner - INFO - 
2025-05-20 23:14:37,243 - TaskScriptRunner - INFO - Disassembly of <code object <listcomp> at 0x7fee2a513ec0, file "/workspace/NVFlare/examples/advanced/llm_hf/hf_pretrain/workdir/site-math/simulate_job/app_site-math/custom/src/pretrain_nvflare.py", line 114>:
2025-05-20 23:14:37,244 - TaskScriptRunner - INFO - 114           0 BUILD_LIST               0
2025-05-20 23:14:37,244 - TaskScriptRunner - INFO -               2 LOAD_FAST                0 (.0)
2025-05-20 23:14:37,244 - TaskScriptRunner - INFO -         >>    4 FOR_ITER                10 (to 26)
2025-05-20 23:14:37,244 - TaskScriptRunner - INFO -               6 STORE_FAST               1 (i)
2025-05-20 23:14:37,244 - TaskScriptRunner - INFO -               8 LOAD_DEREF               0 (all_tokens)
2025-05-20 23:14:37,244 - TaskScriptRunner - INFO -              10 LOAD_FAST                1 (i)
2025-05-20 23:14:37,245 - TaskScriptRunner - INFO -              12 LOAD_FAST                1 (i)
2025-05-20 23:14:37,245 - TaskScriptRunner - INFO -              14 LOAD_DEREF               1 (block_size)
2025-05-20 23:14:37,245 - TaskScriptRunner - INFO -              16 BINARY_ADD
2025-05-20 23:14:37,245 - TaskScriptRunner - INFO -              18 BUILD_SLICE              2
2025-05-20 23:14:37,245 - TaskScriptRunner - INFO -              20 BINARY_SUBSCR
2025-05-20 23:14:37,245 - TaskScriptRunner - INFO -              22 LIST_APPEND              2
2025-05-20 23:14:37,246 - TaskScriptRunner - INFO -              24 JUMP_ABSOLUTE            2 (to 4)
2025-05-20 23:14:37,246 - TaskScriptRunner - INFO -         >>   26 RETURN_VALUE
2025-05-20 23:14:37,246 - TaskScriptRunner - INFO - 114           0 BUILD_LIST               0
2025-05-20 23:14:37,246 - TaskScriptRunner - INFO -               2 LOAD_FAST                0 (.0)
2025-05-20 23:14:37,246 - TaskScriptRunner - INFO -         >>    4 FOR_ITER                10 (to 26)
2025-05-20 23:14:37,246 - TaskScriptRunner - INFO -               6 STORE_FAST               1 (i)
2025-05-20 23:14:37,247 - TaskScriptRunner - INFO -               8 LOAD_DEREF               0 (all_tokens)
2025-05-20 23:14:37,247 - TaskScriptRunner - INFO -              10 LOAD_FAST                1 (i)
2025-05-20 23:14:37,247 - TaskScriptRunner - INFO -              12 LOAD_FAST                1 (i)
2025-05-20 23:14:37,247 - TaskScriptRunner - INFO -              14 LOAD_DEREF               1 (block_size)
2025-05-20 23:14:37,247 - TaskScriptRunner - INFO -              16 BINARY_ADD
2025-05-20 23:14:37,247 - TaskScriptRunner - INFO -              18 BUILD_SLICE              2
2025-05-20 23:14:37,248 - TaskScriptRunner - INFO -              20 BINARY_SUBSCR
2025-05-20 23:14:37,248 - TaskScriptRunner - INFO -              22 LIST_APPEND              2
2025-05-20 23:14:37,248 - TaskScriptRunner - INFO -              24 JUMP_ABSOLUTE            2 (to 4)
2025-05-20 23:14:37,248 - TaskScriptRunner - INFO -         >>   26 RETURN_VALUE
2025-05-20 23:14:44,131 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Running dequantization...
2025-05-20 23:14:44,133 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Running dequantization on 179 variables
2025-05-20 23:14:44,134 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.embed_tokens.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,136 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.0.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,136 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.0.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,137 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.0.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,138 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.0.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,139 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.0.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,139 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.0.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,155 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.0.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,155 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.0.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,155 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.0.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,156 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.0.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,156 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.1.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,156 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.1.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,156 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.1.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,158 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.1.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,158 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.1.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,170 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.2.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,170 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.2.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,171 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.2.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,177 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.2.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,177 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.2.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,177 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.3.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,178 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.3.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,178 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.3.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,179 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.3.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,179 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.3.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,183 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.3.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,187 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.3.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,189 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.3.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,192 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.4.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,192 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.4.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,192 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.4.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,204 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.5.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,205 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.5.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,205 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.5.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,211 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.5.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,212 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.5.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,212 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.6.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,212 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.6.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,212 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.6.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,213 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.6.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,213 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.6.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,213 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.6.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,220 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.6.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,220 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.6.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,220 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.6.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,221 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.7.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,221 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.7.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,221 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.7.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,221 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.7.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,222 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.7.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,222 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.7.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,228 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.7.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,229 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.7.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,229 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.7.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,229 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.8.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,230 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.8.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,230 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.8.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,230 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.8.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,230 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.8.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,231 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.8.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,237 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.8.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,237 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.8.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,238 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.8.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,238 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.9.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,238 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.9.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,240 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.9.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,240 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.9.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,240 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.9.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,240 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.9.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,244 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.9.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,244 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.9.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,244 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.9.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,245 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.10.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,245 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.10.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,245 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.10.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,246 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.10.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,247 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.10.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,247 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.10.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,298 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.14.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,299 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.14.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,299 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.15.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,299 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.15.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,300 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.15.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,300 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.15.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,300 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.15.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,300 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.15.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,307 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.15.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,307 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.15.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,307 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.layers.15.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,308 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Skipping dequantization for model.model.norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:14:44,342 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Dequantized 88/179 params. Before dequantization: 1792.08 MB with meta: 0.00 MB. After dequantization: 3584.16 MB.
2025-05-20 23:14:44,343 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Dequantized back to {'model.model.embed_tokens.weight': 'float16', 'model.model.layers.0.self_attn.q_proj.weight': 'float16', 'model.model.layers.0.self_attn.k_proj.weight': 'float16', 'model.model.layers.0.self_attn.v_proj.weight': 'float16', 'model.model.layers.0.self_attn.o_proj.weight': 'float16', 'model.model.layers.0.self_attn.q_norm.weight': 'float16', 'model.model.layers.0.self_attn.k_norm.weight': 'float16', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float16', 'model.model.layers.0.mlp.down_proj.weight': 'float16', 'model.model.layers.0.post_attention_layernorm.weight': 'float16', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.1.self_attn.q_proj.weight': 'float16', 'model.model.layers.1.self_attn.k_proj.weight': 'float16', 'model.model.layers.1.self_attn.v_proj.weight': 'float16', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float16', 'model.model.layers.1.self_attn.k_norm.weight': 'float16', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float16', 'model.model.layers.2.self_attn.k_norm.weight': 'float16', 'model.model.layers.2.mlp.gate_proj.weight': 'float16', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float16', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.3.self_attn.q_proj.weight': 'float16', 'model.model.layers.3.self_attn.k_proj.weight': 'float16', 'model.model.layers.3.self_attn.v_proj.weight': 'float16', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float16', 'model.model.layers.3.self_attn.k_norm.weight': 'float16', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float16', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float16', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float16', 'model.model.layers.4.self_attn.q_norm.weight': 'float16', 'model.model.layers.4.self_attn.k_norm.weight': 'float16', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float16', 'model.model.layers.5.self_attn.k_norm.weight': 'float16', 'model.model.layers.5.mlp.gate_proj.weight': 'float16', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float16', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.6.self_attn.q_proj.weight': 'float16', 'model.model.layers.6.self_attn.k_proj.weight': 'float16', 'model.model.layers.6.self_attn.v_proj.weight': 'float16', 'model.model.layers.6.self_attn.o_proj.weight': 'float16', 'model.model.layers.6.self_attn.q_norm.weight': 'float16', 'model.model.layers.6.self_attn.k_norm.weight': 'float16', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float16', 'model.model.layers.6.post_attention_layernorm.weight': 'float16', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.7.self_attn.q_proj.weight': 'float16', 'model.model.layers.7.self_attn.k_proj.weight': 'float16', 'model.model.layers.7.self_attn.v_proj.weight': 'float16', 'model.model.layers.7.self_attn.o_proj.weight': 'float16', 'model.model.layers.7.self_attn.q_norm.weight': 'float16', 'model.model.layers.7.self_attn.k_norm.weight': 'float16', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float16', 'model.model.layers.7.post_attention_layernorm.weight': 'float16', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.8.self_attn.q_proj.weight': 'float16', 'model.model.layers.8.self_attn.k_proj.weight': 'float16', 'model.model.layers.8.self_attn.v_proj.weight': 'float16', 'model.model.layers.8.self_attn.o_proj.weight': 'float16', 'model.model.layers.8.self_attn.q_norm.weight': 'float16', 'model.model.layers.8.self_attn.k_norm.weight': 'float16', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float16', 'model.model.layers.8.post_attention_layernorm.weight': 'float16', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.9.self_attn.q_proj.weight': 'float16', 'model.model.layers.9.self_attn.k_proj.weight': 'float16', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float16', 'model.model.layers.9.self_attn.q_norm.weight': 'float16', 'model.model.layers.9.self_attn.k_norm.weight': 'float16', 'model.model.layers.9.mlp.gate_proj.weight': 'float16', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float16', 'model.model.layers.9.post_attention_layernorm.weight': 'float16', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.10.self_attn.q_proj.weight': 'float16', 'model.model.layers.10.self_attn.k_proj.weight': 'float16', 'model.model.layers.10.self_attn.v_proj.weight': 'float16', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float16', 'model.model.layers.10.self_attn.k_norm.weight': 'float16', 'model.model.layers.10.mlp.gate_proj.weight': 'float16', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float32', 'model.model.layers.11.self_attn.k_norm.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float32', 'model.model.layers.12.self_attn.k_norm.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float32', 'model.model.layers.13.self_attn.k_norm.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float32', 'model.model.layers.14.self_attn.k_norm.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float16', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.15.self_attn.q_proj.weight': 'float16', 'model.model.layers.15.self_attn.k_proj.weight': 'float16', 'model.model.layers.15.self_attn.v_proj.weight': 'float16', 'model.model.layers.15.self_attn.o_proj.weight': 'float16', 'model.model.layers.15.self_attn.q_norm.weight': 'float16', 'model.model.layers.15.self_attn.k_norm.weight': 'float16', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float16', 'model.model.layers.15.post_attention_layernorm.weight': 'float16', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float16', 'model.model.norm.weight': 'float16', 'model.lm_head.weight': 'float32'}
2025-05-20 23:14:44,344 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - execute for task (train)
2025-05-20 23:14:44,345 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - send data to peer
2025-05-20 23:14:44,345 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - sending payload to peer
2025-05-20 23:14:44,346 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Waiting for result from peer
2025-05-20 23:14:44,592 - TaskScriptRunner - INFO - --- federated round 0 ---
2025-05-20 23:14:47,051 - TaskScriptRunner - INFO - {'loss': 7.8433, 'grad_norm': 8.5625, 'learning_rate': 0.0, 'epoch': 1.0}
2025-05-20 23:15:04,233 - TaskScriptRunner - INFO - {'train_runtime': 18.8596, 'train_samples_per_second': 0.53, 'train_steps_per_second': 0.053, 'train_loss': 7.843297481536865, 'epoch': 1.0}
2025-05-20 23:15:06,359 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Running quantization...
2025-05-20 23:15:06,360 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Running quantization on 179 variables
2025-05-20 23:15:13,449 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Quantized 179/179 params. Before quantization: 5664.51 MB. After quantization: 2832.25 MB with meta: 0.00 MB.
2025-05-20 23:15:13,451 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=87011389-6fdd-46e8-9147-e9b7de05c906] - Quantized from {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float32', 'model.model.layers.0.self_attn.k_norm.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float32', 'model.model.layers.1.self_attn.k_norm.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float32', 'model.model.layers.2.self_attn.k_norm.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float32', 'model.model.layers.3.self_attn.k_norm.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float32', 'model.model.layers.4.self_attn.k_norm.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float32', 'model.model.layers.5.self_attn.k_norm.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float32', 'model.model.layers.6.self_attn.k_norm.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float32', 'model.model.layers.7.self_attn.k_norm.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float32', 'model.model.layers.8.self_attn.k_norm.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float32', 'model.model.layers.9.self_attn.k_norm.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float32', 'model.model.layers.10.self_attn.k_norm.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float32', 'model.model.layers.11.self_attn.k_norm.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float32', 'model.model.layers.12.self_attn.k_norm.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float32', 'model.model.layers.13.self_attn.k_norm.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float32', 'model.model.layers.14.self_attn.k_norm.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float32', 'model.model.layers.15.self_attn.k_norm.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'} to float16
2025-05-20 23:18:19,733 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Running dequantization...
2025-05-20 23:18:19,734 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Running dequantization on 179 variables
2025-05-20 23:18:19,734 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.embed_tokens.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,735 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.0.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,735 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.0.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,735 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.0.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,736 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.0.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,736 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.0.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,737 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.0.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,737 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.0.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,738 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.0.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,738 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.0.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,738 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.0.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,739 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.0.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,739 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.1.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,740 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.1.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,740 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.1.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,741 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.1.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,741 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.1.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,741 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.1.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,742 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.1.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,742 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.1.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,743 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.1.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,743 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.1.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,743 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.1.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,744 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.2.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,744 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.2.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,745 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.2.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,745 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.2.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,746 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.2.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,746 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.2.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,746 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.2.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,747 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.2.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,747 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.2.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,748 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.2.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,748 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.2.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,748 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.3.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,749 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.3.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,749 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.3.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,750 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.3.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,750 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.3.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,750 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.3.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,751 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.3.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,841 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.3.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,842 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.3.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,843 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.4.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,843 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.4.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,867 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.4.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:19,867 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.4.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:20,001 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.4.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:20,002 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.4.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:20,043 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.5.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:20,043 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.5.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:20,178 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.5.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:20,179 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.5.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:20,353 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.6.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:20,354 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.6.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:21,750 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.14.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:21,751 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Skipping dequantization for model.model.layers.14.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:18:22,468 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Dequantized 122/179 params. Before dequantization: 1976.14 MB with meta: 0.00 MB. After dequantization: 3952.29 MB.
2025-05-20 23:18:22,470 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Dequantized back to {'model.model.embed_tokens.weight': 'float16', 'model.model.layers.0.self_attn.q_proj.weight': 'float16', 'model.model.layers.0.self_attn.k_proj.weight': 'float16', 'model.model.layers.0.self_attn.v_proj.weight': 'float16', 'model.model.layers.0.self_attn.o_proj.weight': 'float16', 'model.model.layers.0.self_attn.q_norm.weight': 'float16', 'model.model.layers.0.self_attn.k_norm.weight': 'float16', 'model.model.layers.0.mlp.gate_proj.weight': 'float16', 'model.model.layers.0.mlp.up_proj.weight': 'float16', 'model.model.layers.0.mlp.down_proj.weight': 'float16', 'model.model.layers.0.post_attention_layernorm.weight': 'float16', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.1.self_attn.q_proj.weight': 'float16', 'model.model.layers.1.self_attn.k_proj.weight': 'float16', 'model.model.layers.1.self_attn.v_proj.weight': 'float16', 'model.model.layers.1.self_attn.o_proj.weight': 'float16', 'model.model.layers.1.self_attn.q_norm.weight': 'float16', 'model.model.layers.1.self_attn.k_norm.weight': 'float16', 'model.model.layers.1.mlp.gate_proj.weight': 'float16', 'model.model.layers.1.mlp.up_proj.weight': 'float16', 'model.model.layers.1.mlp.down_proj.weight': 'float16', 'model.model.layers.1.post_attention_layernorm.weight': 'float16', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.2.self_attn.q_proj.weight': 'float16', 'model.model.layers.2.self_attn.k_proj.weight': 'float16', 'model.model.layers.2.self_attn.v_proj.weight': 'float16', 'model.model.layers.2.self_attn.o_proj.weight': 'float16', 'model.model.layers.2.self_attn.q_norm.weight': 'float16', 'model.model.layers.2.self_attn.k_norm.weight': 'float16', 'model.model.layers.2.mlp.gate_proj.weight': 'float16', 'model.model.layers.2.mlp.up_proj.weight': 'float16', 'model.model.layers.2.mlp.down_proj.weight': 'float16', 'model.model.layers.2.post_attention_layernorm.weight': 'float16', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.3.self_attn.q_proj.weight': 'float16', 'model.model.layers.3.self_attn.k_proj.weight': 'float16', 'model.model.layers.3.self_attn.v_proj.weight': 'float16', 'model.model.layers.3.self_attn.o_proj.weight': 'float16', 'model.model.layers.3.self_attn.q_norm.weight': 'float16', 'model.model.layers.3.self_attn.k_norm.weight': 'float16', 'model.model.layers.3.mlp.gate_proj.weight': 'float16', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float16', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.4.self_attn.q_proj.weight': 'float16', 'model.model.layers.4.self_attn.k_proj.weight': 'float16', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float16', 'model.model.layers.4.self_attn.k_norm.weight': 'float16', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float16', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float16', 'model.model.layers.5.self_attn.k_norm.weight': 'float16', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float16', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float32', 'model.model.layers.6.self_attn.k_norm.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float16', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float32', 'model.model.layers.7.self_attn.k_norm.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float32', 'model.model.layers.8.self_attn.k_norm.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float32', 'model.model.layers.9.self_attn.k_norm.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float32', 'model.model.layers.10.self_attn.k_norm.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float32', 'model.model.layers.11.self_attn.k_norm.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float32', 'model.model.layers.12.self_attn.k_norm.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float32', 'model.model.layers.13.self_attn.k_norm.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float32', 'model.model.layers.14.self_attn.k_norm.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float16', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float32', 'model.model.layers.15.self_attn.k_norm.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'}
2025-05-20 23:18:22,471 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - execute for task (train)
2025-05-20 23:18:22,472 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - send data to peer
2025-05-20 23:18:22,473 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - sending payload to peer
2025-05-20 23:18:22,474 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Waiting for result from peer
2025-05-20 23:18:22,596 - TaskScriptRunner - INFO - --- federated round 1 ---
2025-05-20 23:18:42,469 - TaskScriptRunner - INFO - RNG state successfully loaded
2025-05-20 23:18:42,984 - TaskScriptRunner - INFO - {'loss': 7.8433, 'grad_norm': 8.5625, 'learning_rate': 0.0005, 'epoch': 2.0}
2025-05-20 23:19:01,603 - TaskScriptRunner - INFO - {'train_runtime': 19.1338, 'train_samples_per_second': 1.045, 'train_steps_per_second': 0.105, 'train_loss': 3.9216485023498535, 'epoch': 2.0}
2025-05-20 23:19:03,852 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Running quantization...
2025-05-20 23:19:03,853 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Running quantization on 179 variables
2025-05-20 23:19:10,653 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Quantized 179/179 params. Before quantization: 5664.51 MB. After quantization: 2832.25 MB with meta: 0.00 MB.
2025-05-20 23:19:10,653 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7907a425-af0d-4870-bb70-be75eb0166bf] - Quantized from {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float32', 'model.model.layers.0.self_attn.k_norm.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float32', 'model.model.layers.1.self_attn.k_norm.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float32', 'model.model.layers.2.self_attn.k_norm.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float32', 'model.model.layers.3.self_attn.k_norm.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float32', 'model.model.layers.4.self_attn.k_norm.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float32', 'model.model.layers.5.self_attn.k_norm.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float32', 'model.model.layers.6.self_attn.k_norm.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float32', 'model.model.layers.7.self_attn.k_norm.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float32', 'model.model.layers.8.self_attn.k_norm.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float32', 'model.model.layers.9.self_attn.k_norm.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float32', 'model.model.layers.10.self_attn.k_norm.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float32', 'model.model.layers.11.self_attn.k_norm.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float32', 'model.model.layers.12.self_attn.k_norm.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float32', 'model.model.layers.13.self_attn.k_norm.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float32', 'model.model.layers.14.self_attn.k_norm.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float32', 'model.model.layers.15.self_attn.k_norm.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'} to float16
2025-05-20 23:22:36,666 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Running dequantization...
2025-05-20 23:22:36,666 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Running dequantization on 179 variables
2025-05-20 23:22:37,268 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.0.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,268 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.0.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,374 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.0.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,375 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.0.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,375 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.1.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,418 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.1.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,418 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.1.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,556 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.1.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,556 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.1.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,557 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.2.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,598 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.2.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,599 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.2.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,736 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.2.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,737 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.2.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,737 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.3.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,779 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.3.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,779 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.3.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,917 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.3.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,918 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.3.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,918 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.4.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,950 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.4.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:37,950 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.4.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,085 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.4.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,086 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.4.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,086 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.5.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,087 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.5.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,104 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.5.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,105 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.5.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,239 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.5.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,239 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.5.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,240 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.6.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,272 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.6.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,272 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.6.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,406 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.6.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,407 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.6.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,407 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.7.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,419 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.7.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,431 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.7.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,431 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.7.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,565 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.7.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,566 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.7.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,566 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.8.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,598 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.8.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,599 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.8.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,732 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.8.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,733 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.8.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,733 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.9.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,754 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.9.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,754 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.9.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,755 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.9.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,889 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.9.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,890 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.9.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,890 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.10.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,919 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.10.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:38,920 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.10.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,053 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.10.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,054 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.10.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,054 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.11.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,078 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.11.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,078 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.11.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,078 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.11.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,212 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.11.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,213 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.11.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,213 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.12.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,242 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.12.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,243 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.12.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,377 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.12.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,378 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.12.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,378 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.13.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,410 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.13.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,411 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.13.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,545 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.13.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,545 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.13.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,546 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.14.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,558 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.14.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,569 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.14.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,570 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.14.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,703 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.14.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,704 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.14.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,704 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.15.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,736 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.15.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,737 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.15.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,871 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.15.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,871 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.layers.15.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:39,872 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Skipping dequantization for model.model.norm.weight, quantization bit float16 >= source data bit float16
2025-05-20 23:22:40,415 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Dequantized 94/179 params. Before dequantization: 2672.00 MB with meta: 0.00 MB. After dequantization: 5344.00 MB.
2025-05-20 23:22:40,416 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float16', 'model.model.layers.0.self_attn.k_norm.weight': 'float16', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float16', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.1.self_attn.q_proj.weight': 'float16', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float16', 'model.model.layers.1.self_attn.k_norm.weight': 'float16', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float16', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.2.self_attn.q_proj.weight': 'float16', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float16', 'model.model.layers.2.self_attn.k_norm.weight': 'float16', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float16', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.3.self_attn.q_proj.weight': 'float16', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float16', 'model.model.layers.3.self_attn.k_norm.weight': 'float16', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float16', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.4.self_attn.q_proj.weight': 'float16', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float16', 'model.model.layers.4.self_attn.k_norm.weight': 'float16', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float16', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.5.self_attn.q_proj.weight': 'float16', 'model.model.layers.5.self_attn.k_proj.weight': 'float16', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float16', 'model.model.layers.5.self_attn.k_norm.weight': 'float16', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float16', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.6.self_attn.q_proj.weight': 'float16', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float16', 'model.model.layers.6.self_attn.k_norm.weight': 'float16', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float16', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.7.self_attn.q_proj.weight': 'float16', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float16', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float16', 'model.model.layers.7.self_attn.k_norm.weight': 'float16', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float16', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.8.self_attn.q_proj.weight': 'float16', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float16', 'model.model.layers.8.self_attn.k_norm.weight': 'float16', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float16', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.9.self_attn.q_proj.weight': 'float16', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float16', 'model.model.layers.9.self_attn.q_norm.weight': 'float16', 'model.model.layers.9.self_attn.k_norm.weight': 'float16', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float16', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.10.self_attn.q_proj.weight': 'float16', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float16', 'model.model.layers.10.self_attn.k_norm.weight': 'float16', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float16', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.11.self_attn.q_proj.weight': 'float16', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float16', 'model.model.layers.11.self_attn.q_norm.weight': 'float16', 'model.model.layers.11.self_attn.k_norm.weight': 'float16', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float16', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.12.self_attn.q_proj.weight': 'float16', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float16', 'model.model.layers.12.self_attn.k_norm.weight': 'float16', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float16', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.13.self_attn.q_proj.weight': 'float16', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float16', 'model.model.layers.13.self_attn.k_norm.weight': 'float16', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float16', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.14.self_attn.q_proj.weight': 'float16', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float16', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float16', 'model.model.layers.14.self_attn.k_norm.weight': 'float16', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float16', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.15.self_attn.q_proj.weight': 'float16', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float16', 'model.model.layers.15.self_attn.k_norm.weight': 'float16', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float16', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float16', 'model.model.norm.weight': 'float16', 'model.lm_head.weight': 'float32'}
2025-05-20 23:22:40,417 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - execute for task (train)
2025-05-20 23:22:40,419 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - send data to peer
2025-05-20 23:22:40,419 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - sending payload to peer
2025-05-20 23:22:40,420 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Waiting for result from peer
2025-05-20 23:22:40,746 - TaskScriptRunner - INFO - --- federated round 2 ---
2025-05-20 23:22:59,628 - TaskScriptRunner - INFO - RNG state successfully loaded
2025-05-20 23:23:00,182 - TaskScriptRunner - INFO - {'loss': 8.0056, 'grad_norm': 19.75, 'learning_rate': 0.0, 'epoch': 3.0}
2025-05-20 23:23:18,822 - TaskScriptRunner - INFO - {'train_runtime': 19.1945, 'train_samples_per_second': 1.563, 'train_steps_per_second': 0.156, 'train_loss': 2.6685256958007812, 'epoch': 3.0}
2025-05-20 23:23:20,395 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Running quantization...
2025-05-20 23:23:20,396 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Running quantization on 179 variables
2025-05-20 23:23:26,766 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Quantized 179/179 params. Before quantization: 5664.51 MB. After quantization: 2832.25 MB with meta: 0.00 MB.
2025-05-20 23:23:26,766 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=47756b1d-5e8a-469b-85d6-ca1d87283a35] - Quantized from {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float32', 'model.model.layers.0.self_attn.k_norm.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float32', 'model.model.layers.1.self_attn.k_norm.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float32', 'model.model.layers.2.self_attn.k_norm.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float32', 'model.model.layers.3.self_attn.k_norm.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float32', 'model.model.layers.4.self_attn.k_norm.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float32', 'model.model.layers.5.self_attn.k_norm.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float32', 'model.model.layers.6.self_attn.k_norm.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float32', 'model.model.layers.7.self_attn.k_norm.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float32', 'model.model.layers.8.self_attn.k_norm.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float32', 'model.model.layers.9.self_attn.k_norm.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float32', 'model.model.layers.10.self_attn.k_norm.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float32', 'model.model.layers.11.self_attn.k_norm.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float32', 'model.model.layers.12.self_attn.k_norm.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float32', 'model.model.layers.13.self_attn.k_norm.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float32', 'model.model.layers.14.self_attn.k_norm.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float32', 'model.model.layers.15.self_attn.k_norm.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'} to float16
2025-05-20 23:26:47,132 - InProcessClientAPI - WARNING - ask to stop job: reason: END_RUN received
2025-05-20 23:26:47,244 - InProcessClientAPI - WARNING - request to stop the job for reason END_RUN received
