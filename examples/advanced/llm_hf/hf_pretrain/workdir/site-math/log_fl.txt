2025-05-15 18:28:33,833 - ModelDequantizer - INFO - Using model dequantizator.
2025-05-15 18:28:33,835 - ModelQuantizer - INFO - Using model quantizator.
2025-05-15 18:28:34,361 - TaskScriptRunner - INFO - start task run() with full path: /workspace/NVFlare/examples/advanced/llm_hf/hf_pretrain/workdir/site-math/simulate_job/app_site-math/custom/src/pretrain_nvflare.py
2025-05-15 18:28:34,608 - TaskScriptRunner - INFO -     smart_open supports the following transport mechanisms:
2025-05-15 18:28:34,609 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,609 - TaskScriptRunner - INFO -     file (smart_open/local_file.py)
2025-05-15 18:28:34,610 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-15 18:28:34,610 - TaskScriptRunner - INFO -     Implements the transport for the file:// schema.
2025-05-15 18:28:34,610 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,611 - TaskScriptRunner - INFO -     ftp (smart_open/ftp.py)
2025-05-15 18:28:34,611 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~~
2025-05-15 18:28:34,612 - TaskScriptRunner - INFO -     Implements I/O streams over FTP.
2025-05-15 18:28:34,612 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,613 - TaskScriptRunner - INFO -     gs (smart_open/gcs.py)
2025-05-15 18:28:34,613 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~
2025-05-15 18:28:34,614 - TaskScriptRunner - INFO -     Implements file-like objects for reading and writing to/from GCS.
2025-05-15 18:28:34,614 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,615 - TaskScriptRunner - INFO -     min_part_size: int, optional
        The minimum part size for multipart uploads. For writing only.
    client: google.cloud.storage.Client, optional
        The GCS client to use when working with google-cloud-storage.
    blob_properties: dict, optional
        Set properties on blob before writing. For writing only.
    blob_open_kwargs: dict, optional
        Additional keyword arguments to propagate to the blob.open method
        of the google-cloud-storage library.

2025-05-15 18:28:34,615 - TaskScriptRunner - INFO -     hdfs (smart_open/hdfs.py)
2025-05-15 18:28:34,616 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-15 18:28:34,616 - TaskScriptRunner - INFO -     Implements reading and writing to/from HDFS.
2025-05-15 18:28:34,616 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,617 - TaskScriptRunner - INFO -     http (smart_open/http.py)
2025-05-15 18:28:34,617 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-15 18:28:34,618 - TaskScriptRunner - INFO -     Implements file-like objects for reading from http.
2025-05-15 18:28:34,618 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,618 - TaskScriptRunner - INFO -     kerberos: boolean, optional
        If True, will attempt to use the local Kerberos credentials
    user: str, optional
        The username for authenticating over HTTP
    password: str, optional
        The password for authenticating over HTTP
    cert: str/tuple, optional
        if String, path to ssl client cert file (.pem). If Tuple, (‘cert’, ‘key’)
    headers: dict, optional
        Any headers to send in the request. If ``None``, the default headers are sent:
        ``{'Accept-Encoding': 'identity'}``. To use no headers at all,
        set this variable to an empty dict, ``{}``.
    buffer_size: int, optional
        The buffer size to use when performing I/O.

2025-05-15 18:28:34,619 - TaskScriptRunner - INFO -     s3 (smart_open/s3.py)
2025-05-15 18:28:34,619 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~
2025-05-15 18:28:34,620 - TaskScriptRunner - INFO -     Implements file-like objects for reading and writing from/to AWS S3.
2025-05-15 18:28:34,620 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,620 - TaskScriptRunner - INFO -     buffer_size: int, optional
        The buffer size to use when performing I/O.
    min_part_size: int, optional
        The minimum part size for multipart uploads.  For writing only.
    multipart_upload: bool, optional
        Default: `True`
        If set to `True`, will use multipart upload for writing to S3. If set
        to `False`, S3 upload will use the S3 Single-Part Upload API, which
        is more ideal for small file sizes.
        For writing only.
    version_id: str, optional
        Version of the object, used when reading object.
        If None, will fetch the most recent version.
    defer_seek: boolean, optional
        Default: `False`
        If set to `True` on a file opened for reading, GetObject will not be
        called until the first seek() or read().
        Avoids redundant API queries when seeking before reading.
    client: object, optional
        The S3 client to use when working with boto3.
        If you don't specify this, then smart_open will create a new client for you.
    client_kwargs: dict, optional
        Additional parameters to pass to the relevant functions of the client.
        The keys are fully qualified method names, e.g. `S3.Client.create_multipart_upload`.
        The values are kwargs to pass to that method each time it is called.
    writebuffer: IO[bytes], optional
        By default, this module will buffer data in memory using io.BytesIO
        when writing. Pass another binary IO instance here to use it instead.
        For example, you may pass a file object to buffer to local disk instead
        of in RAM. Use this to keep RAM usage low at the expense of additional
        disk IO. If you pass in an open file, then you are responsible for
        cleaning it up after writing completes.

2025-05-15 18:28:34,621 - TaskScriptRunner - INFO -     scp (smart_open/ssh.py)
2025-05-15 18:28:34,621 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~~
2025-05-15 18:28:34,622 - TaskScriptRunner - INFO -     Implements I/O streams over SSH.
2025-05-15 18:28:34,622 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,623 - TaskScriptRunner - INFO -     mode: str, optional
        The mode to use for opening the file.
    host: str, optional
        The hostname of the remote machine.  May not be None.
    user: str, optional
        The username to use to login to the remote machine.
        If None, defaults to the name of the current user.
    password: str, optional
        The password to use to login to the remote machine.
    port: int, optional
        The port to connect to.
    transport_params: dict, optional
        Any additional settings to be passed to paramiko.SSHClient.connect

2025-05-15 18:28:34,623 - TaskScriptRunner - INFO -     webhdfs (smart_open/webhdfs.py)
2025-05-15 18:28:34,624 - TaskScriptRunner - INFO -     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-15 18:28:34,624 - TaskScriptRunner - INFO -     Implements reading and writing to/from WebHDFS.
2025-05-15 18:28:34,624 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,625 - TaskScriptRunner - INFO -     min_part_size: int, optional
        For writing only.

2025-05-15 18:28:34,625 - TaskScriptRunner - INFO -     Examples
2025-05-15 18:28:34,626 - TaskScriptRunner - INFO -     --------
2025-05-15 18:28:34,626 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,627 - TaskScriptRunner - INFO -     See README.rst
2025-05-15 18:28:34,627 - TaskScriptRunner - INFO -     This function also supports transparent compression and decompression 
2025-05-15 18:28:34,627 - TaskScriptRunner - INFO -     using the following codecs:
2025-05-15 18:28:34,628 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,628 - TaskScriptRunner - INFO -     * .bz2
2025-05-15 18:28:34,628 - TaskScriptRunner - INFO -     * .gz
2025-05-15 18:28:34,629 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,629 - TaskScriptRunner - INFO -     The function depends on the file extension to determine the appropriate codec.
2025-05-15 18:28:34,630 - TaskScriptRunner - INFO -     Supported URI schemes are:
2025-05-15 18:28:34,630 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,631 - TaskScriptRunner - INFO -     * file
2025-05-15 18:28:34,631 - TaskScriptRunner - INFO -     * ftp
2025-05-15 18:28:34,632 - TaskScriptRunner - INFO -     * gs
2025-05-15 18:28:34,632 - TaskScriptRunner - INFO -     * hdfs
2025-05-15 18:28:34,633 - TaskScriptRunner - INFO -     * http
2025-05-15 18:28:34,633 - TaskScriptRunner - INFO -     * s3
2025-05-15 18:28:34,634 - TaskScriptRunner - INFO -     * scp
2025-05-15 18:28:34,634 - TaskScriptRunner - INFO -     * webhdfs
2025-05-15 18:28:34,635 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,635 - TaskScriptRunner - INFO -     Valid URI examples::
2025-05-15 18:28:34,635 - TaskScriptRunner - INFO - 
2025-05-15 18:28:34,636 - TaskScriptRunner - INFO -     * ./local/path/file
2025-05-15 18:28:34,636 - TaskScriptRunner - INFO -     * ~/local/path/file
2025-05-15 18:28:34,637 - TaskScriptRunner - INFO -     * local/path/file
2025-05-15 18:28:34,637 - TaskScriptRunner - INFO -     * ./local/path/file.gz
2025-05-15 18:28:34,637 - TaskScriptRunner - INFO -     * file:///home/user/file
2025-05-15 18:28:34,638 - TaskScriptRunner - INFO -     * file:///home/user/file.bz2
2025-05-15 18:28:34,638 - TaskScriptRunner - INFO -     * ftp://username@host/path/file
2025-05-15 18:28:34,639 - TaskScriptRunner - INFO -     * ftp://username:password@host/path/file
2025-05-15 18:28:34,639 - TaskScriptRunner - INFO -     * ftp://username:password@host:port/path/file
2025-05-15 18:28:34,639 - TaskScriptRunner - INFO -     * ftps://username@host/path/file
2025-05-15 18:28:34,640 - TaskScriptRunner - INFO -     * ftps://username:password@host/path/file
2025-05-15 18:28:34,640 - TaskScriptRunner - INFO -     * ftps://username:password@host:port/path/file
2025-05-15 18:28:34,640 - TaskScriptRunner - INFO -     * hdfs:///path/file
2025-05-15 18:28:34,641 - TaskScriptRunner - INFO -     * hdfs://path/file
2025-05-15 18:28:34,641 - TaskScriptRunner - INFO -     * viewfs:///path/file
2025-05-15 18:28:34,642 - TaskScriptRunner - INFO -     * viewfs://path/file
2025-05-15 18:28:34,642 - TaskScriptRunner - INFO -     * s3://my_bucket/my_key
2025-05-15 18:28:34,642 - TaskScriptRunner - INFO -     * s3://my_key:my_secret@my_bucket/my_key
2025-05-15 18:28:34,643 - TaskScriptRunner - INFO -     * s3://my_key:my_secret@my_server:my_port@my_bucket/my_key
2025-05-15 18:28:34,643 - TaskScriptRunner - INFO -     * ssh://username@host/path/file
2025-05-15 18:28:34,643 - TaskScriptRunner - INFO -     * ssh://username@host//path/file
2025-05-15 18:28:34,644 - TaskScriptRunner - INFO -     * scp://username@host/path/file
2025-05-15 18:28:34,644 - TaskScriptRunner - INFO -     * sftp://username@host/path/file
2025-05-15 18:28:34,645 - TaskScriptRunner - INFO -     * webhdfs://host:port/path/file
2025-05-15 18:28:38,905 - TaskScriptRunner - INFO - Attempting to load training data from: /workspace/NVFlare/examples/advanced/llm_hf/data/math/train.npy
2025-05-15 18:28:38,906 - TaskScriptRunner - INFO - Loading data from /workspace/NVFlare/examples/advanced/llm_hf/data/math/train.npy...
2025-05-15 18:28:38,906 - TaskScriptRunner - INFO - data_array shape: (100644201,)
2025-05-15 18:28:38,907 - TaskScriptRunner - INFO - data_array dtype: uint32
2025-05-15 18:28:38,907 - TaskScriptRunner - INFO - data_array size: 100644201
2025-05-15 18:28:40,636 - TaskScriptRunner - INFO - 100644201 len text_list
2025-05-15 18:28:41,405 - TaskScriptRunner - INFO - 1000000 len text_list
2025-05-15 18:28:42,489 - TaskScriptRunner - INFO - Validation data path is same as train or not specified separately. Splitting training data (from /workspace/NVFlare/examples/advanced/llm_hf/data/math/train.npy) for validation (1% test size).
2025-05-15 18:28:42,680 - TaskScriptRunner - INFO - Dataset size: training 990000, validation 10000
2025-05-15 18:28:42,684 - TaskScriptRunner - INFO - Raw dataset structure after loading: DatasetDict({
    train: Dataset({
        features: ['text'],
        num_rows: 990000
    })
    validation: Dataset({
        features: ['text'],
        num_rows: 10000
    })
})
2025-05-15 18:28:42,690 - TaskScriptRunner - INFO - 102           0 LOAD_GLOBAL              0 (isinstance)
2025-05-15 18:28:42,692 - TaskScriptRunner - INFO -               2 LOAD_FAST                0 (examples)
2025-05-15 18:28:42,693 - TaskScriptRunner - INFO -               4 LOAD_CONST               1 ('text')
2025-05-15 18:28:42,694 - TaskScriptRunner - INFO -               6 BINARY_SUBSCR
2025-05-15 18:28:42,696 - TaskScriptRunner - INFO -               8 LOAD_CONST               2 (0)
2025-05-15 18:28:42,697 - TaskScriptRunner - INFO -              10 BINARY_SUBSCR
2025-05-15 18:28:42,698 - TaskScriptRunner - INFO -              12 LOAD_GLOBAL              1 (int)
2025-05-15 18:28:42,700 - TaskScriptRunner - INFO -              14 CALL_FUNCTION            2
2025-05-15 18:28:42,701 - TaskScriptRunner - INFO -              16 POP_JUMP_IF_FALSE       14 (to 28)
2025-05-15 18:28:42,702 - TaskScriptRunner - INFO - 
2025-05-15 18:28:42,704 - TaskScriptRunner - INFO - 104          18 LOAD_FAST                0 (examples)
2025-05-15 18:28:42,704 - TaskScriptRunner - INFO -              20 LOAD_CONST               1 ('text')
2025-05-15 18:28:42,707 - TaskScriptRunner - INFO -              22 BINARY_SUBSCR
2025-05-15 18:28:42,708 - TaskScriptRunner - INFO -              24 STORE_DEREF              0 (all_tokens)
2025-05-15 18:28:42,710 - TaskScriptRunner - INFO -              26 JUMP_FORWARD             9 (to 46)
2025-05-15 18:28:42,711 - TaskScriptRunner - INFO - 
2025-05-15 18:28:42,711 - TaskScriptRunner - INFO - 107     >>   28 LOAD_GLOBAL              2 (list)
2025-05-15 18:28:42,713 - TaskScriptRunner - INFO -              30 LOAD_GLOBAL              3 (chain)
2025-05-15 18:28:42,714 - TaskScriptRunner - INFO -              32 LOAD_METHOD              4 (from_iterable)
2025-05-15 18:28:42,716 - TaskScriptRunner - INFO -              34 LOAD_FAST                0 (examples)
2025-05-15 18:28:42,717 - TaskScriptRunner - INFO -              36 LOAD_CONST               1 ('text')
2025-05-15 18:28:42,719 - TaskScriptRunner - INFO -              38 BINARY_SUBSCR
2025-05-15 18:28:42,720 - TaskScriptRunner - INFO -              40 CALL_METHOD              1
2025-05-15 18:28:42,721 - TaskScriptRunner - INFO -              42 CALL_FUNCTION            1
2025-05-15 18:28:42,721 - TaskScriptRunner - INFO -              44 STORE_DEREF              0 (all_tokens)
2025-05-15 18:28:42,724 - TaskScriptRunner - INFO - 
2025-05-15 18:28:42,725 - TaskScriptRunner - INFO - 110     >>   46 LOAD_GLOBAL              5 (len)
2025-05-15 18:28:42,727 - TaskScriptRunner - INFO -              48 LOAD_DEREF               0 (all_tokens)
2025-05-15 18:28:42,729 - TaskScriptRunner - INFO -              50 CALL_FUNCTION            1
2025-05-15 18:28:42,731 - TaskScriptRunner - INFO -              52 LOAD_DEREF               1 (block_size)
2025-05-15 18:28:42,732 - TaskScriptRunner - INFO -              54 BINARY_FLOOR_DIVIDE
2025-05-15 18:28:42,733 - TaskScriptRunner - INFO -              56 LOAD_DEREF               1 (block_size)
2025-05-15 18:28:42,734 - TaskScriptRunner - INFO -              58 BINARY_MULTIPLY
2025-05-15 18:28:42,735 - TaskScriptRunner - INFO -              60 STORE_FAST               2 (total_len)
2025-05-15 18:28:42,738 - TaskScriptRunner - INFO - 
2025-05-15 18:28:42,739 - TaskScriptRunner - INFO - 114          62 LOAD_CONST               3 ('input_ids')
2025-05-15 18:28:42,740 - TaskScriptRunner - INFO -              64 LOAD_CLOSURE             0 (all_tokens)
2025-05-15 18:28:42,742 - TaskScriptRunner - INFO -              66 LOAD_CLOSURE             1 (block_size)
2025-05-15 18:28:42,744 - TaskScriptRunner - INFO -              68 BUILD_TUPLE              2
2025-05-15 18:28:42,746 - TaskScriptRunner - INFO -              70 LOAD_CONST               4 (<code object <listcomp> at 0x7fe4fe979b00, file "/workspace/NVFlare/examples/advanced/llm_hf/hf_pretrain/workdir/site-math/simulate_job/app_site-math/custom/src/pretrain_nvflare.py", line 114>)
2025-05-15 18:28:42,748 - TaskScriptRunner - INFO -              72 LOAD_CONST               5 ('group_tokens.<locals>.<listcomp>')
2025-05-15 18:28:42,749 - TaskScriptRunner - INFO -              74 MAKE_FUNCTION            8 (closure)
2025-05-15 18:28:42,751 - TaskScriptRunner - INFO -              76 LOAD_GLOBAL              6 (range)
2025-05-15 18:28:42,752 - TaskScriptRunner - INFO -              78 LOAD_CONST               2 (0)
2025-05-15 18:28:42,753 - TaskScriptRunner - INFO -              80 LOAD_FAST                2 (total_len)
2025-05-15 18:28:42,755 - TaskScriptRunner - INFO -              82 LOAD_DEREF               1 (block_size)
2025-05-15 18:28:42,756 - TaskScriptRunner - INFO -              84 CALL_FUNCTION            3
2025-05-15 18:28:42,757 - TaskScriptRunner - INFO -              86 GET_ITER
2025-05-15 18:28:42,758 - TaskScriptRunner - INFO -              88 CALL_FUNCTION            1
2025-05-15 18:28:42,760 - TaskScriptRunner - INFO - 
2025-05-15 18:28:42,762 - TaskScriptRunner - INFO - 113          90 BUILD_MAP                1
2025-05-15 18:28:42,763 - TaskScriptRunner - INFO -              92 STORE_FAST               3 (result)
2025-05-15 18:28:42,764 - TaskScriptRunner - INFO - 
2025-05-15 18:28:42,765 - TaskScriptRunner - INFO - 118          94 LOAD_FAST                3 (result)
2025-05-15 18:28:42,767 - TaskScriptRunner - INFO -              96 LOAD_CONST               3 ('input_ids')
2025-05-15 18:28:42,769 - TaskScriptRunner - INFO -              98 BINARY_SUBSCR
2025-05-15 18:28:42,770 - TaskScriptRunner - INFO -             100 LOAD_METHOD              7 (copy)
2025-05-15 18:28:42,772 - TaskScriptRunner - INFO -             102 CALL_METHOD              0
2025-05-15 18:28:42,773 - TaskScriptRunner - INFO -             104 LOAD_FAST                3 (result)
2025-05-15 18:28:42,775 - TaskScriptRunner - INFO -             106 LOAD_CONST               6 ('labels')
2025-05-15 18:28:42,776 - TaskScriptRunner - INFO -             108 STORE_SUBSCR
2025-05-15 18:28:42,779 - TaskScriptRunner - INFO - 
2025-05-15 18:28:42,780 - TaskScriptRunner - INFO - 120         110 LOAD_FAST                3 (result)
2025-05-15 18:28:42,781 - TaskScriptRunner - INFO -             112 RETURN_VALUE
2025-05-15 18:28:42,783 - TaskScriptRunner - INFO - 
2025-05-15 18:28:42,785 - TaskScriptRunner - INFO - Disassembly of <code object <listcomp> at 0x7fe4fe979b00, file "/workspace/NVFlare/examples/advanced/llm_hf/hf_pretrain/workdir/site-math/simulate_job/app_site-math/custom/src/pretrain_nvflare.py", line 114>:
2025-05-15 18:28:42,787 - TaskScriptRunner - INFO - 114           0 BUILD_LIST               0
2025-05-15 18:28:42,790 - TaskScriptRunner - INFO -               2 LOAD_FAST                0 (.0)
2025-05-15 18:28:42,792 - TaskScriptRunner - INFO -         >>    4 FOR_ITER                10 (to 26)
2025-05-15 18:28:42,794 - TaskScriptRunner - INFO -               6 STORE_FAST               1 (i)
2025-05-15 18:28:42,795 - TaskScriptRunner - INFO -               8 LOAD_DEREF               0 (all_tokens)
2025-05-15 18:28:42,797 - TaskScriptRunner - INFO -              10 LOAD_FAST                1 (i)
2025-05-15 18:28:42,799 - TaskScriptRunner - INFO -              12 LOAD_FAST                1 (i)
2025-05-15 18:28:42,800 - TaskScriptRunner - INFO -              14 LOAD_DEREF               1 (block_size)
2025-05-15 18:28:42,802 - TaskScriptRunner - INFO -              16 BINARY_ADD
2025-05-15 18:28:42,805 - TaskScriptRunner - INFO -              18 BUILD_SLICE              2
2025-05-15 18:28:42,806 - TaskScriptRunner - INFO -              20 BINARY_SUBSCR
2025-05-15 18:28:42,808 - TaskScriptRunner - INFO -              22 LIST_APPEND              2
2025-05-15 18:28:42,809 - TaskScriptRunner - INFO -              24 JUMP_ABSOLUTE            2 (to 4)
2025-05-15 18:28:42,810 - TaskScriptRunner - INFO -         >>   26 RETURN_VALUE
2025-05-15 18:28:42,811 - TaskScriptRunner - INFO - 114           0 BUILD_LIST               0
2025-05-15 18:28:42,813 - TaskScriptRunner - INFO -               2 LOAD_FAST                0 (.0)
2025-05-15 18:28:42,815 - TaskScriptRunner - INFO -         >>    4 FOR_ITER                10 (to 26)
2025-05-15 18:28:42,816 - TaskScriptRunner - INFO -               6 STORE_FAST               1 (i)
2025-05-15 18:28:42,817 - TaskScriptRunner - INFO -               8 LOAD_DEREF               0 (all_tokens)
2025-05-15 18:28:42,818 - TaskScriptRunner - INFO -              10 LOAD_FAST                1 (i)
2025-05-15 18:28:42,820 - TaskScriptRunner - INFO -              12 LOAD_FAST                1 (i)
2025-05-15 18:28:42,821 - TaskScriptRunner - INFO -              14 LOAD_DEREF               1 (block_size)
2025-05-15 18:28:42,823 - TaskScriptRunner - INFO -              16 BINARY_ADD
2025-05-15 18:28:42,824 - TaskScriptRunner - INFO -              18 BUILD_SLICE              2
2025-05-15 18:28:42,826 - TaskScriptRunner - INFO -              20 BINARY_SUBSCR
2025-05-15 18:28:42,828 - TaskScriptRunner - INFO -              22 LIST_APPEND              2
2025-05-15 18:28:42,828 - TaskScriptRunner - INFO -              24 JUMP_ABSOLUTE            2 (to 4)
2025-05-15 18:28:42,829 - TaskScriptRunner - INFO -         >>   26 RETURN_VALUE
2025-05-15 18:28:52,219 - TaskScriptRunner - INFO - 102           0 LOAD_GLOBAL              0 (isinstance)
2025-05-15 18:28:52,220 - TaskScriptRunner - INFO -               2 LOAD_FAST                0 (examples)
2025-05-15 18:28:52,221 - TaskScriptRunner - INFO -               4 LOAD_CONST               1 ('text')
2025-05-15 18:28:52,222 - TaskScriptRunner - INFO -               6 BINARY_SUBSCR
2025-05-15 18:28:52,222 - TaskScriptRunner - INFO -               8 LOAD_CONST               2 (0)
2025-05-15 18:28:52,223 - TaskScriptRunner - INFO -              10 BINARY_SUBSCR
2025-05-15 18:28:52,224 - TaskScriptRunner - INFO -              12 LOAD_GLOBAL              1 (int)
2025-05-15 18:28:52,224 - TaskScriptRunner - INFO -              14 CALL_FUNCTION            2
2025-05-15 18:28:52,225 - TaskScriptRunner - INFO -              16 POP_JUMP_IF_FALSE       14 (to 28)
2025-05-15 18:28:52,226 - TaskScriptRunner - INFO - 
2025-05-15 18:28:52,226 - TaskScriptRunner - INFO - 104          18 LOAD_FAST                0 (examples)
2025-05-15 18:28:52,227 - TaskScriptRunner - INFO -              20 LOAD_CONST               1 ('text')
2025-05-15 18:28:52,228 - TaskScriptRunner - INFO -              22 BINARY_SUBSCR
2025-05-15 18:28:52,229 - TaskScriptRunner - INFO -              24 STORE_DEREF              0 (all_tokens)
2025-05-15 18:28:52,229 - TaskScriptRunner - INFO -              26 JUMP_FORWARD             9 (to 46)
2025-05-15 18:28:52,230 - TaskScriptRunner - INFO - 
2025-05-15 18:28:52,230 - TaskScriptRunner - INFO - 107     >>   28 LOAD_GLOBAL              2 (list)
2025-05-15 18:28:52,231 - TaskScriptRunner - INFO -              30 LOAD_GLOBAL              3 (chain)
2025-05-15 18:28:52,231 - TaskScriptRunner - INFO -              32 LOAD_METHOD              4 (from_iterable)
2025-05-15 18:28:52,232 - TaskScriptRunner - INFO -              34 LOAD_FAST                0 (examples)
2025-05-15 18:28:52,233 - TaskScriptRunner - INFO -              36 LOAD_CONST               1 ('text')
2025-05-15 18:28:52,233 - TaskScriptRunner - INFO -              38 BINARY_SUBSCR
2025-05-15 18:28:52,234 - TaskScriptRunner - INFO -              40 CALL_METHOD              1
2025-05-15 18:28:52,234 - TaskScriptRunner - INFO -              42 CALL_FUNCTION            1
2025-05-15 18:28:52,235 - TaskScriptRunner - INFO -              44 STORE_DEREF              0 (all_tokens)
2025-05-15 18:28:52,235 - TaskScriptRunner - INFO - 
2025-05-15 18:28:52,236 - TaskScriptRunner - INFO - 110     >>   46 LOAD_GLOBAL              5 (len)
2025-05-15 18:28:52,237 - TaskScriptRunner - INFO -              48 LOAD_DEREF               0 (all_tokens)
2025-05-15 18:28:52,237 - TaskScriptRunner - INFO -              50 CALL_FUNCTION            1
2025-05-15 18:28:52,238 - TaskScriptRunner - INFO -              52 LOAD_DEREF               1 (block_size)
2025-05-15 18:28:52,238 - TaskScriptRunner - INFO -              54 BINARY_FLOOR_DIVIDE
2025-05-15 18:28:52,239 - TaskScriptRunner - INFO -              56 LOAD_DEREF               1 (block_size)
2025-05-15 18:28:52,240 - TaskScriptRunner - INFO -              58 BINARY_MULTIPLY
2025-05-15 18:28:52,240 - TaskScriptRunner - INFO -              60 STORE_FAST               2 (total_len)
2025-05-15 18:28:52,241 - TaskScriptRunner - INFO - 
2025-05-15 18:28:52,241 - TaskScriptRunner - INFO - 114          62 LOAD_CONST               3 ('input_ids')
2025-05-15 18:28:52,242 - TaskScriptRunner - INFO -              64 LOAD_CLOSURE             0 (all_tokens)
2025-05-15 18:28:52,242 - TaskScriptRunner - INFO -              66 LOAD_CLOSURE             1 (block_size)
2025-05-15 18:28:52,243 - TaskScriptRunner - INFO -              68 BUILD_TUPLE              2
2025-05-15 18:28:52,244 - TaskScriptRunner - INFO -              70 LOAD_CONST               4 (<code object <listcomp> at 0x7fe4fe979b00, file "/workspace/NVFlare/examples/advanced/llm_hf/hf_pretrain/workdir/site-math/simulate_job/app_site-math/custom/src/pretrain_nvflare.py", line 114>)
2025-05-15 18:28:52,244 - TaskScriptRunner - INFO -              72 LOAD_CONST               5 ('group_tokens.<locals>.<listcomp>')
2025-05-15 18:28:52,245 - TaskScriptRunner - INFO -              74 MAKE_FUNCTION            8 (closure)
2025-05-15 18:28:52,246 - TaskScriptRunner - INFO -              76 LOAD_GLOBAL              6 (range)
2025-05-15 18:28:52,248 - TaskScriptRunner - INFO -              78 LOAD_CONST               2 (0)
2025-05-15 18:28:52,249 - TaskScriptRunner - INFO -              80 LOAD_FAST                2 (total_len)
2025-05-15 18:28:52,249 - TaskScriptRunner - INFO -              82 LOAD_DEREF               1 (block_size)
2025-05-15 18:28:52,250 - TaskScriptRunner - INFO -              84 CALL_FUNCTION            3
2025-05-15 18:28:52,250 - TaskScriptRunner - INFO -              86 GET_ITER
2025-05-15 18:28:52,251 - TaskScriptRunner - INFO -              88 CALL_FUNCTION            1
2025-05-15 18:28:52,251 - TaskScriptRunner - INFO - 
2025-05-15 18:28:52,252 - TaskScriptRunner - INFO - 113          90 BUILD_MAP                1
2025-05-15 18:28:52,254 - TaskScriptRunner - INFO -              92 STORE_FAST               3 (result)
2025-05-15 18:28:52,254 - TaskScriptRunner - INFO - 
2025-05-15 18:28:52,255 - TaskScriptRunner - INFO - 118          94 LOAD_FAST                3 (result)
2025-05-15 18:28:52,255 - TaskScriptRunner - INFO -              96 LOAD_CONST               3 ('input_ids')
2025-05-15 18:28:52,256 - TaskScriptRunner - INFO -              98 BINARY_SUBSCR
2025-05-15 18:28:52,257 - TaskScriptRunner - INFO -             100 LOAD_METHOD              7 (copy)
2025-05-15 18:28:52,257 - TaskScriptRunner - INFO -             102 CALL_METHOD              0
2025-05-15 18:28:52,258 - TaskScriptRunner - INFO -             104 LOAD_FAST                3 (result)
2025-05-15 18:28:52,259 - TaskScriptRunner - INFO -             106 LOAD_CONST               6 ('labels')
2025-05-15 18:28:52,260 - TaskScriptRunner - INFO -             108 STORE_SUBSCR
2025-05-15 18:28:52,260 - TaskScriptRunner - INFO - 
2025-05-15 18:28:52,261 - TaskScriptRunner - INFO - 120         110 LOAD_FAST                3 (result)
2025-05-15 18:28:52,262 - TaskScriptRunner - INFO -             112 RETURN_VALUE
2025-05-15 18:28:52,262 - TaskScriptRunner - INFO - 
2025-05-15 18:28:52,263 - TaskScriptRunner - INFO - Disassembly of <code object <listcomp> at 0x7fe4fe979b00, file "/workspace/NVFlare/examples/advanced/llm_hf/hf_pretrain/workdir/site-math/simulate_job/app_site-math/custom/src/pretrain_nvflare.py", line 114>:
2025-05-15 18:28:52,263 - TaskScriptRunner - INFO - 114           0 BUILD_LIST               0
2025-05-15 18:28:52,264 - TaskScriptRunner - INFO -               2 LOAD_FAST                0 (.0)
2025-05-15 18:28:52,265 - TaskScriptRunner - INFO -         >>    4 FOR_ITER                10 (to 26)
2025-05-15 18:28:52,266 - TaskScriptRunner - INFO -               6 STORE_FAST               1 (i)
2025-05-15 18:28:52,266 - TaskScriptRunner - INFO -               8 LOAD_DEREF               0 (all_tokens)
2025-05-15 18:28:52,267 - TaskScriptRunner - INFO -              10 LOAD_FAST                1 (i)
2025-05-15 18:28:52,268 - TaskScriptRunner - INFO -              12 LOAD_FAST                1 (i)
2025-05-15 18:28:52,268 - TaskScriptRunner - INFO -              14 LOAD_DEREF               1 (block_size)
2025-05-15 18:28:52,269 - TaskScriptRunner - INFO -              16 BINARY_ADD
2025-05-15 18:28:52,269 - TaskScriptRunner - INFO -              18 BUILD_SLICE              2
2025-05-15 18:28:52,271 - TaskScriptRunner - INFO -              20 BINARY_SUBSCR
2025-05-15 18:28:52,271 - TaskScriptRunner - INFO -              22 LIST_APPEND              2
2025-05-15 18:28:52,272 - TaskScriptRunner - INFO -              24 JUMP_ABSOLUTE            2 (to 4)
2025-05-15 18:28:52,273 - TaskScriptRunner - INFO -         >>   26 RETURN_VALUE
2025-05-15 18:28:52,273 - TaskScriptRunner - INFO - 114           0 BUILD_LIST               0
2025-05-15 18:28:52,274 - TaskScriptRunner - INFO -               2 LOAD_FAST                0 (.0)
2025-05-15 18:28:52,274 - TaskScriptRunner - INFO -         >>    4 FOR_ITER                10 (to 26)
2025-05-15 18:28:52,275 - TaskScriptRunner - INFO -               6 STORE_FAST               1 (i)
2025-05-15 18:28:52,276 - TaskScriptRunner - INFO -               8 LOAD_DEREF               0 (all_tokens)
2025-05-15 18:28:52,276 - TaskScriptRunner - INFO -              10 LOAD_FAST                1 (i)
2025-05-15 18:28:52,277 - TaskScriptRunner - INFO -              12 LOAD_FAST                1 (i)
2025-05-15 18:28:52,277 - TaskScriptRunner - INFO -              14 LOAD_DEREF               1 (block_size)
2025-05-15 18:28:52,278 - TaskScriptRunner - INFO -              16 BINARY_ADD
2025-05-15 18:28:52,279 - TaskScriptRunner - INFO -              18 BUILD_SLICE              2
2025-05-15 18:28:52,279 - TaskScriptRunner - INFO -              20 BINARY_SUBSCR
2025-05-15 18:28:52,280 - TaskScriptRunner - INFO -              22 LIST_APPEND              2
2025-05-15 18:28:52,280 - TaskScriptRunner - INFO -              24 JUMP_ABSOLUTE            2 (to 4)
2025-05-15 18:28:52,281 - TaskScriptRunner - INFO -         >>   26 RETURN_VALUE
2025-05-15 18:28:53,611 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=412ac6fd-7905-4052-9f24-dd4cc7ac21ad] - Running dequantization...
2025-05-15 18:28:53,611 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=412ac6fd-7905-4052-9f24-dd4cc7ac21ad] - Running dequantization on 179 variables
2025-05-15 18:28:53,854 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=412ac6fd-7905-4052-9f24-dd4cc7ac21ad] - Dequantized 179/179 params. Before dequantization: 2832.25 MB with meta: 0.00 MB. After dequantization: 5664.51 MB.
2025-05-15 18:28:53,857 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=412ac6fd-7905-4052-9f24-dd4cc7ac21ad] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float32', 'model.model.layers.0.self_attn.k_norm.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float32', 'model.model.layers.1.self_attn.k_norm.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float32', 'model.model.layers.2.self_attn.k_norm.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float32', 'model.model.layers.3.self_attn.k_norm.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float32', 'model.model.layers.4.self_attn.k_norm.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float32', 'model.model.layers.5.self_attn.k_norm.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float32', 'model.model.layers.6.self_attn.k_norm.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float32', 'model.model.layers.7.self_attn.k_norm.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float32', 'model.model.layers.8.self_attn.k_norm.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float32', 'model.model.layers.9.self_attn.k_norm.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float32', 'model.model.layers.10.self_attn.k_norm.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float32', 'model.model.layers.11.self_attn.k_norm.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float32', 'model.model.layers.12.self_attn.k_norm.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float32', 'model.model.layers.13.self_attn.k_norm.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float32', 'model.model.layers.14.self_attn.k_norm.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float32', 'model.model.layers.15.self_attn.k_norm.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'}
2025-05-15 18:28:53,860 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=412ac6fd-7905-4052-9f24-dd4cc7ac21ad] - execute for task (train)
2025-05-15 18:28:53,861 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=412ac6fd-7905-4052-9f24-dd4cc7ac21ad] - send data to peer
2025-05-15 18:28:53,862 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=412ac6fd-7905-4052-9f24-dd4cc7ac21ad] - sending payload to peer
2025-05-15 18:28:53,864 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=412ac6fd-7905-4052-9f24-dd4cc7ac21ad] - Waiting for result from peer
2025-05-15 18:28:59,225 - TaskScriptRunner - INFO - --- federated round 0 ---
2025-05-15 18:29:00,393 - TaskScriptRunner - INFO - {'eval_loss': 8.795811653137207, 'eval_model_preparation_time': 0.0064, 'eval_runtime': 0.5622, 'eval_samples_per_second': 124.514, 'eval_steps_per_second': 16.009}
2025-05-15 18:29:00,394 - TaskScriptRunner - INFO - eval metrics: {'eval_loss': 8.795811653137207, 'eval_model_preparation_time': 0.0064, 'eval_runtime': 0.5622, 'eval_samples_per_second': 124.514, 'eval_steps_per_second': 16.009, 'perplexity': 6606.515599834131}
2025-05-15 18:29:03,273 - TaskScriptRunner - INFO - {'loss': 8.5981, 'grad_norm': 13.5, 'learning_rate': 0.0, 'epoch': 0.005772005772005772}
2025-05-15 18:29:04,370 - TaskScriptRunner - INFO - {'loss': 8.6744, 'grad_norm': 10.875, 'learning_rate': 8.333333333333333e-05, 'epoch': 0.011544011544011544}
2025-05-15 18:29:05,448 - TaskScriptRunner - INFO - {'loss': 7.9187, 'grad_norm': 7.625, 'learning_rate': 0.00016666666666666666, 'epoch': 0.017316017316017316}
2025-05-15 18:29:06,528 - TaskScriptRunner - INFO - {'loss': 7.9568, 'grad_norm': 16.625, 'learning_rate': 0.00025, 'epoch': 0.023088023088023088}
2025-05-15 18:29:07,625 - TaskScriptRunner - INFO - {'loss': 11.9362, 'grad_norm': 101.0, 'learning_rate': 0.0003333333333333333, 'epoch': 0.02886002886002886}
2025-05-15 18:29:08,704 - TaskScriptRunner - INFO - {'loss': 9.6598, 'grad_norm': 28.5, 'learning_rate': 0.0004166666666666667, 'epoch': 0.03463203463203463}
2025-05-15 18:29:09,789 - TaskScriptRunner - INFO - {'loss': 9.4126, 'grad_norm': 35.0, 'learning_rate': 0.0005, 'epoch': 0.04040404040404041}
2025-05-15 18:29:10,865 - TaskScriptRunner - INFO - {'loss': 9.1622, 'grad_norm': 38.5, 'learning_rate': 0.0004999557652060729, 'epoch': 0.046176046176046176}
2025-05-15 18:29:11,949 - TaskScriptRunner - INFO - {'loss': 8.5241, 'grad_norm': 8.25, 'learning_rate': 0.0004998230764780276, 'epoch': 0.05194805194805195}
2025-05-15 18:29:13,038 - TaskScriptRunner - INFO - {'loss': 8.3689, 'grad_norm': 10.375, 'learning_rate': 0.0004996019807715324, 'epoch': 0.05772005772005772}
2025-05-15 18:29:14,115 - TaskScriptRunner - INFO - {'loss': 7.9521, 'grad_norm': 8.125, 'learning_rate': 0.0004992925563275714, 'epoch': 0.06349206349206349}
2025-05-15 18:29:15,191 - TaskScriptRunner - INFO - {'loss': 8.529, 'grad_norm': 14.375, 'learning_rate': 0.0004988949126447567, 'epoch': 0.06926406926406926}
2025-05-15 18:29:16,272 - TaskScriptRunner - INFO - {'loss': 7.954, 'grad_norm': 11.3125, 'learning_rate': 0.0004984091904405792, 'epoch': 0.07503607503607504}
2025-05-15 18:29:17,389 - TaskScriptRunner - INFO - {'loss': 7.7266, 'grad_norm': 7.0625, 'learning_rate': 0.000497835561601612, 'epoch': 0.08080808080808081}
2025-05-15 18:29:18,508 - TaskScriptRunner - INFO - {'loss': 8.1219, 'grad_norm': 10.4375, 'learning_rate': 0.0004971742291226826, 'epoch': 0.08658008658008658}
2025-05-15 18:29:19,573 - TaskScriptRunner - INFO - {'loss': 8.0693, 'grad_norm': 23.125, 'learning_rate': 0.0004964254270350387, 'epoch': 0.09235209235209235}
2025-05-15 18:29:20,646 - TaskScriptRunner - INFO - {'loss': 7.7709, 'grad_norm': 8.375, 'learning_rate': 0.0004955894203235284, 'epoch': 0.09812409812409813}
2025-05-15 18:29:21,719 - TaskScriptRunner - INFO - {'loss': 7.7282, 'grad_norm': 5.375, 'learning_rate': 0.0004946665048328287, 'epoch': 0.1038961038961039}
2025-05-15 18:29:22,823 - TaskScriptRunner - INFO - {'loss': 7.6397, 'grad_norm': 5.21875, 'learning_rate': 0.0004936570071627517, 'epoch': 0.10966810966810966}
2025-05-15 18:29:23,887 - TaskScriptRunner - INFO - {'loss': 7.5681, 'grad_norm': 8.6875, 'learning_rate': 0.0004925612845526691, 'epoch': 0.11544011544011544}
2025-05-15 18:29:24,946 - TaskScriptRunner - INFO - {'loss': 7.5938, 'grad_norm': 5.5, 'learning_rate': 0.0004913797247550911, 'epoch': 0.12121212121212122}
2025-05-15 18:29:26,001 - TaskScriptRunner - INFO - {'loss': 7.5745, 'grad_norm': 4.34375, 'learning_rate': 0.0004901127458984516, 'epoch': 0.12698412698412698}
2025-05-15 18:29:27,063 - TaskScriptRunner - INFO - {'loss': 7.5515, 'grad_norm': 4.5625, 'learning_rate': 0.0004887607963391394, 'epoch': 0.13275613275613277}
2025-05-15 18:29:28,116 - TaskScriptRunner - INFO - {'loss': 7.471, 'grad_norm': 3.515625, 'learning_rate': 0.00048732435450283564, 'epoch': 0.13852813852813853}
2025-05-15 18:29:29,174 - TaskScriptRunner - INFO - {'loss': 7.5775, 'grad_norm': 5.59375, 'learning_rate': 0.00048580392871520943, 'epoch': 0.1443001443001443}
2025-05-15 18:29:30,232 - TaskScriptRunner - INFO - {'loss': 7.4914, 'grad_norm': 3.015625, 'learning_rate': 0.00048420005702203196, 'epoch': 0.15007215007215008}
2025-05-15 18:29:31,288 - TaskScriptRunner - INFO - {'loss': 7.5697, 'grad_norm': 3.140625, 'learning_rate': 0.00048251330699877374, 'epoch': 0.15584415584415584}
2025-05-15 18:29:32,346 - TaskScriptRunner - INFO - {'loss': 7.5102, 'grad_norm': 3.046875, 'learning_rate': 0.00048074427554975236, 'epoch': 0.16161616161616163}
2025-05-15 18:29:33,401 - TaskScriptRunner - INFO - {'loss': 7.5294, 'grad_norm': 3.0, 'learning_rate': 0.00047889358869690056, 'epoch': 0.1673881673881674}
2025-05-15 18:29:34,456 - TaskScriptRunner - INFO - {'loss': 7.5263, 'grad_norm': 3.15625, 'learning_rate': 0.0004769619013582309, 'epoch': 0.17316017316017315}
2025-05-15 18:29:35,510 - TaskScriptRunner - INFO - {'loss': 7.5215, 'grad_norm': 2.53125, 'learning_rate': 0.00047494989711607415, 'epoch': 0.17893217893217894}
2025-05-15 18:29:36,567 - TaskScriptRunner - INFO - {'loss': 7.524, 'grad_norm': 2.609375, 'learning_rate': 0.0004728582879751746, 'epoch': 0.1847041847041847}
2025-05-15 18:29:37,626 - TaskScriptRunner - INFO - {'loss': 7.4817, 'grad_norm': 3.078125, 'learning_rate': 0.00047068781411072687, 'epoch': 0.19047619047619047}
2025-05-15 18:29:38,684 - TaskScriptRunner - INFO - {'loss': 7.4674, 'grad_norm': 2.828125, 'learning_rate': 0.00046843924360644385, 'epoch': 0.19624819624819625}
2025-05-15 18:29:39,739 - TaskScriptRunner - INFO - {'loss': 7.5368, 'grad_norm': 2.78125, 'learning_rate': 0.00046611337218274864, 'epoch': 0.20202020202020202}
2025-05-15 18:29:40,798 - TaskScriptRunner - INFO - {'loss': 7.5882, 'grad_norm': 2.734375, 'learning_rate': 0.0004637110229151863, 'epoch': 0.2077922077922078}
2025-05-15 18:29:41,851 - TaskScriptRunner - INFO - {'loss': 7.4634, 'grad_norm': 2.09375, 'learning_rate': 0.00046123304594315517, 'epoch': 0.21356421356421357}
2025-05-15 18:29:42,908 - TaskScriptRunner - INFO - {'loss': 7.5288, 'grad_norm': 2.875, 'learning_rate': 0.0004586803181690609, 'epoch': 0.21933621933621933}
2025-05-15 18:29:43,971 - TaskScriptRunner - INFO - {'loss': 7.5046, 'grad_norm': 2.640625, 'learning_rate': 0.0004560537429479998, 'epoch': 0.22510822510822512}
2025-05-15 18:29:45,028 - TaskScriptRunner - INFO - {'loss': 7.5484, 'grad_norm': 2.78125, 'learning_rate': 0.00045335424976808116, 'epoch': 0.23088023088023088}
2025-05-15 18:29:46,084 - TaskScriptRunner - INFO - {'loss': 7.5354, 'grad_norm': 2.03125, 'learning_rate': 0.0004505827939215009, 'epoch': 0.23665223665223664}
2025-05-15 18:29:47,140 - TaskScriptRunner - INFO - {'loss': 7.4529, 'grad_norm': 2.75, 'learning_rate': 0.00044774035616648516, 'epoch': 0.24242424242424243}
2025-05-15 18:29:48,192 - TaskScriptRunner - INFO - {'loss': 7.5861, 'grad_norm': 2.515625, 'learning_rate': 0.0004448279423802207, 'epoch': 0.2481962481962482}
2025-05-15 18:29:49,244 - TaskScriptRunner - INFO - {'loss': 7.5338, 'grad_norm': 2.1875, 'learning_rate': 0.0004418465832028967, 'epoch': 0.25396825396825395}
2025-05-15 18:29:50,298 - TaskScriptRunner - INFO - {'loss': 7.4979, 'grad_norm': 2.109375, 'learning_rate': 0.00043879733367298404, 'epoch': 0.2597402597402597}
2025-05-15 18:29:51,354 - TaskScriptRunner - INFO - {'loss': 7.5978, 'grad_norm': 2.109375, 'learning_rate': 0.00043568127285387924, 'epoch': 0.26551226551226553}
2025-05-15 18:29:52,408 - TaskScriptRunner - INFO - {'loss': 7.5724, 'grad_norm': 2.234375, 'learning_rate': 0.00043249950345204804, 'epoch': 0.2712842712842713}
2025-05-15 18:29:53,462 - TaskScriptRunner - INFO - {'loss': 7.5828, 'grad_norm': 2.234375, 'learning_rate': 0.0004292531514268008, 'epoch': 0.27705627705627706}
2025-05-15 18:29:54,518 - TaskScriptRunner - INFO - {'loss': 7.4608, 'grad_norm': 1.828125, 'learning_rate': 0.00042594336559184035, 'epoch': 0.2828282828282828}
2025-05-15 18:29:55,572 - TaskScriptRunner - INFO - {'loss': 7.4937, 'grad_norm': 2.296875, 'learning_rate': 0.0004225713172087216, 'epoch': 0.2886002886002886}
2025-05-15 18:29:56,628 - TaskScriptRunner - INFO - {'loss': 7.4861, 'grad_norm': 2.40625, 'learning_rate': 0.0004191381995723672, 'epoch': 0.2943722943722944}
2025-05-15 18:29:57,682 - TaskScriptRunner - INFO - {'loss': 7.4319, 'grad_norm': 2.40625, 'learning_rate': 0.00041564522758878654, 'epoch': 0.30014430014430016}
2025-05-15 18:29:58,736 - TaskScriptRunner - INFO - {'loss': 7.5124, 'grad_norm': 2.078125, 'learning_rate': 0.0004120936373451467, 'epoch': 0.3059163059163059}
2025-05-15 18:29:59,792 - TaskScriptRunner - INFO - {'loss': 7.5071, 'grad_norm': 2.046875, 'learning_rate': 0.000408484685672348, 'epoch': 0.3116883116883117}
2025-05-15 18:30:00,852 - TaskScriptRunner - INFO - {'loss': 7.5044, 'grad_norm': 2.28125, 'learning_rate': 0.0004048196497002588, 'epoch': 0.31746031746031744}
2025-05-15 18:30:01,906 - TaskScriptRunner - INFO - {'loss': 7.4585, 'grad_norm': 1.859375, 'learning_rate': 0.0004010998264057667, 'epoch': 0.32323232323232326}
2025-05-15 18:30:02,961 - TaskScriptRunner - INFO - {'loss': 7.4923, 'grad_norm': 1.984375, 'learning_rate': 0.0003973265321538069, 'epoch': 0.329004329004329}
2025-05-15 18:30:04,015 - TaskScriptRunner - INFO - {'loss': 7.4486, 'grad_norm': 1.8203125, 'learning_rate': 0.0003935011022315284, 'epoch': 0.3347763347763348}
2025-05-15 18:30:05,069 - TaskScriptRunner - INFO - {'loss': 7.4381, 'grad_norm': 1.875, 'learning_rate': 0.00038962489037576583, 'epoch': 0.34054834054834054}
2025-05-15 18:30:06,125 - TaskScriptRunner - INFO - {'loss': 7.5355, 'grad_norm': 2.125, 'learning_rate': 0.0003856992682939803, 'epoch': 0.3463203463203463}
2025-05-15 18:30:07,182 - TaskScriptRunner - INFO - {'loss': 7.4856, 'grad_norm': 1.75, 'learning_rate': 0.0003817256251788425, 'epoch': 0.35209235209235207}
2025-05-15 18:30:08,236 - TaskScriptRunner - INFO - {'loss': 7.4742, 'grad_norm': 1.9609375, 'learning_rate': 0.00037770536721662694, 'epoch': 0.3578643578643579}
2025-05-15 18:30:09,291 - TaskScriptRunner - INFO - {'loss': 7.4431, 'grad_norm': 1.9296875, 'learning_rate': 0.0003736399170895938, 'epoch': 0.36363636363636365}
2025-05-15 18:30:10,345 - TaskScriptRunner - INFO - {'loss': 7.5604, 'grad_norm': 2.21875, 'learning_rate': 0.0003695307134725316, 'epoch': 0.3694083694083694}
2025-05-15 18:30:11,408 - TaskScriptRunner - INFO - {'loss': 7.4036, 'grad_norm': 1.9453125, 'learning_rate': 0.0003653792105236422, 'epoch': 0.37518037518037517}
2025-05-15 18:30:12,465 - TaskScriptRunner - INFO - {'loss': 7.4354, 'grad_norm': 1.8828125, 'learning_rate': 0.00036118687736994487, 'epoch': 0.38095238095238093}
2025-05-15 18:30:13,521 - TaskScriptRunner - INFO - {'loss': 7.495, 'grad_norm': 1.8515625, 'learning_rate': 0.0003569551975873847, 'epoch': 0.38672438672438675}
2025-05-15 18:30:14,580 - TaskScriptRunner - INFO - {'loss': 7.4922, 'grad_norm': 1.921875, 'learning_rate': 0.00035268566867582683, 'epoch': 0.3924963924963925}
2025-05-15 18:30:15,636 - TaskScriptRunner - INFO - {'loss': 7.3793, 'grad_norm': 1.7109375, 'learning_rate': 0.0003483798015291239, 'epoch': 0.39826839826839827}
2025-05-15 18:30:16,694 - TaskScriptRunner - INFO - {'loss': 7.3737, 'grad_norm': 1.71875, 'learning_rate': 0.00034403911990044307, 'epoch': 0.40404040404040403}
2025-05-15 18:30:17,749 - TaskScriptRunner - INFO - {'loss': 7.4197, 'grad_norm': 2.15625, 'learning_rate': 0.00033966515986304317, 'epoch': 0.4098124098124098}
2025-05-15 18:30:18,801 - TaskScriptRunner - INFO - {'loss': 7.3202, 'grad_norm': 2.15625, 'learning_rate': 0.0003352594692666915, 'epoch': 0.4155844155844156}
2025-05-15 18:30:19,854 - TaskScriptRunner - INFO - {'loss': 7.4655, 'grad_norm': 1.671875, 'learning_rate': 0.000330823607189913, 'epoch': 0.4213564213564214}
2025-05-15 18:30:20,908 - TaskScriptRunner - INFO - {'loss': 7.4769, 'grad_norm': 1.7421875, 'learning_rate': 0.0003263591433882666, 'epoch': 0.42712842712842713}
2025-05-15 18:30:21,965 - TaskScriptRunner - INFO - {'loss': 7.5285, 'grad_norm': 1.6953125, 'learning_rate': 0.00032186765773884244, 'epoch': 0.4329004329004329}
2025-05-15 18:30:23,025 - TaskScriptRunner - INFO - {'loss': 7.4527, 'grad_norm': 1.921875, 'learning_rate': 0.0003173507396811774, 'epoch': 0.43867243867243866}
2025-05-15 18:30:24,082 - TaskScriptRunner - INFO - {'loss': 7.3743, 'grad_norm': 1.734375, 'learning_rate': 0.00031280998765478727, 'epoch': 0.4444444444444444}
2025-05-15 18:30:25,137 - TaskScriptRunner - INFO - {'loss': 7.4309, 'grad_norm': 2.109375, 'learning_rate': 0.0003082470085335133, 'epoch': 0.45021645021645024}
2025-05-15 18:30:26,196 - TaskScriptRunner - INFO - {'loss': 7.3623, 'grad_norm': 1.828125, 'learning_rate': 0.00030366341705688466, 'epoch': 0.455988455988456}
2025-05-15 18:30:27,252 - TaskScriptRunner - INFO - {'loss': 7.4157, 'grad_norm': 1.5625, 'learning_rate': 0.0002990608352586965, 'epoch': 0.46176046176046176}
2025-05-15 18:30:28,315 - TaskScriptRunner - INFO - {'loss': 7.4327, 'grad_norm': 1.7578125, 'learning_rate': 0.00029444089189300783, 'epoch': 0.4675324675324675}
2025-05-15 18:30:29,369 - TaskScriptRunner - INFO - {'loss': 7.4362, 'grad_norm': 1.6875, 'learning_rate': 0.00028980522185776065, 'epoch': 0.4733044733044733}
2025-05-15 18:30:30,422 - TaskScriptRunner - INFO - {'loss': 7.4027, 'grad_norm': 1.7265625, 'learning_rate': 0.00028515546561622466, 'epoch': 0.4790764790764791}
2025-05-15 18:30:31,481 - TaskScriptRunner - INFO - {'loss': 7.4137, 'grad_norm': 1.9609375, 'learning_rate': 0.000280493268616473, 'epoch': 0.48484848484848486}
2025-05-15 18:30:32,536 - TaskScriptRunner - INFO - {'loss': 7.4065, 'grad_norm': 1.8046875, 'learning_rate': 0.0002758202807090941, 'epoch': 0.4906204906204906}
2025-05-15 18:30:33,598 - TaskScriptRunner - INFO - {'loss': 7.4405, 'grad_norm': 1.59375, 'learning_rate': 0.00027113815556334474, 'epoch': 0.4963924963924964}
2025-05-15 18:30:34,651 - TaskScriptRunner - INFO - {'loss': 7.3764, 'grad_norm': 1.734375, 'learning_rate': 0.00026644855008195267, 'epoch': 0.5021645021645021}
2025-05-15 18:30:35,706 - TaskScriptRunner - INFO - {'loss': 7.4357, 'grad_norm': 1.6484375, 'learning_rate': 0.0002617531238147744, 'epoch': 0.5079365079365079}
2025-05-15 18:30:36,766 - TaskScriptRunner - INFO - {'loss': 7.429, 'grad_norm': 1.890625, 'learning_rate': 0.0002570535383715165, 'epoch': 0.5137085137085137}
2025-05-15 18:30:37,819 - TaskScriptRunner - INFO - {'loss': 7.4084, 'grad_norm': 1.671875, 'learning_rate': 0.0002523514568337281, 'epoch': 0.5194805194805194}
2025-05-15 18:30:38,872 - TaskScriptRunner - INFO - {'loss': 7.4225, 'grad_norm': 1.796875, 'learning_rate': 0.000247648543166272, 'epoch': 0.5252525252525253}
2025-05-15 18:30:39,926 - TaskScriptRunner - INFO - {'loss': 7.46, 'grad_norm': 1.9140625, 'learning_rate': 0.00024294646162848353, 'epoch': 0.5310245310245311}
2025-05-15 18:30:40,979 - TaskScriptRunner - INFO - {'loss': 7.4939, 'grad_norm': 1.6015625, 'learning_rate': 0.00023824687618522567, 'epoch': 0.5367965367965368}
2025-05-15 18:30:42,045 - TaskScriptRunner - INFO - {'loss': 7.4228, 'grad_norm': 1.921875, 'learning_rate': 0.00023355144991804737, 'epoch': 0.5425685425685426}
2025-05-15 18:30:43,099 - TaskScriptRunner - INFO - {'loss': 7.4992, 'grad_norm': 1.5625, 'learning_rate': 0.00022886184443665522, 'epoch': 0.5483405483405484}
2025-05-15 18:30:44,154 - TaskScriptRunner - INFO - {'loss': 7.3876, 'grad_norm': 1.6953125, 'learning_rate': 0.0002241797192909059, 'epoch': 0.5541125541125541}
2025-05-15 18:30:45,210 - TaskScriptRunner - INFO - {'loss': 7.4043, 'grad_norm': 2.046875, 'learning_rate': 0.000219506731383527, 'epoch': 0.5598845598845599}
2025-05-15 18:30:46,264 - TaskScriptRunner - INFO - {'loss': 7.457, 'grad_norm': 1.7734375, 'learning_rate': 0.0002148445343837755, 'epoch': 0.5656565656565656}
2025-05-15 18:30:47,318 - TaskScriptRunner - INFO - {'loss': 7.3575, 'grad_norm': 1.890625, 'learning_rate': 0.00021019477814223942, 'epoch': 0.5714285714285714}
2025-05-15 18:30:48,374 - TaskScriptRunner - INFO - {'loss': 7.4039, 'grad_norm': 2.03125, 'learning_rate': 0.0002055591081069922, 'epoch': 0.5772005772005772}
2025-05-15 18:30:49,427 - TaskScriptRunner - INFO - {'loss': 7.4031, 'grad_norm': 1.734375, 'learning_rate': 0.00020093916474130352, 'epoch': 0.5829725829725829}
2025-05-15 18:30:50,482 - TaskScriptRunner - INFO - {'loss': 7.3922, 'grad_norm': 1.7421875, 'learning_rate': 0.00019633658294311535, 'epoch': 0.5887445887445888}
2025-05-15 18:30:51,539 - TaskScriptRunner - INFO - {'loss': 7.3967, 'grad_norm': 1.953125, 'learning_rate': 0.0001917529914664867, 'epoch': 0.5945165945165946}
2025-05-15 18:30:52,594 - TaskScriptRunner - INFO - {'loss': 7.402, 'grad_norm': 1.6875, 'learning_rate': 0.00018719001234521283, 'epoch': 0.6002886002886003}
2025-05-15 18:30:53,648 - TaskScriptRunner - INFO - {'loss': 7.3653, 'grad_norm': 1.65625, 'learning_rate': 0.00018264926031882274, 'epoch': 0.6060606060606061}
2025-05-15 18:30:54,703 - TaskScriptRunner - INFO - {'loss': 7.4276, 'grad_norm': 1.5078125, 'learning_rate': 0.00017813234226115766, 'epoch': 0.6118326118326118}
2025-05-15 18:30:55,761 - TaskScriptRunner - INFO - {'loss': 7.4163, 'grad_norm': 1.6953125, 'learning_rate': 0.00017364085661173345, 'epoch': 0.6176046176046176}
2025-05-15 18:30:56,819 - TaskScriptRunner - INFO - {'loss': 7.3949, 'grad_norm': 1.4921875, 'learning_rate': 0.000169176392810087, 'epoch': 0.6233766233766234}
2025-05-15 18:30:57,873 - TaskScriptRunner - INFO - {'loss': 7.3474, 'grad_norm': 1.453125, 'learning_rate': 0.0001647405307333085, 'epoch': 0.6291486291486291}
2025-05-15 18:30:58,934 - TaskScriptRunner - INFO - {'loss': 7.3913, 'grad_norm': 1.5234375, 'learning_rate': 0.00016033484013695687, 'epoch': 0.6349206349206349}
2025-05-15 18:30:59,989 - TaskScriptRunner - INFO - {'loss': 7.3751, 'grad_norm': 1.5078125, 'learning_rate': 0.00015596088009955694, 'epoch': 0.6406926406926406}
2025-05-15 18:31:01,043 - TaskScriptRunner - INFO - {'loss': 7.4067, 'grad_norm': 1.53125, 'learning_rate': 0.00015162019847087617, 'epoch': 0.6464646464646465}
2025-05-15 18:31:02,107 - TaskScriptRunner - INFO - {'loss': 7.3936, 'grad_norm': 1.421875, 'learning_rate': 0.00014731433132417315, 'epoch': 0.6522366522366523}
2025-05-15 18:31:03,161 - TaskScriptRunner - INFO - {'loss': 7.3803, 'grad_norm': 1.4375, 'learning_rate': 0.00014304480241261527, 'epoch': 0.658008658008658}
2025-05-15 18:31:04,215 - TaskScriptRunner - INFO - {'loss': 7.3383, 'grad_norm': 1.390625, 'learning_rate': 0.0001388131226300552, 'epoch': 0.6637806637806638}
2025-05-15 18:31:05,272 - TaskScriptRunner - INFO - {'loss': 7.3762, 'grad_norm': 1.5078125, 'learning_rate': 0.0001346207894763578, 'epoch': 0.6695526695526696}
2025-05-15 18:31:06,328 - TaskScriptRunner - INFO - {'loss': 7.3567, 'grad_norm': 1.640625, 'learning_rate': 0.0001304692865274683, 'epoch': 0.6753246753246753}
2025-05-15 18:31:07,386 - TaskScriptRunner - INFO - {'loss': 7.4187, 'grad_norm': 1.4609375, 'learning_rate': 0.0001263600829104062, 'epoch': 0.6810966810966811}
2025-05-15 18:31:08,439 - TaskScriptRunner - INFO - {'loss': 7.409, 'grad_norm': 1.4921875, 'learning_rate': 0.00012229463278337307, 'epoch': 0.6868686868686869}
2025-05-15 18:31:09,492 - TaskScriptRunner - INFO - {'loss': 7.3818, 'grad_norm': 1.6953125, 'learning_rate': 0.00011827437482115758, 'epoch': 0.6926406926406926}
2025-05-15 18:31:10,553 - TaskScriptRunner - INFO - {'loss': 7.4282, 'grad_norm': 1.640625, 'learning_rate': 0.00011430073170601968, 'epoch': 0.6984126984126984}
2025-05-15 18:31:11,608 - TaskScriptRunner - INFO - {'loss': 7.4073, 'grad_norm': 1.7265625, 'learning_rate': 0.00011037510962423425, 'epoch': 0.7041847041847041}
2025-05-15 18:31:12,666 - TaskScriptRunner - INFO - {'loss': 7.3963, 'grad_norm': 1.6015625, 'learning_rate': 0.0001064988977684716, 'epoch': 0.70995670995671}
2025-05-15 18:31:13,721 - TaskScriptRunner - INFO - {'loss': 7.337, 'grad_norm': 1.625, 'learning_rate': 0.00010267346784619325, 'epoch': 0.7157287157287158}
2025-05-15 18:31:14,777 - TaskScriptRunner - INFO - {'loss': 7.3859, 'grad_norm': 1.609375, 'learning_rate': 9.890017359423326e-05, 'epoch': 0.7215007215007215}
2025-05-15 18:31:15,832 - TaskScriptRunner - INFO - {'loss': 7.3205, 'grad_norm': 1.3671875, 'learning_rate': 9.518035029974126e-05, 'epoch': 0.7272727272727273}
2025-05-15 18:31:16,888 - TaskScriptRunner - INFO - {'loss': 7.3241, 'grad_norm': 1.375, 'learning_rate': 9.151531432765204e-05, 'epoch': 0.733044733044733}
2025-05-15 18:31:17,944 - TaskScriptRunner - INFO - {'loss': 7.4123, 'grad_norm': 1.5, 'learning_rate': 8.790636265485333e-05, 'epoch': 0.7388167388167388}
2025-05-15 18:31:19,003 - TaskScriptRunner - INFO - {'loss': 7.3948, 'grad_norm': 1.2578125, 'learning_rate': 8.435477241121353e-05, 'epoch': 0.7445887445887446}
2025-05-15 18:31:20,058 - TaskScriptRunner - INFO - {'loss': 7.4035, 'grad_norm': 1.390625, 'learning_rate': 8.086180042763284e-05, 'epoch': 0.7503607503607503}
2025-05-15 18:31:21,112 - TaskScriptRunner - INFO - {'loss': 7.3424, 'grad_norm': 1.53125, 'learning_rate': 7.742868279127849e-05, 'epoch': 0.7561327561327561}
2025-05-15 18:31:22,174 - TaskScriptRunner - INFO - {'loss': 7.416, 'grad_norm': 1.3671875, 'learning_rate': 7.405663440815968e-05, 'epoch': 0.7619047619047619}
2025-05-15 18:31:23,228 - TaskScriptRunner - INFO - {'loss': 7.3278, 'grad_norm': 1.4296875, 'learning_rate': 7.074684857319927e-05, 'epoch': 0.7676767676767676}
2025-05-15 18:31:24,292 - TaskScriptRunner - INFO - {'loss': 7.3875, 'grad_norm': 1.3203125, 'learning_rate': 6.750049654795198e-05, 'epoch': 0.7734487734487735}
2025-05-15 18:31:25,345 - TaskScriptRunner - INFO - {'loss': 7.3234, 'grad_norm': 1.3203125, 'learning_rate': 6.431872714612072e-05, 'epoch': 0.7792207792207793}
2025-05-15 18:31:26,400 - TaskScriptRunner - INFO - {'loss': 7.3634, 'grad_norm': 1.296875, 'learning_rate': 6.120266632701598e-05, 'epoch': 0.784992784992785}
2025-05-15 18:31:27,458 - TaskScriptRunner - INFO - {'loss': 7.3782, 'grad_norm': 1.3359375, 'learning_rate': 5.815341679710326e-05, 'epoch': 0.7907647907647908}
2025-05-15 18:31:28,516 - TaskScriptRunner - INFO - {'loss': 7.3929, 'grad_norm': 1.359375, 'learning_rate': 5.517205761977939e-05, 'epoch': 0.7965367965367965}
2025-05-15 18:31:29,573 - TaskScriptRunner - INFO - {'loss': 7.3549, 'grad_norm': 1.3203125, 'learning_rate': 5.225964383351489e-05, 'epoch': 0.8023088023088023}
2025-05-15 18:31:30,628 - TaskScriptRunner - INFO - {'loss': 7.3895, 'grad_norm': 1.296875, 'learning_rate': 4.941720607849912e-05, 'epoch': 0.8080808080808081}
2025-05-15 18:31:31,685 - TaskScriptRunner - INFO - {'loss': 7.3694, 'grad_norm': 1.328125, 'learning_rate': 4.664575023191886e-05, 'epoch': 0.8138528138528138}
2025-05-15 18:31:32,743 - TaskScriptRunner - INFO - {'loss': 7.3656, 'grad_norm': 1.2890625, 'learning_rate': 4.394625705200012e-05, 'epoch': 0.8196248196248196}
2025-05-15 18:31:33,796 - TaskScriptRunner - INFO - {'loss': 7.3274, 'grad_norm': 1.265625, 'learning_rate': 4.131968183093912e-05, 'epoch': 0.8253968253968254}
2025-05-15 18:31:34,851 - TaskScriptRunner - INFO - {'loss': 7.3736, 'grad_norm': 1.3671875, 'learning_rate': 3.876695405684485e-05, 'epoch': 0.8311688311688312}
2025-05-15 18:31:35,906 - TaskScriptRunner - INFO - {'loss': 7.352, 'grad_norm': 1.3125, 'learning_rate': 3.628897708481377e-05, 'epoch': 0.836940836940837}
2025-05-15 18:31:36,962 - TaskScriptRunner - INFO - {'loss': 7.3178, 'grad_norm': 1.2890625, 'learning_rate': 3.388662781725141e-05, 'epoch': 0.8427128427128427}
2025-05-15 18:31:38,029 - TaskScriptRunner - INFO - {'loss': 7.2835, 'grad_norm': 1.359375, 'learning_rate': 3.1560756393556184e-05, 'epoch': 0.8484848484848485}
2025-05-15 18:31:39,082 - TaskScriptRunner - INFO - {'loss': 7.352, 'grad_norm': 1.3515625, 'learning_rate': 2.9312185889273145e-05, 'epoch': 0.8542568542568543}
2025-05-15 18:31:40,135 - TaskScriptRunner - INFO - {'loss': 7.3817, 'grad_norm': 1.2421875, 'learning_rate': 2.7141712024825378e-05, 'epoch': 0.86002886002886}
2025-05-15 18:31:41,195 - TaskScriptRunner - INFO - {'loss': 7.3627, 'grad_norm': 1.296875, 'learning_rate': 2.505010288392587e-05, 'epoch': 0.8658008658008658}
2025-05-15 18:31:42,250 - TaskScriptRunner - INFO - {'loss': 7.3361, 'grad_norm': 1.265625, 'learning_rate': 2.3038098641769088e-05, 'epoch': 0.8715728715728716}
2025-05-15 18:31:43,303 - TaskScriptRunner - INFO - {'loss': 7.3344, 'grad_norm': 1.2109375, 'learning_rate': 2.1106411303099453e-05, 'epoch': 0.8773448773448773}
2025-05-15 18:31:44,360 - TaskScriptRunner - INFO - {'loss': 7.3394, 'grad_norm': 1.3203125, 'learning_rate': 1.9255724450247676e-05, 'epoch': 0.8831168831168831}
2025-05-15 18:31:45,416 - TaskScriptRunner - INFO - {'loss': 7.4067, 'grad_norm': 1.2578125, 'learning_rate': 1.7486693001226267e-05, 'epoch': 0.8888888888888888}
2025-05-15 18:31:46,470 - TaskScriptRunner - INFO - {'loss': 7.4078, 'grad_norm': 1.2890625, 'learning_rate': 1.579994297796808e-05, 'epoch': 0.8946608946608947}
2025-05-15 18:31:47,529 - TaskScriptRunner - INFO - {'loss': 7.3871, 'grad_norm': 1.2109375, 'learning_rate': 1.4196071284790529e-05, 'epoch': 0.9004329004329005}
2025-05-15 18:31:48,585 - TaskScriptRunner - INFO - {'loss': 7.389, 'grad_norm': 1.3359375, 'learning_rate': 1.2675645497164351e-05, 'epoch': 0.9062049062049062}
2025-05-15 18:31:49,653 - TaskScriptRunner - INFO - {'loss': 7.3978, 'grad_norm': 1.2265625, 'learning_rate': 1.1239203660860647e-05, 'epoch': 0.911976911976912}
2025-05-15 18:31:50,710 - TaskScriptRunner - INFO - {'loss': 7.3805, 'grad_norm': 1.3671875, 'learning_rate': 9.88725410154842e-06, 'epoch': 0.9177489177489178}
2025-05-15 18:31:51,768 - TaskScriptRunner - INFO - {'loss': 7.3118, 'grad_norm': 1.359375, 'learning_rate': 8.620275244908826e-06, 'epoch': 0.9235209235209235}
2025-05-15 18:31:52,827 - TaskScriptRunner - INFO - {'loss': 7.4196, 'grad_norm': 1.3046875, 'learning_rate': 7.438715447331018e-06, 'epoch': 0.9292929292929293}
2025-05-15 18:31:53,880 - TaskScriptRunner - INFO - {'loss': 7.3744, 'grad_norm': 1.265625, 'learning_rate': 6.342992837248235e-06, 'epoch': 0.935064935064935}
2025-05-15 18:31:54,942 - TaskScriptRunner - INFO - {'loss': 7.3615, 'grad_norm': 1.25, 'learning_rate': 5.333495167171354e-06, 'epoch': 0.9408369408369408}
2025-05-15 18:31:55,998 - TaskScriptRunner - INFO - {'loss': 7.4075, 'grad_norm': 1.234375, 'learning_rate': 4.410579676471571e-06, 'epoch': 0.9466089466089466}
2025-05-15 18:31:57,054 - TaskScriptRunner - INFO - {'loss': 7.4288, 'grad_norm': 1.2265625, 'learning_rate': 3.5745729649613034e-06, 'epoch': 0.9523809523809523}
2025-05-15 18:31:58,117 - TaskScriptRunner - INFO - {'loss': 7.4002, 'grad_norm': 1.1796875, 'learning_rate': 2.8257708773173627e-06, 'epoch': 0.9581529581529582}
2025-05-15 18:31:59,172 - TaskScriptRunner - INFO - {'loss': 7.3354, 'grad_norm': 1.3203125, 'learning_rate': 2.1644383983880357e-06, 'epoch': 0.963924963924964}
2025-05-15 18:32:00,226 - TaskScriptRunner - INFO - {'loss': 7.3282, 'grad_norm': 1.2109375, 'learning_rate': 1.5908095594207582e-06, 'epoch': 0.9696969696969697}
2025-05-15 18:32:01,280 - TaskScriptRunner - INFO - {'loss': 7.3628, 'grad_norm': 1.203125, 'learning_rate': 1.1050873552433394e-06, 'epoch': 0.9754689754689755}
2025-05-15 18:32:02,336 - TaskScriptRunner - INFO - {'loss': 7.32, 'grad_norm': 1.234375, 'learning_rate': 7.074436724286704e-07, 'epoch': 0.9812409812409812}
2025-05-15 18:32:03,403 - TaskScriptRunner - INFO - {'loss': 7.3693, 'grad_norm': 1.328125, 'learning_rate': 3.9801922846766094e-07, 'epoch': 0.987012987012987}
2025-05-15 18:32:04,458 - TaskScriptRunner - INFO - {'loss': 7.413, 'grad_norm': 1.1015625, 'learning_rate': 1.7692352197240524e-07, 'epoch': 0.9927849927849928}
2025-05-15 18:32:05,511 - TaskScriptRunner - INFO - {'loss': 7.3762, 'grad_norm': 1.2890625, 'learning_rate': 4.423479392709484e-08, 'epoch': 0.9985569985569985}
2025-05-15 18:32:21,061 - TaskScriptRunner - INFO - {'train_runtime': 200.4205, 'train_samples_per_second': 34.577, 'train_steps_per_second': 0.863, 'train_loss': 7.546659943685366, 'epoch': 0.9985569985569985}
2025-05-15 18:32:22,850 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=412ac6fd-7905-4052-9f24-dd4cc7ac21ad] - Running quantization...
2025-05-15 18:32:22,852 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=412ac6fd-7905-4052-9f24-dd4cc7ac21ad] - Running quantization on 179 variables
2025-05-15 18:32:29,492 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=412ac6fd-7905-4052-9f24-dd4cc7ac21ad] - Quantized 179/179 params. Before quantization: 5664.51 MB. After quantization: 2832.25 MB with meta: 0.00 MB.
2025-05-15 18:32:29,493 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=412ac6fd-7905-4052-9f24-dd4cc7ac21ad] - Quantized from {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float32', 'model.model.layers.0.self_attn.k_norm.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float32', 'model.model.layers.1.self_attn.k_norm.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float32', 'model.model.layers.2.self_attn.k_norm.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float32', 'model.model.layers.3.self_attn.k_norm.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float32', 'model.model.layers.4.self_attn.k_norm.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float32', 'model.model.layers.5.self_attn.k_norm.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float32', 'model.model.layers.6.self_attn.k_norm.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float32', 'model.model.layers.7.self_attn.k_norm.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float32', 'model.model.layers.8.self_attn.k_norm.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float32', 'model.model.layers.9.self_attn.k_norm.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float32', 'model.model.layers.10.self_attn.k_norm.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float32', 'model.model.layers.11.self_attn.k_norm.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float32', 'model.model.layers.12.self_attn.k_norm.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float32', 'model.model.layers.13.self_attn.k_norm.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float32', 'model.model.layers.14.self_attn.k_norm.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float32', 'model.model.layers.15.self_attn.k_norm.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'} to float16
2025-05-15 18:38:55,375 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Running dequantization...
2025-05-15 18:38:55,376 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Running dequantization on 179 variables
2025-05-15 18:38:57,374 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.7.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,376 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.7.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,418 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.8.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,420 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.8.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,556 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.8.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,557 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.8.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,600 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.9.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,601 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.9.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,739 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.9.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,740 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.9.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,783 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.10.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,784 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.10.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,922 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.10.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,923 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.10.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,924 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.11.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,957 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.11.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:57,958 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.11.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,096 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.11.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,097 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.11.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,098 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.12.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,132 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.12.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,133 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.12.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,274 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.12.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,275 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.12.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,276 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.13.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,310 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.13.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,311 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.13.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,451 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.13.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,452 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.13.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,497 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.14.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,498 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.14.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,636 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.14.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,638 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.14.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,638 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.15.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,673 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.15.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,674 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.15.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,813 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.15.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,814 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.layers.15.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:58,815 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Skipping dequantization for model.model.norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:38:59,370 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Dequantized 140/179 params. Before dequantization: 2800.12 MB with meta: 0.00 MB. After dequantization: 5600.23 MB.
2025-05-15 18:38:59,372 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float32', 'model.model.layers.0.self_attn.k_norm.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float32', 'model.model.layers.1.self_attn.k_norm.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float32', 'model.model.layers.2.self_attn.k_norm.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float32', 'model.model.layers.3.self_attn.k_norm.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float32', 'model.model.layers.4.self_attn.k_norm.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float32', 'model.model.layers.5.self_attn.k_norm.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float32', 'model.model.layers.6.self_attn.k_norm.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float32', 'model.model.layers.7.self_attn.k_norm.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float16', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float16', 'model.model.layers.8.self_attn.k_norm.weight': 'float16', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float16', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float16', 'model.model.layers.9.self_attn.k_norm.weight': 'float16', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float16', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float16', 'model.model.layers.10.self_attn.k_norm.weight': 'float16', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float16', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.11.self_attn.q_proj.weight': 'float16', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float16', 'model.model.layers.11.self_attn.k_norm.weight': 'float16', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float16', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.12.self_attn.q_proj.weight': 'float16', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float16', 'model.model.layers.12.self_attn.k_norm.weight': 'float16', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float16', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.13.self_attn.q_proj.weight': 'float16', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float16', 'model.model.layers.13.self_attn.k_norm.weight': 'float16', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float16', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float16', 'model.model.layers.14.self_attn.k_norm.weight': 'float16', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float16', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.15.self_attn.q_proj.weight': 'float16', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float16', 'model.model.layers.15.self_attn.k_norm.weight': 'float16', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float16', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float16', 'model.model.norm.weight': 'float16', 'model.lm_head.weight': 'float32'}
2025-05-15 18:38:59,375 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - execute for task (train)
2025-05-15 18:38:59,378 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - send data to peer
2025-05-15 18:38:59,379 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - sending payload to peer
2025-05-15 18:38:59,381 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Waiting for result from peer
2025-05-15 18:38:59,796 - TaskScriptRunner - INFO - --- federated round 1 ---
2025-05-15 18:39:00,894 - TaskScriptRunner - INFO - {'eval_loss': 8.16836166381836, 'eval_model_preparation_time': 0.0064, 'eval_runtime': 0.2455, 'eval_samples_per_second': 285.151, 'eval_steps_per_second': 36.662, 'epoch': 0.9985569985569985}
2025-05-15 18:39:00,896 - TaskScriptRunner - INFO - eval metrics: {'eval_loss': 8.16836166381836, 'eval_model_preparation_time': 0.0064, 'eval_runtime': 0.2455, 'eval_samples_per_second': 285.151, 'eval_steps_per_second': 36.662, 'epoch': 0.9985569985569985, 'perplexity': 3527.5598977809127}
2025-05-15 18:39:20,957 - TaskScriptRunner - INFO - RNG state successfully loaded
2025-05-15 18:39:22,035 - TaskScriptRunner - INFO - {'loss': 8.0537, 'grad_norm': 9.5625, 'learning_rate': 0.0, 'epoch': 1.0057720057720059}
2025-05-15 18:39:23,075 - TaskScriptRunner - INFO - {'loss': 8.0795, 'grad_norm': 9.3125, 'learning_rate': 0.0002605469934405078, 'epoch': 1.0115440115440115}
2025-05-15 18:39:24,124 - TaskScriptRunner - INFO - {'loss': 7.7628, 'grad_norm': 3.3125, 'learning_rate': 0.0002582041791754375, 'epoch': 1.0173160173160174}
2025-05-15 18:39:25,183 - TaskScriptRunner - INFO - {'loss': 8.0, 'grad_norm': 9.125, 'learning_rate': 0.00025586064340081516, 'epoch': 1.023088023088023}
2025-05-15 18:39:26,242 - TaskScriptRunner - INFO - {'loss': 7.9595, 'grad_norm': 9.1875, 'learning_rate': 0.00025351659221689896, 'epoch': 1.028860028860029}
2025-05-15 18:39:27,316 - TaskScriptRunner - INFO - {'loss': 7.7844, 'grad_norm': 4.65625, 'learning_rate': 0.0002511722317692747, 'epoch': 1.0346320346320346}
2025-05-15 18:39:28,389 - TaskScriptRunner - INFO - {'loss': 7.7455, 'grad_norm': 8.6875, 'learning_rate': 0.0002488277682307254, 'epoch': 1.0404040404040404}
2025-05-15 18:39:29,467 - TaskScriptRunner - INFO - {'loss': 7.7461, 'grad_norm': 7.25, 'learning_rate': 0.00024648340778310105, 'epoch': 1.046176046176046}
2025-05-15 18:39:30,546 - TaskScriptRunner - INFO - {'loss': 7.6593, 'grad_norm': 4.21875, 'learning_rate': 0.0002441393565991849, 'epoch': 1.051948051948052}
2025-05-15 18:39:31,624 - TaskScriptRunner - INFO - {'loss': 7.5647, 'grad_norm': 3.09375, 'learning_rate': 0.00024179582082456253, 'epoch': 1.0577200577200576}
2025-05-15 18:39:32,757 - TaskScriptRunner - INFO - {'loss': 7.5575, 'grad_norm': 3.890625, 'learning_rate': 0.00023945300655949225, 'epoch': 1.0634920634920635}
2025-05-15 18:39:33,857 - TaskScriptRunner - INFO - {'loss': 7.4884, 'grad_norm': 3.625, 'learning_rate': 0.00023711111984077966, 'epoch': 1.0692640692640694}
2025-05-15 18:39:34,923 - TaskScriptRunner - INFO - {'loss': 7.4191, 'grad_norm': 2.96875, 'learning_rate': 0.00023477036662365828, 'epoch': 1.075036075036075}
2025-05-15 18:39:35,995 - TaskScriptRunner - INFO - {'loss': 7.4441, 'grad_norm': 4.40625, 'learning_rate': 0.00023243095276367684, 'epoch': 1.0808080808080809}
2025-05-15 18:39:37,036 - TaskScriptRunner - INFO - {'loss': 7.4609, 'grad_norm': 4.1875, 'learning_rate': 0.00023009308399859506, 'epoch': 1.0865800865800865}
2025-05-15 18:39:38,081 - TaskScriptRunner - INFO - {'loss': 7.4875, 'grad_norm': 2.484375, 'learning_rate': 0.00022775696593029104, 'epoch': 1.0923520923520924}
2025-05-15 18:39:39,121 - TaskScriptRunner - INFO - {'loss': 7.4308, 'grad_norm': 2.609375, 'learning_rate': 0.00022542280400667918, 'epoch': 1.098124098124098}
2025-05-15 18:39:40,171 - TaskScriptRunner - INFO - {'loss': 7.3175, 'grad_norm': 2.53125, 'learning_rate': 0.00022309080350364253, 'epoch': 1.103896103896104}
2025-05-15 18:39:41,212 - TaskScriptRunner - INFO - {'loss': 7.3679, 'grad_norm': 2.640625, 'learning_rate': 0.0002207611695069794, 'epoch': 1.1096681096681096}
2025-05-15 18:39:42,251 - TaskScriptRunner - INFO - {'loss': 7.3754, 'grad_norm': 2.375, 'learning_rate': 0.00021843410689436824, 'epoch': 1.1154401154401155}
2025-05-15 18:39:43,299 - TaskScriptRunner - INFO - {'loss': 7.4065, 'grad_norm': 2.015625, 'learning_rate': 0.0002161098203173492, 'epoch': 1.121212121212121}
2025-05-15 18:39:44,343 - TaskScriptRunner - INFO - {'loss': 7.3632, 'grad_norm': 1.84375, 'learning_rate': 0.000213788514183326, 'epoch': 1.126984126984127}
2025-05-15 18:39:45,390 - TaskScriptRunner - INFO - {'loss': 7.3099, 'grad_norm': 2.53125, 'learning_rate': 0.00021147039263759028, 'epoch': 1.1327561327561328}
2025-05-15 18:39:46,440 - TaskScriptRunner - INFO - {'loss': 7.3534, 'grad_norm': 2.21875, 'learning_rate': 0.00020915565954536742, 'epoch': 1.1385281385281385}
2025-05-15 18:39:47,481 - TaskScriptRunner - INFO - {'loss': 7.3543, 'grad_norm': 2.265625, 'learning_rate': 0.0002068445184738886, 'epoch': 1.1443001443001444}
2025-05-15 18:39:48,524 - TaskScriptRunner - INFO - {'loss': 7.3115, 'grad_norm': 2.078125, 'learning_rate': 0.00020453717267448717, 'epoch': 1.15007215007215}
2025-05-15 18:39:49,566 - TaskScriptRunner - INFO - {'loss': 7.3154, 'grad_norm': 1.8203125, 'learning_rate': 0.00020223382506472505, 'epoch': 1.155844155844156}
2025-05-15 18:39:50,606 - TaskScriptRunner - INFO - {'loss': 7.3584, 'grad_norm': 1.7109375, 'learning_rate': 0.00019993467821054645, 'epoch': 1.1616161616161615}
2025-05-15 18:39:51,645 - TaskScriptRunner - INFO - {'loss': 7.3113, 'grad_norm': 2.09375, 'learning_rate': 0.00019763993430846395, 'epoch': 1.1673881673881674}
2025-05-15 18:39:52,685 - TaskScriptRunner - INFO - {'loss': 7.406, 'grad_norm': 1.609375, 'learning_rate': 0.000195349795167776, 'epoch': 1.173160173160173}
2025-05-15 18:39:53,733 - TaskScriptRunner - INFO - {'loss': 7.3339, 'grad_norm': 1.6875, 'learning_rate': 0.0001930644621928194, 'epoch': 1.178932178932179}
2025-05-15 18:39:54,786 - TaskScriptRunner - INFO - {'loss': 7.3526, 'grad_norm': 1.8046875, 'learning_rate': 0.0001907841363652568, 'epoch': 1.1847041847041848}
2025-05-15 18:39:55,827 - TaskScriptRunner - INFO - {'loss': 7.3234, 'grad_norm': 1.5390625, 'learning_rate': 0.00018850901822640146, 'epoch': 1.1904761904761905}
2025-05-15 18:39:56,867 - TaskScriptRunner - INFO - {'loss': 7.4072, 'grad_norm': 1.65625, 'learning_rate': 0.0001862393078595809, 'epoch': 1.1962481962481963}
2025-05-15 18:39:57,906 - TaskScriptRunner - INFO - {'loss': 7.4083, 'grad_norm': 1.9296875, 'learning_rate': 0.0001839752048725408, 'epoch': 1.202020202020202}
2025-05-15 18:39:58,946 - TaskScriptRunner - INFO - {'loss': 7.3961, 'grad_norm': 1.6015625, 'learning_rate': 0.00018171690837989057, 'epoch': 1.2077922077922079}
2025-05-15 18:39:59,995 - TaskScriptRunner - INFO - {'loss': 7.4036, 'grad_norm': 1.546875, 'learning_rate': 0.00017946461698559237, 'epoch': 1.2135642135642135}
2025-05-15 18:40:01,037 - TaskScriptRunner - INFO - {'loss': 7.3232, 'grad_norm': 1.6796875, 'learning_rate': 0.00017721852876549508, 'epoch': 1.2193362193362194}
2025-05-15 18:40:02,076 - TaskScriptRunner - INFO - {'loss': 7.3948, 'grad_norm': 1.890625, 'learning_rate': 0.00017497884124991487, 'epoch': 1.225108225108225}
2025-05-15 18:40:03,115 - TaskScriptRunner - INFO - {'loss': 7.4026, 'grad_norm': 1.6640625, 'learning_rate': 0.00017274575140626317, 'epoch': 1.230880230880231}
2025-05-15 18:40:04,153 - TaskScriptRunner - INFO - {'loss': 7.3974, 'grad_norm': 1.5625, 'learning_rate': 0.00017051945562172494, 'epoch': 1.2366522366522366}
2025-05-15 18:40:05,194 - TaskScriptRunner - INFO - {'loss': 7.3143, 'grad_norm': 1.546875, 'learning_rate': 0.00016830014968598734, 'epoch': 1.2424242424242424}
2025-05-15 18:40:06,235 - TaskScriptRunner - INFO - {'loss': 7.3914, 'grad_norm': 1.734375, 'learning_rate': 0.00016608802877402136, 'epoch': 1.248196248196248}
2025-05-15 18:40:07,274 - TaskScriptRunner - INFO - {'loss': 7.3759, 'grad_norm': 1.59375, 'learning_rate': 0.00016388328742891677, 'epoch': 1.253968253968254}
2025-05-15 18:40:08,316 - TaskScriptRunner - INFO - {'loss': 7.3363, 'grad_norm': 1.5859375, 'learning_rate': 0.00016168611954477417, 'epoch': 1.2597402597402598}
2025-05-15 18:40:09,356 - TaskScriptRunner - INFO - {'loss': 7.3725, 'grad_norm': 1.578125, 'learning_rate': 0.00015949671834965222, 'epoch': 1.2655122655122655}
2025-05-15 18:40:10,398 - TaskScriptRunner - INFO - {'loss': 7.3916, 'grad_norm': 1.78125, 'learning_rate': 0.00015731527638857492, 'epoch': 1.2712842712842713}
2025-05-15 18:40:11,438 - TaskScriptRunner - INFO - {'loss': 7.3137, 'grad_norm': 1.84375, 'learning_rate': 0.00015514198550659793, 'epoch': 1.277056277056277}
2025-05-15 18:40:12,477 - TaskScriptRunner - INFO - {'loss': 7.3567, 'grad_norm': 1.6953125, 'learning_rate': 0.00015297703683193753, 'epoch': 1.2828282828282829}
2025-05-15 18:40:13,515 - TaskScriptRunner - INFO - {'loss': 7.3742, 'grad_norm': 1.5859375, 'learning_rate': 0.00015082062075916165, 'epoch': 1.2886002886002885}
2025-05-15 18:40:14,557 - TaskScriptRunner - INFO - {'loss': 7.3856, 'grad_norm': 1.5, 'learning_rate': 0.00014867292693244546, 'epoch': 1.2943722943722944}
2025-05-15 18:40:15,597 - TaskScriptRunner - INFO - {'loss': 7.3726, 'grad_norm': 1.6640625, 'learning_rate': 0.000146534144228894, 'epoch': 1.3001443001443}
2025-05-15 18:40:16,636 - TaskScriptRunner - INFO - {'loss': 7.3972, 'grad_norm': 1.6484375, 'learning_rate': 0.00014440446074193099, 'epoch': 1.305916305916306}
2025-05-15 18:40:17,676 - TaskScriptRunner - INFO - {'loss': 7.333, 'grad_norm': 1.75, 'learning_rate': 0.00014228406376475743, 'epoch': 1.3116883116883118}
2025-05-15 18:40:18,716 - TaskScriptRunner - INFO - {'loss': 7.2984, 'grad_norm': 1.71875, 'learning_rate': 0.00014017313977387997, 'epoch': 1.3174603174603174}
2025-05-15 18:40:19,756 - TaskScriptRunner - INFO - {'loss': 7.4107, 'grad_norm': 1.671875, 'learning_rate': 0.00013807187441271156, 'epoch': 1.3232323232323233}
2025-05-15 18:40:20,795 - TaskScriptRunner - INFO - {'loss': 7.3404, 'grad_norm': 1.6484375, 'learning_rate': 0.00013598045247524554, 'epoch': 1.329004329004329}
2025-05-15 18:40:21,835 - TaskScriptRunner - INFO - {'loss': 7.3451, 'grad_norm': 1.7265625, 'learning_rate': 0.00013389905788980294, 'epoch': 1.3347763347763348}
2025-05-15 18:40:22,876 - TaskScriptRunner - INFO - {'loss': 7.3895, 'grad_norm': 1.640625, 'learning_rate': 0.00013182787370285865, 'epoch': 1.3405483405483405}
2025-05-15 18:40:23,916 - TaskScriptRunner - INFO - {'loss': 7.3647, 'grad_norm': 1.6953125, 'learning_rate': 0.00012976708206294252, 'epoch': 1.3463203463203464}
2025-05-15 18:40:24,955 - TaskScriptRunner - INFO - {'loss': 7.3824, 'grad_norm': 1.6015625, 'learning_rate': 0.00012771686420462054, 'epoch': 1.352092352092352}
2025-05-15 18:40:25,995 - TaskScriptRunner - INFO - {'loss': 7.432, 'grad_norm': 1.6171875, 'learning_rate': 0.0001256774004325565, 'epoch': 1.3578643578643579}
2025-05-15 18:40:27,034 - TaskScriptRunner - INFO - {'loss': 7.3783, 'grad_norm': 1.5625, 'learning_rate': 0.00012364887010565535, 'epoch': 1.3636363636363638}
2025-05-15 18:40:28,078 - TaskScriptRunner - INFO - {'loss': 7.3569, 'grad_norm': 1.5390625, 'learning_rate': 0.00012163145162128947, 'epoch': 1.3694083694083694}
2025-05-15 18:40:29,116 - TaskScriptRunner - INFO - {'loss': 7.3285, 'grad_norm': 1.6875, 'learning_rate': 0.0001196253223996099, 'epoch': 1.375180375180375}
2025-05-15 18:40:30,157 - TaskScriptRunner - INFO - {'loss': 7.3751, 'grad_norm': 1.75, 'learning_rate': 0.00011763065886794258, 'epoch': 1.380952380952381}
2025-05-15 18:40:31,207 - TaskScriptRunner - INFO - {'loss': 7.4235, 'grad_norm': 1.859375, 'learning_rate': 0.00011564763644527357, 'epoch': 1.3867243867243868}
2025-05-15 18:40:32,248 - TaskScriptRunner - INFO - {'loss': 7.4149, 'grad_norm': 1.578125, 'learning_rate': 0.00011367642952682153, 'epoch': 1.3924963924963925}
2025-05-15 18:40:33,286 - TaskScriptRunner - INFO - {'loss': 7.3641, 'grad_norm': 1.9453125, 'learning_rate': 0.00011171721146870015, 'epoch': 1.3982683982683983}
2025-05-15 18:40:34,326 - TaskScriptRunner - INFO - {'loss': 7.3095, 'grad_norm': 2.15625, 'learning_rate': 0.00010977015457267365, 'epoch': 1.404040404040404}
2025-05-15 18:40:35,364 - TaskScriptRunner - INFO - {'loss': 7.3397, 'grad_norm': 1.9765625, 'learning_rate': 0.00010783543007100266, 'epoch': 1.4098124098124099}
2025-05-15 18:40:36,421 - TaskScriptRunner - INFO - {'loss': 7.4186, 'grad_norm': 2.375, 'learning_rate': 0.00010591320811138636, 'epoch': 1.4155844155844157}
2025-05-15 18:40:37,459 - TaskScriptRunner - INFO - {'loss': 7.3828, 'grad_norm': 1.9609375, 'learning_rate': 0.00010400365774199818, 'epoch': 1.4213564213564214}
2025-05-15 18:40:38,499 - TaskScriptRunner - INFO - {'loss': 7.4065, 'grad_norm': 2.015625, 'learning_rate': 0.0001021069468966194, 'epoch': 1.427128427128427}
2025-05-15 18:40:39,549 - TaskScriptRunner - INFO - {'loss': 7.3727, 'grad_norm': 1.9765625, 'learning_rate': 0.00010022324237987047, 'epoch': 1.432900432900433}
2025-05-15 18:40:40,591 - TaskScriptRunner - INFO - {'loss': 7.4207, 'grad_norm': 1.7421875, 'learning_rate': 9.835270985254111e-05, 'epoch': 1.4386724386724388}
2025-05-15 18:40:41,630 - TaskScriptRunner - INFO - {'loss': 7.3651, 'grad_norm': 1.6953125, 'learning_rate': 9.649551381702168e-05, 'epoch': 1.4444444444444444}
2025-05-15 18:40:42,668 - TaskScriptRunner - INFO - {'loss': 7.3787, 'grad_norm': 1.53125, 'learning_rate': 9.46518176028364e-05, 'epoch': 1.4502164502164503}
2025-05-15 18:40:43,706 - TaskScriptRunner - INFO - {'loss': 7.3673, 'grad_norm': 1.71875, 'learning_rate': 9.282178335227883e-05, 'epoch': 1.455988455988456}
2025-05-15 18:40:44,747 - TaskScriptRunner - INFO - {'loss': 7.3334, 'grad_norm': 1.6796875, 'learning_rate': 9.100557200615292e-05, 'epoch': 1.4617604617604618}
2025-05-15 18:40:45,786 - TaskScriptRunner - INFO - {'loss': 7.3773, 'grad_norm': 1.828125, 'learning_rate': 8.920334328961918e-05, 'epoch': 1.4675324675324675}
2025-05-15 18:40:46,824 - TaskScriptRunner - INFO - {'loss': 7.3488, 'grad_norm': 1.765625, 'learning_rate': 8.74152556981474e-05, 'epoch': 1.4733044733044733}
2025-05-15 18:40:47,862 - TaskScriptRunner - INFO - {'loss': 7.427, 'grad_norm': 1.984375, 'learning_rate': 8.56414664835785e-05, 'epoch': 1.479076479076479}
2025-05-15 18:40:48,901 - TaskScriptRunner - INFO - {'loss': 7.3515, 'grad_norm': 1.6015625, 'learning_rate': 8.388213164029459e-05, 'epoch': 1.4848484848484849}
2025-05-15 18:40:49,946 - TaskScriptRunner - INFO - {'loss': 7.4119, 'grad_norm': 1.5625, 'learning_rate': 8.213740589150032e-05, 'epoch': 1.4906204906204907}
2025-05-15 18:40:50,989 - TaskScriptRunner - INFO - {'loss': 7.3912, 'grad_norm': 1.671875, 'learning_rate': 8.040744267561637e-05, 'epoch': 1.4963924963924964}
2025-05-15 18:40:52,028 - TaskScriptRunner - INFO - {'loss': 7.3997, 'grad_norm': 1.765625, 'learning_rate': 7.869239413278442e-05, 'epoch': 1.502164502164502}
2025-05-15 18:40:53,078 - TaskScriptRunner - INFO - {'loss': 7.3349, 'grad_norm': 1.671875, 'learning_rate': 7.699241109148844e-05, 'epoch': 1.507936507936508}
2025-05-15 18:40:54,120 - TaskScriptRunner - INFO - {'loss': 7.3493, 'grad_norm': 1.6015625, 'learning_rate': 7.530764305528959e-05, 'epoch': 1.5137085137085138}
2025-05-15 18:40:55,159 - TaskScriptRunner - INFO - {'loss': 7.3535, 'grad_norm': 1.8671875, 'learning_rate': 7.363823818967824e-05, 'epoch': 1.5194805194805194}
2025-05-15 18:40:56,202 - TaskScriptRunner - INFO - {'loss': 7.3843, 'grad_norm': 1.78125, 'learning_rate': 7.198434330904388e-05, 'epoch': 1.5252525252525253}
2025-05-15 18:40:57,241 - TaskScriptRunner - INFO - {'loss': 7.353, 'grad_norm': 1.71875, 'learning_rate': 7.034610386376342e-05, 'epoch': 1.531024531024531}
2025-05-15 18:40:58,279 - TaskScriptRunner - INFO - {'loss': 7.3932, 'grad_norm': 1.6328125, 'learning_rate': 6.872366392741017e-05, 'epoch': 1.5367965367965368}
2025-05-15 18:40:59,319 - TaskScriptRunner - INFO - {'loss': 7.4042, 'grad_norm': 1.7421875, 'learning_rate': 6.711716618408281e-05, 'epoch': 1.5425685425685427}
2025-05-15 18:41:00,359 - TaskScriptRunner - INFO - {'loss': 7.3581, 'grad_norm': 1.7265625, 'learning_rate': 6.552675191585741e-05, 'epoch': 1.5483405483405484}
2025-05-15 18:41:01,400 - TaskScriptRunner - INFO - {'loss': 7.3909, 'grad_norm': 1.984375, 'learning_rate': 6.395256099036278e-05, 'epoch': 1.554112554112554}
2025-05-15 18:41:02,439 - TaskScriptRunner - INFO - {'loss': 7.4146, 'grad_norm': 1.734375, 'learning_rate': 6.239473184847941e-05, 'epoch': 1.5598845598845599}
2025-05-15 18:41:03,478 - TaskScriptRunner - INFO - {'loss': 7.3862, 'grad_norm': 1.734375, 'learning_rate': 6.085340149216467e-05, 'epoch': 1.5656565656565657}
2025-05-15 18:41:04,518 - TaskScriptRunner - INFO - {'loss': 7.3928, 'grad_norm': 1.7421875, 'learning_rate': 5.9328705472404546e-05, 'epoch': 1.5714285714285714}
2025-05-15 18:41:05,556 - TaskScriptRunner - INFO - {'loss': 7.4358, 'grad_norm': 1.6875, 'learning_rate': 5.7820777877292065e-05, 'epoch': 1.577200577200577}
2025-05-15 18:41:06,594 - TaskScriptRunner - INFO - {'loss': 7.3356, 'grad_norm': 1.8046875, 'learning_rate': 5.632975132023585e-05, 'epoch': 1.582972582972583}
2025-05-15 18:41:07,636 - TaskScriptRunner - INFO - {'loss': 7.3872, 'grad_norm': 1.890625, 'learning_rate': 5.485575692829678e-05, 'epoch': 1.5887445887445888}
2025-05-15 18:41:08,675 - TaskScriptRunner - INFO - {'loss': 7.2702, 'grad_norm': 1.90625, 'learning_rate': 5.339892433065654e-05, 'epoch': 1.5945165945165947}
2025-05-15 18:41:09,716 - TaskScriptRunner - INFO - {'loss': 7.4592, 'grad_norm': 1.8671875, 'learning_rate': 5.195938164721767e-05, 'epoch': 1.6002886002886003}
2025-05-15 18:41:10,765 - TaskScriptRunner - INFO - {'loss': 7.3226, 'grad_norm': 1.5390625, 'learning_rate': 5.0537255477335644e-05, 'epoch': 1.606060606060606}
2025-05-15 18:41:11,806 - TaskScriptRunner - INFO - {'loss': 7.2895, 'grad_norm': 2.125, 'learning_rate': 4.913267088868553e-05, 'epoch': 1.6118326118326118}
2025-05-15 18:41:12,847 - TaskScriptRunner - INFO - {'loss': 7.3925, 'grad_norm': 1.796875, 'learning_rate': 4.7745751406263163e-05, 'epoch': 1.6176046176046177}
2025-05-15 18:41:13,887 - TaskScriptRunner - INFO - {'loss': 7.3546, 'grad_norm': 1.8046875, 'learning_rate': 4.637661900152143e-05, 'epoch': 1.6233766233766234}
2025-05-15 18:41:14,929 - TaskScriptRunner - INFO - {'loss': 7.4133, 'grad_norm': 1.8046875, 'learning_rate': 4.5025394081643854e-05, 'epoch': 1.629148629148629}
2025-05-15 18:41:15,971 - TaskScriptRunner - INFO - {'loss': 7.264, 'grad_norm': 1.59375, 'learning_rate': 4.3692195478955615e-05, 'epoch': 1.6349206349206349}
2025-05-15 18:41:17,010 - TaskScriptRunner - INFO - {'loss': 7.3105, 'grad_norm': 1.640625, 'learning_rate': 4.237714044047258e-05, 'epoch': 1.6406926406926408}
2025-05-15 18:41:18,050 - TaskScriptRunner - INFO - {'loss': 7.3165, 'grad_norm': 1.8359375, 'learning_rate': 4.108034461759036e-05, 'epoch': 1.6464646464646466}
2025-05-15 18:41:19,096 - TaskScriptRunner - INFO - {'loss': 7.3313, 'grad_norm': 1.9296875, 'learning_rate': 3.980192205591354e-05, 'epoch': 1.6522366522366523}
2025-05-15 18:41:20,136 - TaskScriptRunner - INFO - {'loss': 7.3548, 'grad_norm': 1.734375, 'learning_rate': 3.8541985185225645e-05, 'epoch': 1.658008658008658}
2025-05-15 18:41:21,186 - TaskScriptRunner - INFO - {'loss': 7.3359, 'grad_norm': 1.71875, 'learning_rate': 3.7300644809602155e-05, 'epoch': 1.6637806637806638}
2025-05-15 18:41:22,227 - TaskScriptRunner - INFO - {'loss': 7.3164, 'grad_norm': 1.640625, 'learning_rate': 3.6078010097665206e-05, 'epoch': 1.6695526695526697}
2025-05-15 18:41:23,268 - TaskScriptRunner - INFO - {'loss': 7.4107, 'grad_norm': 1.6328125, 'learning_rate': 3.487418857298366e-05, 'epoch': 1.6753246753246753}
2025-05-15 18:41:24,316 - TaskScriptRunner - INFO - {'loss': 7.351, 'grad_norm': 1.5625, 'learning_rate': 3.368928610461652e-05, 'epoch': 1.681096681096681}
2025-05-15 18:41:25,357 - TaskScriptRunner - INFO - {'loss': 7.341, 'grad_norm': 1.6484375, 'learning_rate': 3.2523406897802446e-05, 'epoch': 1.6868686868686869}
2025-05-15 18:41:26,397 - TaskScriptRunner - INFO - {'loss': 7.3897, 'grad_norm': 1.84375, 'learning_rate': 3.1376653484795545e-05, 'epoch': 1.6926406926406927}
2025-05-15 18:41:27,437 - TaskScriptRunner - INFO - {'loss': 7.3691, 'grad_norm': 1.6328125, 'learning_rate': 3.0249126715848258e-05, 'epoch': 1.6984126984126984}
2025-05-15 18:41:28,476 - TaskScriptRunner - INFO - {'loss': 7.3357, 'grad_norm': 1.578125, 'learning_rate': 2.9140925750342357e-05, 'epoch': 1.704184704184704}
2025-05-15 18:41:29,516 - TaskScriptRunner - INFO - {'loss': 7.3513, 'grad_norm': 1.6328125, 'learning_rate': 2.8052148048068076e-05, 'epoch': 1.70995670995671}
2025-05-15 18:41:30,558 - TaskScriptRunner - INFO - {'loss': 7.3226, 'grad_norm': 1.6328125, 'learning_rate': 2.698288936065338e-05, 'epoch': 1.7157287157287158}
2025-05-15 18:41:31,598 - TaskScriptRunner - INFO - {'loss': 7.3975, 'grad_norm': 1.375, 'learning_rate': 2.593324372314318e-05, 'epoch': 1.7215007215007216}
2025-05-15 18:41:32,635 - TaskScriptRunner - INFO - {'loss': 7.3231, 'grad_norm': 1.5078125, 'learning_rate': 2.4903303445729276e-05, 'epoch': 1.7272727272727273}
2025-05-15 18:41:33,674 - TaskScriptRunner - INFO - {'loss': 7.3581, 'grad_norm': 1.4765625, 'learning_rate': 2.3893159105632362e-05, 'epoch': 1.733044733044733}
2025-05-15 18:41:34,713 - TaskScriptRunner - INFO - {'loss': 7.3666, 'grad_norm': 1.5859375, 'learning_rate': 2.2902899539136435e-05, 'epoch': 1.7388167388167388}
2025-05-15 18:41:35,759 - TaskScriptRunner - INFO - {'loss': 7.3034, 'grad_norm': 1.625, 'learning_rate': 2.1932611833775846e-05, 'epoch': 1.7445887445887447}
2025-05-15 18:41:36,797 - TaskScriptRunner - INFO - {'loss': 7.3257, 'grad_norm': 1.6484375, 'learning_rate': 2.0982381320676647e-05, 'epoch': 1.7503607503607503}
2025-05-15 18:41:37,834 - TaskScriptRunner - INFO - {'loss': 7.3548, 'grad_norm': 1.5078125, 'learning_rate': 2.0052291567052295e-05, 'epoch': 1.756132756132756}
2025-05-15 18:41:38,873 - TaskScriptRunner - INFO - {'loss': 7.3287, 'grad_norm': 1.5, 'learning_rate': 1.9142424368854162e-05, 'epoch': 1.7619047619047619}
2025-05-15 18:41:39,912 - TaskScriptRunner - INFO - {'loss': 7.3127, 'grad_norm': 1.53125, 'learning_rate': 1.825285974357835e-05, 'epoch': 1.7676767676767677}
2025-05-15 18:41:40,950 - TaskScriptRunner - INFO - {'loss': 7.331, 'grad_norm': 1.671875, 'learning_rate': 1.738367592322837e-05, 'epoch': 1.7734487734487736}
2025-05-15 18:41:41,989 - TaskScriptRunner - INFO - {'loss': 7.3318, 'grad_norm': 1.5078125, 'learning_rate': 1.6534949347435185e-05, 'epoch': 1.7792207792207793}
2025-05-15 18:41:43,028 - TaskScriptRunner - INFO - {'loss': 7.3386, 'grad_norm': 1.5, 'learning_rate': 1.5706754656734908e-05, 'epoch': 1.784992784992785}
2025-05-15 18:41:44,071 - TaskScriptRunner - INFO - {'loss': 7.35, 'grad_norm': 1.453125, 'learning_rate': 1.4899164686004413e-05, 'epoch': 1.7907647907647908}
2025-05-15 18:41:45,110 - TaskScriptRunner - INFO - {'loss': 7.403, 'grad_norm': 1.4765625, 'learning_rate': 1.4112250458055975e-05, 'epoch': 1.7965367965367967}
2025-05-15 18:41:46,151 - TaskScriptRunner - INFO - {'loss': 7.264, 'grad_norm': 1.6328125, 'learning_rate': 1.3346081177391473e-05, 'epoch': 1.8023088023088023}
2025-05-15 18:41:47,189 - TaskScriptRunner - INFO - {'loss': 7.2868, 'grad_norm': 1.578125, 'learning_rate': 1.2600724224115845e-05, 'epoch': 1.808080808080808}
2025-05-15 18:41:48,227 - TaskScriptRunner - INFO - {'loss': 7.3578, 'grad_norm': 1.6171875, 'learning_rate': 1.1876245148011694e-05, 'epoch': 1.8138528138528138}
2025-05-15 18:41:49,264 - TaskScriptRunner - INFO - {'loss': 7.3388, 'grad_norm': 1.4296875, 'learning_rate': 1.1172707662774561e-05, 'epoch': 1.8196248196248197}
2025-05-15 18:41:50,302 - TaskScriptRunner - INFO - {'loss': 7.2943, 'grad_norm': 1.484375, 'learning_rate': 1.0490173640409468e-05, 'epoch': 1.8253968253968254}
2025-05-15 18:41:51,340 - TaskScriptRunner - INFO - {'loss': 7.3905, 'grad_norm': 1.6328125, 'learning_rate': 9.828703105789983e-06, 'epoch': 1.8311688311688312}
2025-05-15 18:41:52,380 - TaskScriptRunner - INFO - {'loss': 7.3607, 'grad_norm': 1.5390625, 'learning_rate': 9.188354231378899e-06, 'epoch': 1.8369408369408369}
2025-05-15 18:41:53,419 - TaskScriptRunner - INFO - {'loss': 7.338, 'grad_norm': 1.40625, 'learning_rate': 8.569183332112846e-06, 'epoch': 1.8427128427128427}
2025-05-15 18:41:54,456 - TaskScriptRunner - INFO - {'loss': 7.3615, 'grad_norm': 1.5078125, 'learning_rate': 7.971244860449395e-06, 'epoch': 1.8484848484848486}
2025-05-15 18:41:55,493 - TaskScriptRunner - INFO - {'loss': 7.3794, 'grad_norm': 1.515625, 'learning_rate': 7.394591401578166e-06, 'epoch': 1.8542568542568543}
2025-05-15 18:41:56,531 - TaskScriptRunner - INFO - {'loss': 7.3836, 'grad_norm': 1.484375, 'learning_rate': 6.839273668796747e-06, 'epoch': 1.86002886002886}
2025-05-15 18:41:57,570 - TaskScriptRunner - INFO - {'loss': 7.3192, 'grad_norm': 1.4453125, 'learning_rate': 6.3053404990502384e-06, 'epoch': 1.8658008658008658}
2025-05-15 18:41:58,612 - TaskScriptRunner - INFO - {'loss': 7.3722, 'grad_norm': 1.5546875, 'learning_rate': 5.7928388486366555e-06, 'epoch': 1.8715728715728717}
2025-05-15 18:41:59,650 - TaskScriptRunner - INFO - {'loss': 7.2723, 'grad_norm': 1.5234375, 'learning_rate': 5.301813789077264e-06, 'epoch': 1.8773448773448773}
2025-05-15 18:42:00,690 - TaskScriptRunner - INFO - {'loss': 7.2657, 'grad_norm': 1.5625, 'learning_rate': 4.832308503152832e-06, 'epoch': 1.883116883116883}
2025-05-15 18:42:01,729 - TaskScriptRunner - INFO - {'loss': 7.3382, 'grad_norm': 1.7109375, 'learning_rate': 4.384364281105973e-06, 'epoch': 1.8888888888888888}
2025-05-15 18:42:02,766 - TaskScriptRunner - INFO - {'loss': 7.3453, 'grad_norm': 1.4765625, 'learning_rate': 3.9580205170098856e-06, 'epoch': 1.8946608946608947}
2025-05-15 18:42:03,804 - TaskScriptRunner - INFO - {'loss': 7.3368, 'grad_norm': 1.3828125, 'learning_rate': 3.553314705303845e-06, 'epoch': 1.9004329004329006}
2025-05-15 18:42:04,844 - TaskScriptRunner - INFO - {'loss': 7.3414, 'grad_norm': 1.6171875, 'learning_rate': 3.1702824374959527e-06, 'epoch': 1.9062049062049062}
2025-05-15 18:42:05,885 - TaskScriptRunner - INFO - {'loss': 7.2911, 'grad_norm': 1.40625, 'learning_rate': 2.8089573990328076e-06, 'epoch': 1.9119769119769119}
2025-05-15 18:42:06,925 - TaskScriptRunner - INFO - {'loss': 7.3272, 'grad_norm': 1.515625, 'learning_rate': 2.469371366337264e-06, 'epoch': 1.9177489177489178}
2025-05-15 18:42:07,963 - TaskScriptRunner - INFO - {'loss': 7.3588, 'grad_norm': 1.53125, 'learning_rate': 2.1515542040138335e-06, 'epoch': 1.9235209235209236}
2025-05-15 18:42:09,000 - TaskScriptRunner - INFO - {'loss': 7.355, 'grad_norm': 1.4453125, 'learning_rate': 1.8555338622222583e-06, 'epoch': 1.9292929292929293}
2025-05-15 18:42:10,041 - TaskScriptRunner - INFO - {'loss': 7.2745, 'grad_norm': 1.578125, 'learning_rate': 1.581336374219422e-06, 'epoch': 1.935064935064935}
2025-05-15 18:42:11,087 - TaskScriptRunner - INFO - {'loss': 7.3525, 'grad_norm': 1.46875, 'learning_rate': 1.3289858540699584e-06, 'epoch': 1.9408369408369408}
2025-05-15 18:42:12,126 - TaskScriptRunner - INFO - {'loss': 7.3226, 'grad_norm': 1.5703125, 'learning_rate': 1.0985044945254763e-06, 'epoch': 1.9466089466089467}
2025-05-15 18:42:13,163 - TaskScriptRunner - INFO - {'loss': 7.2717, 'grad_norm': 1.46875, 'learning_rate': 8.899125650729256e-07, 'epoch': 1.9523809523809523}
2025-05-15 18:42:14,203 - TaskScriptRunner - INFO - {'loss': 7.332, 'grad_norm': 1.3046875, 'learning_rate': 7.032284101518849e-07, 'epoch': 1.9581529581529582}
2025-05-15 18:42:15,243 - TaskScriptRunner - INFO - {'loss': 7.3699, 'grad_norm': 1.4140625, 'learning_rate': 5.384684475414625e-07, 'epoch': 1.9639249639249639}
2025-05-15 18:42:16,284 - TaskScriptRunner - INFO - {'loss': 7.331, 'grad_norm': 1.3828125, 'learning_rate': 3.9564716691622984e-07, 'epoch': 1.9696969696969697}
2025-05-15 18:42:17,330 - TaskScriptRunner - INFO - {'loss': 7.3776, 'grad_norm': 1.625, 'learning_rate': 2.7477712857215677e-07, 'epoch': 1.9754689754689756}
2025-05-15 18:42:18,370 - TaskScriptRunner - INFO - {'loss': 7.377, 'grad_norm': 1.5, 'learning_rate': 1.7586896232180128e-07, 'epoch': 1.9812409812409812}
2025-05-15 18:42:19,409 - TaskScriptRunner - INFO - {'loss': 7.2944, 'grad_norm': 1.671875, 'learning_rate': 9.89313665596403e-08, 'epoch': 1.987012987012987}
2025-05-15 18:42:20,451 - TaskScriptRunner - INFO - {'loss': 7.3404, 'grad_norm': 1.53125, 'learning_rate': 4.3971107497042806e-08, 'epoch': 1.9927849927849928}
2025-05-15 18:42:21,495 - TaskScriptRunner - INFO - {'loss': 7.3742, 'grad_norm': 1.6484375, 'learning_rate': 1.0993018567162505e-08, 'epoch': 1.9985569985569986}
2025-05-15 18:42:38,264 - TaskScriptRunner - INFO - {'train_runtime': 197.3084, 'train_samples_per_second': 70.245, 'train_steps_per_second': 1.754, 'train_loss': 3.69438292387593, 'epoch': 1.9985569985569986}
2025-05-15 18:42:40,031 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Running quantization...
2025-05-15 18:42:40,032 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Running quantization on 179 variables
2025-05-15 18:42:46,666 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Quantized 179/179 params. Before quantization: 5664.51 MB. After quantization: 2832.25 MB with meta: 0.00 MB.
2025-05-15 18:42:46,668 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=d21d2d15-49a2-47ff-8ae2-c9a379538f89] - Quantized from {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float32', 'model.model.layers.0.self_attn.k_norm.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float32', 'model.model.layers.1.self_attn.k_norm.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float32', 'model.model.layers.2.self_attn.k_norm.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float32', 'model.model.layers.3.self_attn.k_norm.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float32', 'model.model.layers.4.self_attn.k_norm.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float32', 'model.model.layers.5.self_attn.k_norm.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float32', 'model.model.layers.6.self_attn.k_norm.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float32', 'model.model.layers.7.self_attn.k_norm.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float32', 'model.model.layers.8.self_attn.k_norm.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float32', 'model.model.layers.9.self_attn.k_norm.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float32', 'model.model.layers.10.self_attn.k_norm.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float32', 'model.model.layers.11.self_attn.k_norm.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float32', 'model.model.layers.12.self_attn.k_norm.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float32', 'model.model.layers.13.self_attn.k_norm.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float32', 'model.model.layers.14.self_attn.k_norm.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float32', 'model.model.layers.15.self_attn.k_norm.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'} to float16
2025-05-15 18:50:30,114 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Running dequantization...
2025-05-15 18:50:30,115 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Running dequantization on 179 variables
2025-05-15 18:50:30,116 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.embed_tokens.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,117 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.0.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,117 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.0.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,118 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.0.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,119 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.0.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,119 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.0.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,120 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.0.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,120 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.0.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,121 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.0.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,122 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.0.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,122 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.0.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,123 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.0.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,123 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.1.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,124 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.1.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,125 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.1.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,125 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.1.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,126 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.1.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,126 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.1.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,127 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.1.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,127 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.1.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,128 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.1.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,129 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.1.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,129 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.1.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,130 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.2.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,130 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.2.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,131 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.2.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,131 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.2.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,132 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.2.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,133 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.2.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,133 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.2.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,134 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.2.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,169 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.2.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,170 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.2.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,171 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.3.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,172 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.3.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,172 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.3.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,182 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.3.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,182 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.3.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,288 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.3.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,289 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.3.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,332 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.4.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,333 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.4.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,470 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.4.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,471 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.4.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,513 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.5.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,514 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.5.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,650 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.5.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,651 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.5.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,693 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.6.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,694 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.6.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,830 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.6.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,831 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.6.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,871 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.7.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:30,872 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.7.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,009 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.7.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,010 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.7.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,049 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.8.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,050 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.8.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,186 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.8.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,187 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.8.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,229 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.9.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,230 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.9.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,367 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.9.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,368 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.9.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,410 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.10.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,410 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.10.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,547 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.10.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,548 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.10.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,590 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.11.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,591 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.11.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,727 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.11.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,728 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.11.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,770 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.12.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,771 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.12.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,907 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.12.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,908 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.12.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,949 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.13.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:31,950 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.13.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:32,088 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.13.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:32,089 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.13.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:32,130 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.14.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:32,131 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.14.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:32,269 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.14.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:32,270 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.14.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:32,311 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.15.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:32,312 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.15.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:32,450 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.15.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:32,451 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.layers.15.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:32,452 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Skipping dequantization for model.model.norm.weight, quantization bit float16 >= source data bit float16
2025-05-15 18:50:33,002 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Dequantized 90/179 params. Before dequantization: 2064.00 MB with meta: 0.00 MB. After dequantization: 4128.00 MB.
2025-05-15 18:50:33,005 - ModelDequantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Dequantized back to {'model.model.embed_tokens.weight': 'float16', 'model.model.layers.0.self_attn.q_proj.weight': 'float16', 'model.model.layers.0.self_attn.k_proj.weight': 'float16', 'model.model.layers.0.self_attn.v_proj.weight': 'float16', 'model.model.layers.0.self_attn.o_proj.weight': 'float16', 'model.model.layers.0.self_attn.q_norm.weight': 'float16', 'model.model.layers.0.self_attn.k_norm.weight': 'float16', 'model.model.layers.0.mlp.gate_proj.weight': 'float16', 'model.model.layers.0.mlp.up_proj.weight': 'float16', 'model.model.layers.0.mlp.down_proj.weight': 'float16', 'model.model.layers.0.post_attention_layernorm.weight': 'float16', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.1.self_attn.q_proj.weight': 'float16', 'model.model.layers.1.self_attn.k_proj.weight': 'float16', 'model.model.layers.1.self_attn.v_proj.weight': 'float16', 'model.model.layers.1.self_attn.o_proj.weight': 'float16', 'model.model.layers.1.self_attn.q_norm.weight': 'float16', 'model.model.layers.1.self_attn.k_norm.weight': 'float16', 'model.model.layers.1.mlp.gate_proj.weight': 'float16', 'model.model.layers.1.mlp.up_proj.weight': 'float16', 'model.model.layers.1.mlp.down_proj.weight': 'float16', 'model.model.layers.1.post_attention_layernorm.weight': 'float16', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.2.self_attn.q_proj.weight': 'float16', 'model.model.layers.2.self_attn.k_proj.weight': 'float16', 'model.model.layers.2.self_attn.v_proj.weight': 'float16', 'model.model.layers.2.self_attn.o_proj.weight': 'float16', 'model.model.layers.2.self_attn.q_norm.weight': 'float16', 'model.model.layers.2.self_attn.k_norm.weight': 'float16', 'model.model.layers.2.mlp.gate_proj.weight': 'float16', 'model.model.layers.2.mlp.up_proj.weight': 'float16', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float16', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.3.self_attn.q_proj.weight': 'float16', 'model.model.layers.3.self_attn.k_proj.weight': 'float16', 'model.model.layers.3.self_attn.v_proj.weight': 'float16', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float16', 'model.model.layers.3.self_attn.k_norm.weight': 'float16', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float16', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float16', 'model.model.layers.4.self_attn.k_norm.weight': 'float16', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float16', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float16', 'model.model.layers.5.self_attn.k_norm.weight': 'float16', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float16', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float16', 'model.model.layers.6.self_attn.k_norm.weight': 'float16', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float16', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float16', 'model.model.layers.7.self_attn.k_norm.weight': 'float16', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float16', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float16', 'model.model.layers.8.self_attn.k_norm.weight': 'float16', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float16', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float16', 'model.model.layers.9.self_attn.k_norm.weight': 'float16', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float16', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float16', 'model.model.layers.10.self_attn.k_norm.weight': 'float16', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float16', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float16', 'model.model.layers.11.self_attn.k_norm.weight': 'float16', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float16', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float16', 'model.model.layers.12.self_attn.k_norm.weight': 'float16', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float16', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float16', 'model.model.layers.13.self_attn.k_norm.weight': 'float16', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float16', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float16', 'model.model.layers.14.self_attn.k_norm.weight': 'float16', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float16', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float16', 'model.model.layers.15.self_attn.k_norm.weight': 'float16', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float16', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float16', 'model.model.norm.weight': 'float16', 'model.lm_head.weight': 'float32'}
2025-05-15 18:50:33,007 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - execute for task (train)
2025-05-15 18:50:33,010 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - send data to peer
2025-05-15 18:50:33,010 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - sending payload to peer
2025-05-15 18:50:33,012 - PTInProcessClientAPIExecutor - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Waiting for result from peer
2025-05-15 18:50:33,181 - TaskScriptRunner - INFO - --- federated round 2 ---
2025-05-15 18:50:33,978 - TaskScriptRunner - INFO - {'eval_loss': 8.167317390441895, 'eval_model_preparation_time': 0.0064, 'eval_runtime': 0.3264, 'eval_samples_per_second': 214.442, 'eval_steps_per_second': 27.571, 'epoch': 1.9985569985569986}
2025-05-15 18:50:33,978 - TaskScriptRunner - INFO - eval metrics: {'eval_loss': 8.167317390441895, 'eval_model_preparation_time': 0.0064, 'eval_runtime': 0.3264, 'eval_samples_per_second': 214.442, 'eval_steps_per_second': 27.571, 'epoch': 1.9985569985569986, 'perplexity': 3523.878083640604}
2025-05-15 18:50:51,244 - TaskScriptRunner - INFO - RNG state successfully loaded
2025-05-15 18:50:52,420 - TaskScriptRunner - INFO - {'loss': 8.1356, 'grad_norm': 6.8125, 'learning_rate': 0.0, 'epoch': 2.005772005772006}
2025-05-15 18:50:53,534 - TaskScriptRunner - INFO - {'loss': 8.1108, 'grad_norm': 6.59375, 'learning_rate': 0.00013090475294165788, 'epoch': 2.0115440115440117}
2025-05-15 18:50:54,593 - TaskScriptRunner - INFO - {'loss': 7.9734, 'grad_norm': 3.515625, 'learning_rate': 0.00012953421662274264, 'epoch': 2.017316017316017}
2025-05-15 18:50:55,651 - TaskScriptRunner - INFO - {'loss': 7.8885, 'grad_norm': 3.53125, 'learning_rate': 0.0001281683795270203, 'epoch': 2.023088023088023}
2025-05-15 18:50:56,740 - TaskScriptRunner - INFO - {'loss': 7.8462, 'grad_norm': 5.3125, 'learning_rate': 0.0001268072949341293, 'epoch': 2.028860028860029}
2025-05-15 18:50:57,834 - TaskScriptRunner - INFO - {'loss': 7.8353, 'grad_norm': 5.75, 'learning_rate': 0.0001254510159383185, 'epoch': 2.034632034632035}
2025-05-15 18:50:58,923 - TaskScriptRunner - INFO - {'loss': 7.7548, 'grad_norm': 5.125, 'learning_rate': 0.0001240995954463761, 'epoch': 2.04040404040404}
2025-05-15 18:51:00,017 - TaskScriptRunner - INFO - {'loss': 7.6661, 'grad_norm': 4.03125, 'learning_rate': 0.00012275308617556643, 'epoch': 2.046176046176046}
2025-05-15 18:51:01,099 - TaskScriptRunner - INFO - {'loss': 7.616, 'grad_norm': 3.5625, 'learning_rate': 0.00012141154065157281, 'epoch': 2.051948051948052}
2025-05-15 18:51:02,164 - TaskScriptRunner - INFO - {'loss': 7.6385, 'grad_norm': 3.4375, 'learning_rate': 0.00012007501120644901, 'epoch': 2.057720057720058}
2025-05-15 18:51:03,218 - TaskScriptRunner - INFO - {'loss': 7.5805, 'grad_norm': 3.109375, 'learning_rate': 0.0001187435499765773, 'epoch': 2.0634920634920633}
2025-05-15 18:51:04,276 - TaskScriptRunner - INFO - {'loss': 7.5596, 'grad_norm': 2.609375, 'learning_rate': 0.00011741720890063559, 'epoch': 2.069264069264069}
2025-05-15 18:51:05,337 - TaskScriptRunner - INFO - {'loss': 7.5282, 'grad_norm': 2.84375, 'learning_rate': 0.0001160960397175705, 'epoch': 2.075036075036075}
2025-05-15 18:51:06,383 - TaskScriptRunner - INFO - {'loss': 7.5843, 'grad_norm': 2.5625, 'learning_rate': 0.00011478009396457953, 'epoch': 2.080808080808081}
2025-05-15 18:51:07,420 - TaskScriptRunner - INFO - {'loss': 7.5187, 'grad_norm': 1.9921875, 'learning_rate': 0.00011346942297510052, 'epoch': 2.0865800865800868}
2025-05-15 18:51:08,456 - TaskScriptRunner - INFO - {'loss': 7.4363, 'grad_norm': 2.671875, 'learning_rate': 0.00011216407787680919, 'epoch': 2.092352092352092}
2025-05-15 18:51:09,497 - TaskScriptRunner - INFO - {'loss': 7.4415, 'grad_norm': 3.015625, 'learning_rate': 0.00011086410958962481, 'epoch': 2.098124098124098}
2025-05-15 18:51:10,534 - TaskScriptRunner - INFO - {'loss': 7.4549, 'grad_norm': 2.375, 'learning_rate': 0.00010956956882372377, 'epoch': 2.103896103896104}
2025-05-15 18:51:11,582 - TaskScriptRunner - INFO - {'loss': 7.4471, 'grad_norm': 1.8671875, 'learning_rate': 0.00010828050607756152, 'epoch': 2.10966810966811}
2025-05-15 18:51:12,658 - TaskScriptRunner - INFO - {'loss': 7.3998, 'grad_norm': 2.015625, 'learning_rate': 0.00010699697163590256, 'epoch': 2.1154401154401152}
2025-05-15 18:51:13,730 - TaskScriptRunner - INFO - {'loss': 7.3993, 'grad_norm': 2.09375, 'learning_rate': 0.00010571901556785906, 'epoch': 2.121212121212121}
2025-05-15 18:51:14,803 - TaskScriptRunner - INFO - {'loss': 7.4536, 'grad_norm': 2.34375, 'learning_rate': 0.00010444668772493762, 'epoch': 2.126984126984127}
2025-05-15 18:51:15,870 - TaskScriptRunner - INFO - {'loss': 7.3486, 'grad_norm': 1.7578125, 'learning_rate': 0.00010318003773909456, 'epoch': 2.132756132756133}
2025-05-15 18:51:16,939 - TaskScriptRunner - INFO - {'loss': 7.3766, 'grad_norm': 1.5859375, 'learning_rate': 0.00010191911502080026, 'epoch': 2.1385281385281387}
2025-05-15 18:51:18,032 - TaskScriptRunner - INFO - {'loss': 7.3743, 'grad_norm': 2.125, 'learning_rate': 0.00010066396875711086, 'epoch': 2.144300144300144}
2025-05-15 18:51:19,122 - TaskScriptRunner - INFO - {'loss': 7.3481, 'grad_norm': 1.9765625, 'learning_rate': 9.941464790975035e-05, 'epoch': 2.15007215007215}
2025-05-15 18:51:20,187 - TaskScriptRunner - INFO - {'loss': 7.4137, 'grad_norm': 1.6328125, 'learning_rate': 9.817120121320044e-05, 'epoch': 2.155844155844156}
2025-05-15 18:51:21,267 - TaskScriptRunner - INFO - {'loss': 7.3033, 'grad_norm': 1.859375, 'learning_rate': 9.693367717279932e-05, 'epoch': 2.1616161616161618}
2025-05-15 18:51:22,338 - TaskScriptRunner - INFO - {'loss': 7.3418, 'grad_norm': 1.8515625, 'learning_rate': 9.570212406284931e-05, 'epoch': 2.167388167388167}
2025-05-15 18:51:23,415 - TaskScriptRunner - INFO - {'loss': 7.3281, 'grad_norm': 1.6640625, 'learning_rate': 9.447658992473426e-05, 'epoch': 2.173160173160173}
2025-05-15 18:51:24,494 - TaskScriptRunner - INFO - {'loss': 7.3892, 'grad_norm': 2.03125, 'learning_rate': 9.325712256504543e-05, 'epoch': 2.178932178932179}
2025-05-15 18:51:25,567 - TaskScriptRunner - INFO - {'loss': 7.4028, 'grad_norm': 1.7578125, 'learning_rate': 9.204376955371627e-05, 'epoch': 2.184704184704185}
2025-05-15 18:51:26,638 - TaskScriptRunner - INFO - {'loss': 7.4174, 'grad_norm': 1.875, 'learning_rate': 9.083657822216681e-05, 'epoch': 2.1904761904761907}
2025-05-15 18:51:27,717 - TaskScriptRunner - INFO - {'loss': 7.3563, 'grad_norm': 1.78125, 'learning_rate': 8.963559566145762e-05, 'epoch': 2.196248196248196}
2025-05-15 18:51:28,782 - TaskScriptRunner - INFO - {'loss': 7.3044, 'grad_norm': 2.09375, 'learning_rate': 8.844086872045293e-05, 'epoch': 2.202020202020202}
2025-05-15 18:51:29,844 - TaskScriptRunner - INFO - {'loss': 7.266, 'grad_norm': 1.9609375, 'learning_rate': 8.725244400399255e-05, 'epoch': 2.207792207792208}
2025-05-15 18:51:30,901 - TaskScriptRunner - INFO - {'loss': 7.3624, 'grad_norm': 2.15625, 'learning_rate': 8.607036787107428e-05, 'epoch': 2.2135642135642137}
2025-05-15 18:51:31,944 - TaskScriptRunner - INFO - {'loss': 7.3787, 'grad_norm': 1.84375, 'learning_rate': 8.489468643304551e-05, 'epoch': 2.219336219336219}
2025-05-15 18:51:33,007 - TaskScriptRunner - INFO - {'loss': 7.3489, 'grad_norm': 2.203125, 'learning_rate': 8.37254455518043e-05, 'epoch': 2.225108225108225}
2025-05-15 18:51:34,061 - TaskScriptRunner - INFO - {'loss': 7.3041, 'grad_norm': 1.7890625, 'learning_rate': 8.256269083801052e-05, 'epoch': 2.230880230880231}
2025-05-15 18:51:35,113 - TaskScriptRunner - INFO - {'loss': 7.3886, 'grad_norm': 2.171875, 'learning_rate': 8.140646764930651e-05, 'epoch': 2.236652236652237}
2025-05-15 18:51:36,153 - TaskScriptRunner - INFO - {'loss': 7.3738, 'grad_norm': 1.921875, 'learning_rate': 8.025682108854779e-05, 'epoch': 2.242424242424242}
2025-05-15 18:51:37,190 - TaskScriptRunner - INFO - {'loss': 7.3288, 'grad_norm': 2.125, 'learning_rate': 7.911379600204368e-05, 'epoch': 2.248196248196248}
2025-05-15 18:51:38,230 - TaskScriptRunner - INFO - {'loss': 7.348, 'grad_norm': 1.90625, 'learning_rate': 7.797743697780788e-05, 'epoch': 2.253968253968254}
2025-05-15 18:51:39,270 - TaskScriptRunner - INFO - {'loss': 7.3762, 'grad_norm': 1.8046875, 'learning_rate': 7.684778834381906e-05, 'epoch': 2.25974025974026}
2025-05-15 18:51:40,308 - TaskScriptRunner - INFO - {'loss': 7.3625, 'grad_norm': 2.125, 'learning_rate': 7.572489416629183e-05, 'epoch': 2.2655122655122657}
2025-05-15 18:51:41,344 - TaskScriptRunner - INFO - {'loss': 7.3889, 'grad_norm': 2.109375, 'learning_rate': 7.460879824795768e-05, 'epoch': 2.271284271284271}
2025-05-15 18:51:42,382 - TaskScriptRunner - INFO - {'loss': 7.3027, 'grad_norm': 1.859375, 'learning_rate': 7.349954412635631e-05, 'epoch': 2.277056277056277}
2025-05-15 18:51:43,422 - TaskScriptRunner - INFO - {'loss': 7.3769, 'grad_norm': 1.8046875, 'learning_rate': 7.23971750721372e-05, 'epoch': 2.282828282828283}
2025-05-15 18:51:44,478 - TaskScriptRunner - INFO - {'loss': 7.3195, 'grad_norm': 1.953125, 'learning_rate': 7.1301734087372e-05, 'epoch': 2.2886002886002887}
2025-05-15 18:51:45,543 - TaskScriptRunner - INFO - {'loss': 7.3431, 'grad_norm': 2.078125, 'learning_rate': 7.021326390387647e-05, 'epoch': 2.2943722943722946}
2025-05-15 18:51:46,624 - TaskScriptRunner - INFO - {'loss': 7.3301, 'grad_norm': 1.8828125, 'learning_rate': 6.913180698154414e-05, 'epoch': 2.3001443001443}
2025-05-15 18:51:47,683 - TaskScriptRunner - INFO - {'loss': 7.3838, 'grad_norm': 2.046875, 'learning_rate': 6.805740550668971e-05, 'epoch': 2.305916305916306}
2025-05-15 18:51:48,742 - TaskScriptRunner - INFO - {'loss': 7.3744, 'grad_norm': 1.8828125, 'learning_rate': 6.69901013904037e-05, 'epoch': 2.311688311688312}
2025-05-15 18:51:49,800 - TaskScriptRunner - INFO - {'loss': 7.3194, 'grad_norm': 1.96875, 'learning_rate': 6.592993626691693e-05, 'epoch': 2.317460317460317}
2025-05-15 18:51:50,899 - TaskScriptRunner - INFO - {'loss': 7.325, 'grad_norm': 2.046875, 'learning_rate': 6.487695149197703e-05, 'epoch': 2.323232323232323}
2025-05-15 18:51:51,988 - TaskScriptRunner - INFO - {'loss': 7.4354, 'grad_norm': 1.828125, 'learning_rate': 6.383118814123517e-05, 'epoch': 2.329004329004329}
2025-05-15 18:51:53,054 - TaskScriptRunner - INFO - {'loss': 7.3983, 'grad_norm': 1.8984375, 'learning_rate': 6.279268700864335e-05, 'epoch': 2.334776334776335}
2025-05-15 18:51:54,161 - TaskScriptRunner - INFO - {'loss': 7.4168, 'grad_norm': 2.03125, 'learning_rate': 6.176148860486344e-05, 'epoch': 2.3405483405483407}
2025-05-15 18:51:55,280 - TaskScriptRunner - INFO - {'loss': 7.3198, 'grad_norm': 1.78125, 'learning_rate': 6.073763315568642e-05, 'epoch': 2.346320346320346}
2025-05-15 18:51:56,339 - TaskScriptRunner - INFO - {'loss': 7.3607, 'grad_norm': 1.65625, 'learning_rate': 5.972116060046415e-05, 'epoch': 2.352092352092352}
2025-05-15 18:51:57,391 - TaskScriptRunner - INFO - {'loss': 7.3622, 'grad_norm': 1.8203125, 'learning_rate': 5.871211059055037e-05, 'epoch': 2.357864357864358}
2025-05-15 18:51:58,451 - TaskScriptRunner - INFO - {'loss': 7.3243, 'grad_norm': 1.640625, 'learning_rate': 5.771052248775455e-05, 'epoch': 2.3636363636363638}
2025-05-15 18:51:59,531 - TaskScriptRunner - INFO - {'loss': 7.3511, 'grad_norm': 1.875, 'learning_rate': 5.671643536280624e-05, 'epoch': 2.3694083694083696}
2025-05-15 18:52:00,598 - TaskScriptRunner - INFO - {'loss': 7.3335, 'grad_norm': 1.6796875, 'learning_rate': 5.572988799383097e-05, 'epoch': 2.375180375180375}
2025-05-15 18:52:01,649 - TaskScriptRunner - INFO - {'loss': 7.3317, 'grad_norm': 1.828125, 'learning_rate': 5.4750918864837655e-05, 'epoch': 2.380952380952381}
2025-05-15 18:52:02,701 - TaskScriptRunner - INFO - {'loss': 7.345, 'grad_norm': 1.65625, 'learning_rate': 5.377956616421728e-05, 'epoch': 2.386724386724387}
2025-05-15 18:52:03,751 - TaskScriptRunner - INFO - {'loss': 7.3244, 'grad_norm': 1.875, 'learning_rate': 5.281586778325323e-05, 'epoch': 2.3924963924963927}
2025-05-15 18:52:04,804 - TaskScriptRunner - INFO - {'loss': 7.345, 'grad_norm': 1.90625, 'learning_rate': 5.1859861314643264e-05, 'epoch': 2.398268398268398}
2025-05-15 18:52:05,855 - TaskScriptRunner - INFO - {'loss': 7.3573, 'grad_norm': 1.6875, 'learning_rate': 5.091158405103302e-05, 'epoch': 2.404040404040404}
2025-05-15 18:52:06,907 - TaskScriptRunner - INFO - {'loss': 7.3029, 'grad_norm': 1.71875, 'learning_rate': 4.9971072983561265e-05, 'epoch': 2.40981240981241}
2025-05-15 18:52:07,959 - TaskScriptRunner - INFO - {'loss': 7.2725, 'grad_norm': 1.78125, 'learning_rate': 4.903836480041696e-05, 'epoch': 2.4155844155844157}
2025-05-15 18:52:09,033 - TaskScriptRunner - INFO - {'loss': 7.3683, 'grad_norm': 1.7265625, 'learning_rate': 4.8113495885408004e-05, 'epoch': 2.421356421356421}
2025-05-15 18:52:10,110 - TaskScriptRunner - INFO - {'loss': 7.3018, 'grad_norm': 1.7578125, 'learning_rate': 4.71965023165421e-05, 'epoch': 2.427128427128427}
2025-05-15 18:52:11,185 - TaskScriptRunner - INFO - {'loss': 7.3445, 'grad_norm': 1.703125, 'learning_rate': 4.6287419864619207e-05, 'epoch': 2.432900432900433}
2025-05-15 18:52:12,263 - TaskScriptRunner - INFO - {'loss': 7.3258, 'grad_norm': 1.6015625, 'learning_rate': 4.5386283991836506e-05, 'epoch': 2.4386724386724388}
2025-05-15 18:52:13,321 - TaskScriptRunner - INFO - {'loss': 7.3699, 'grad_norm': 1.71875, 'learning_rate': 4.449312985040443e-05, 'epoch': 2.4444444444444446}
2025-05-15 18:52:14,407 - TaskScriptRunner - INFO - {'loss': 7.3176, 'grad_norm': 1.890625, 'learning_rate': 4.360799228117615e-05, 'epoch': 2.45021645021645}
2025-05-15 18:52:15,488 - TaskScriptRunner - INFO - {'loss': 7.3556, 'grad_norm': 1.734375, 'learning_rate': 4.2730905812287915e-05, 'epoch': 2.455988455988456}
2025-05-15 18:52:16,577 - TaskScriptRunner - INFO - {'loss': 7.3462, 'grad_norm': 1.8828125, 'learning_rate': 4.18619046578127e-05, 'epoch': 2.461760461760462}
2025-05-15 18:52:17,663 - TaskScriptRunner - INFO - {'loss': 7.3487, 'grad_norm': 1.671875, 'learning_rate': 4.100102271642478e-05, 'epoch': 2.4675324675324677}
2025-05-15 18:52:18,722 - TaskScriptRunner - INFO - {'loss': 7.3398, 'grad_norm': 1.828125, 'learning_rate': 4.014829357007818e-05, 'epoch': 2.473304473304473}
2025-05-15 18:52:19,804 - TaskScriptRunner - INFO - {'loss': 7.31, 'grad_norm': 1.6171875, 'learning_rate': 3.930375048269613e-05, 'epoch': 2.479076479076479}
2025-05-15 18:52:20,857 - TaskScriptRunner - INFO - {'loss': 7.2804, 'grad_norm': 1.65625, 'learning_rate': 3.846742639887391e-05, 'epoch': 2.484848484848485}
2025-05-15 18:52:21,958 - TaskScriptRunner - INFO - {'loss': 7.2832, 'grad_norm': 1.5625, 'learning_rate': 3.7639353942593404e-05, 'epoch': 2.4906204906204907}
2025-05-15 18:52:23,025 - TaskScriptRunner - INFO - {'loss': 7.3428, 'grad_norm': 1.6875, 'learning_rate': 3.6819565415950355e-05, 'epoch': 2.496392496392496}
2025-05-15 18:52:24,102 - TaskScriptRunner - INFO - {'loss': 7.2736, 'grad_norm': 1.7890625, 'learning_rate': 3.600809279789488e-05, 'epoch': 2.502164502164502}
2025-05-15 18:52:25,179 - TaskScriptRunner - INFO - {'loss': 7.333, 'grad_norm': 1.609375, 'learning_rate': 3.5204967742983456e-05, 'epoch': 2.507936507936508}
2025-05-15 18:52:26,258 - TaskScriptRunner - INFO - {'loss': 7.2806, 'grad_norm': 1.640625, 'learning_rate': 3.4410221580144394e-05, 'epoch': 2.513708513708514}
2025-05-15 18:52:27,318 - TaskScriptRunner - INFO - {'loss': 7.2165, 'grad_norm': 1.765625, 'learning_rate': 3.362388531145544e-05, 'epoch': 2.5194805194805197}
2025-05-15 18:52:28,375 - TaskScriptRunner - INFO - {'loss': 7.3242, 'grad_norm': 1.640625, 'learning_rate': 3.284598961093491e-05, 'epoch': 2.525252525252525}
2025-05-15 18:52:29,437 - TaskScriptRunner - INFO - {'loss': 7.3048, 'grad_norm': 1.6796875, 'learning_rate': 3.20765648233447e-05, 'epoch': 2.531024531024531}
2025-05-15 18:52:30,492 - TaskScriptRunner - INFO - {'loss': 7.307, 'grad_norm': 1.625, 'learning_rate': 3.131564096300679e-05, 'epoch': 2.536796536796537}
2025-05-15 18:52:31,545 - TaskScriptRunner - INFO - {'loss': 7.3535, 'grad_norm': 1.5859375, 'learning_rate': 3.056324771263233e-05, 'epoch': 2.5425685425685427}
2025-05-15 18:52:32,615 - TaskScriptRunner - INFO - {'loss': 7.2594, 'grad_norm': 1.6875, 'learning_rate': 2.9819414422163792e-05, 'epoch': 2.5483405483405486}
2025-05-15 18:52:33,701 - TaskScriptRunner - INFO - {'loss': 7.361, 'grad_norm': 1.890625, 'learning_rate': 2.9084170107630064e-05, 'epoch': 2.554112554112554}
2025-05-15 18:52:34,792 - TaskScriptRunner - INFO - {'loss': 7.3175, 'grad_norm': 1.71875, 'learning_rate': 2.8357543450014566e-05, 'epoch': 2.55988455988456}
2025-05-15 18:52:35,873 - TaskScriptRunner - INFO - {'loss': 7.2926, 'grad_norm': 1.5859375, 'learning_rate': 2.763956279413643e-05, 'epoch': 2.5656565656565657}
2025-05-15 18:52:36,954 - TaskScriptRunner - INFO - {'loss': 7.3337, 'grad_norm': 1.7109375, 'learning_rate': 2.6930256147544823e-05, 'epoch': 2.571428571428571}
2025-05-15 18:52:38,035 - TaskScriptRunner - INFO - {'loss': 7.2869, 'grad_norm': 1.7421875, 'learning_rate': 2.6229651179426383e-05, 'epoch': 2.577200577200577}
2025-05-15 18:52:39,286 - TaskScriptRunner - INFO - {'loss': 7.3315, 'grad_norm': 1.6953125, 'learning_rate': 2.553777521952591e-05, 'epoch': 2.582972582972583}
2025-05-15 18:52:40,383 - TaskScriptRunner - INFO - {'loss': 7.3513, 'grad_norm': 1.640625, 'learning_rate': 2.4854655257080193e-05, 'epoch': 2.588744588744589}
2025-05-15 18:52:41,450 - TaskScriptRunner - INFO - {'loss': 7.3528, 'grad_norm': 1.4453125, 'learning_rate': 2.4180317939765355e-05, 'epoch': 2.5945165945165947}
2025-05-15 18:52:42,503 - TaskScriptRunner - INFO - {'loss': 7.3207, 'grad_norm': 1.5703125, 'learning_rate': 2.3514789572657126e-05, 'epoch': 2.6002886002886}
2025-05-15 18:52:43,604 - TaskScriptRunner - INFO - {'loss': 7.2812, 'grad_norm': 1.5859375, 'learning_rate': 2.285809611720488e-05, 'epoch': 2.606060606060606}
2025-05-15 18:52:44,669 - TaskScriptRunner - INFO - {'loss': 7.3321, 'grad_norm': 1.578125, 'learning_rate': 2.221026319021896e-05, 'epoch': 2.611832611832612}
2025-05-15 18:52:45,735 - TaskScriptRunner - INFO - {'loss': 7.2548, 'grad_norm': 1.578125, 'learning_rate': 2.1571316062871242e-05, 'epoch': 2.6176046176046177}
2025-05-15 18:52:46,800 - TaskScriptRunner - INFO - {'loss': 7.3202, 'grad_norm': 1.8046875, 'learning_rate': 2.0941279659709295e-05, 'epoch': 2.6233766233766236}
2025-05-15 18:52:47,880 - TaskScriptRunner - INFO - {'loss': 7.3014, 'grad_norm': 1.75, 'learning_rate': 2.032017855768431e-05, 'epoch': 2.629148629148629}
2025-05-15 18:52:48,955 - TaskScriptRunner - INFO - {'loss': 7.2923, 'grad_norm': 1.78125, 'learning_rate': 1.9708036985192356e-05, 'epoch': 2.634920634920635}
2025-05-15 18:52:50,013 - TaskScriptRunner - INFO - {'loss': 7.2865, 'grad_norm': 1.5859375, 'learning_rate': 1.9104878821129156e-05, 'epoch': 2.6406926406926408}
2025-05-15 18:52:51,071 - TaskScriptRunner - INFO - {'loss': 7.3449, 'grad_norm': 1.5703125, 'learning_rate': 1.8510727593958472e-05, 'epoch': 2.6464646464646466}
2025-05-15 18:52:52,132 - TaskScriptRunner - INFO - {'loss': 7.296, 'grad_norm': 1.6640625, 'learning_rate': 1.7925606480794637e-05, 'epoch': 2.6522366522366525}
2025-05-15 18:52:53,235 - TaskScriptRunner - INFO - {'loss': 7.2598, 'grad_norm': 1.6953125, 'learning_rate': 1.7349538306498212e-05, 'epoch': 2.658008658008658}
2025-05-15 18:52:54,365 - TaskScriptRunner - INFO - {'loss': 7.3797, 'grad_norm': 1.625, 'learning_rate': 1.678254554278566e-05, 'epoch': 2.663780663780664}
2025-05-15 18:52:55,424 - TaskScriptRunner - INFO - {'loss': 7.2302, 'grad_norm': 1.8125, 'learning_rate': 1.6224650307352594e-05, 'epoch': 2.6695526695526697}
2025-05-15 18:52:56,478 - TaskScriptRunner - INFO - {'loss': 7.3868, 'grad_norm': 1.5625, 'learning_rate': 1.5675874363011462e-05, 'epoch': 2.675324675324675}
2025-05-15 18:52:57,563 - TaskScriptRunner - INFO - {'loss': 7.2577, 'grad_norm': 1.5390625, 'learning_rate': 1.5136239116842033e-05, 'epoch': 2.681096681096681}
2025-05-15 18:52:58,644 - TaskScriptRunner - INFO - {'loss': 7.3482, 'grad_norm': 1.5625, 'learning_rate': 1.4605765619356726e-05, 'epoch': 2.686868686868687}
2025-05-15 18:52:59,732 - TaskScriptRunner - INFO - {'loss': 7.2526, 'grad_norm': 1.6328125, 'learning_rate': 1.4084474563679284e-05, 'epoch': 2.6926406926406927}
2025-05-15 18:53:00,810 - TaskScriptRunner - INFO - {'loss': 7.315, 'grad_norm': 1.7265625, 'learning_rate': 1.3572386284737587e-05, 'epoch': 2.6984126984126986}
2025-05-15 18:53:01,886 - TaskScriptRunner - INFO - {'loss': 7.293, 'grad_norm': 1.65625, 'learning_rate': 1.3069520758470454e-05, 'epoch': 2.704184704184704}
2025-05-15 18:53:02,934 - TaskScriptRunner - INFO - {'loss': 7.256, 'grad_norm': 1.65625, 'learning_rate': 1.2575897601048353e-05, 'epoch': 2.70995670995671}
2025-05-15 18:53:03,981 - TaskScriptRunner - INFO - {'loss': 7.2494, 'grad_norm': 1.5859375, 'learning_rate': 1.2091536068108255e-05, 'epoch': 2.7157287157287158}
2025-05-15 18:53:05,051 - TaskScriptRunner - INFO - {'loss': 7.2463, 'grad_norm': 1.546875, 'learning_rate': 1.161645505400244e-05, 'epoch': 2.7215007215007216}
2025-05-15 18:53:06,096 - TaskScriptRunner - INFO - {'loss': 7.3068, 'grad_norm': 1.6796875, 'learning_rate': 1.1150673091061491e-05, 'epoch': 2.7272727272727275}
2025-05-15 18:53:07,141 - TaskScriptRunner - INFO - {'loss': 7.2805, 'grad_norm': 1.734375, 'learning_rate': 1.0694208348871304e-05, 'epoch': 2.733044733044733}
2025-05-15 18:53:08,183 - TaskScriptRunner - INFO - {'loss': 7.3481, 'grad_norm': 1.6015625, 'learning_rate': 1.0247078633564416e-05, 'epoch': 2.738816738816739}
2025-05-15 18:53:09,225 - TaskScriptRunner - INFO - {'loss': 7.3268, 'grad_norm': 1.5390625, 'learning_rate': 9.809301387125408e-06, 'epoch': 2.7445887445887447}
2025-05-15 18:53:10,273 - TaskScriptRunner - INFO - {'loss': 7.3259, 'grad_norm': 1.515625, 'learning_rate': 9.380893686710328e-06, 'epoch': 2.75036075036075}
2025-05-15 18:53:11,314 - TaskScriptRunner - INFO - {'loss': 7.337, 'grad_norm': 1.65625, 'learning_rate': 8.961872243980734e-06, 'epoch': 2.756132756132756}
2025-05-15 18:53:12,380 - TaskScriptRunner - INFO - {'loss': 7.3464, 'grad_norm': 1.5859375, 'learning_rate': 8.55225340445176e-06, 'epoch': 2.761904761904762}
2025-05-15 18:53:13,427 - TaskScriptRunner - INFO - {'loss': 7.3317, 'grad_norm': 1.5625, 'learning_rate': 8.152053146854465e-06, 'epoch': 2.7676767676767677}
2025-05-15 18:53:14,476 - TaskScriptRunner - INFO - {'loss': 7.3394, 'grad_norm': 1.59375, 'learning_rate': 7.761287082512447e-06, 'epoch': 2.7734487734487736}
2025-05-15 18:53:15,522 - TaskScriptRunner - INFO - {'loss': 7.2586, 'grad_norm': 1.4921875, 'learning_rate': 7.379970454732959e-06, 'epoch': 2.779220779220779}
2025-05-15 18:53:16,574 - TaskScriptRunner - INFO - {'loss': 7.2969, 'grad_norm': 1.546875, 'learning_rate': 7.008118138212394e-06, 'epoch': 2.784992784992785}
2025-05-15 18:53:17,628 - TaskScriptRunner - INFO - {'loss': 7.229, 'grad_norm': 1.6328125, 'learning_rate': 6.645744638455742e-06, 'epoch': 2.790764790764791}
2025-05-15 18:53:18,678 - TaskScriptRunner - INFO - {'loss': 7.289, 'grad_norm': 1.5, 'learning_rate': 6.292864091210964e-06, 'epoch': 2.7965367965367967}
2025-05-15 18:53:19,759 - TaskScriptRunner - INFO - {'loss': 7.2469, 'grad_norm': 1.6015625, 'learning_rate': 5.949490261917573e-06, 'epoch': 2.8023088023088025}
2025-05-15 18:53:20,805 - TaskScriptRunner - INFO - {'loss': 7.3073, 'grad_norm': 1.5859375, 'learning_rate': 5.615636545169639e-06, 'epoch': 2.808080808080808}
2025-05-15 18:53:21,855 - TaskScriptRunner - INFO - {'loss': 7.2862, 'grad_norm': 1.59375, 'learning_rate': 5.291315964193161e-06, 'epoch': 2.813852813852814}
2025-05-15 18:53:22,898 - TaskScriptRunner - INFO - {'loss': 7.2848, 'grad_norm': 1.546875, 'learning_rate': 4.9765411703382446e-06, 'epoch': 2.8196248196248197}
2025-05-15 18:53:23,943 - TaskScriptRunner - INFO - {'loss': 7.3079, 'grad_norm': 1.484375, 'learning_rate': 4.6713244425854175e-06, 'epoch': 2.825396825396825}
2025-05-15 18:53:24,991 - TaskScriptRunner - INFO - {'loss': 7.3509, 'grad_norm': 1.546875, 'learning_rate': 4.375677687066731e-06, 'epoch': 2.8311688311688314}
2025-05-15 18:53:26,038 - TaskScriptRunner - INFO - {'loss': 7.252, 'grad_norm': 1.5625, 'learning_rate': 4.089612436601359e-06, 'epoch': 2.836940836940837}
2025-05-15 18:53:27,101 - TaskScriptRunner - INFO - {'loss': 7.2644, 'grad_norm': 1.5078125, 'learning_rate': 3.8131398502455615e-06, 'epoch': 2.8427128427128427}
2025-05-15 18:53:28,148 - TaskScriptRunner - INFO - {'loss': 7.3307, 'grad_norm': 1.5078125, 'learning_rate': 3.5462707128575687e-06, 'epoch': 2.8484848484848486}
2025-05-15 18:53:29,195 - TaskScriptRunner - INFO - {'loss': 7.2691, 'grad_norm': 1.640625, 'learning_rate': 3.28901543467669e-06, 'epoch': 2.854256854256854}
2025-05-15 18:53:30,243 - TaskScriptRunner - INFO - {'loss': 7.2918, 'grad_norm': 1.4296875, 'learning_rate': 3.0413840509174173e-06, 'epoch': 2.86002886002886}
2025-05-15 18:53:31,288 - TaskScriptRunner - INFO - {'loss': 7.3228, 'grad_norm': 1.6015625, 'learning_rate': 2.803386221377796e-06, 'epoch': 2.865800865800866}
2025-05-15 18:53:32,338 - TaskScriptRunner - INFO - {'loss': 7.3752, 'grad_norm': 1.515625, 'learning_rate': 2.5750312300627244e-06, 'epoch': 2.8715728715728717}
2025-05-15 18:53:33,387 - TaskScriptRunner - INFO - {'loss': 7.3198, 'grad_norm': 1.625, 'learning_rate': 2.3563279848216877e-06, 'epoch': 2.8773448773448775}
2025-05-15 18:53:34,460 - TaskScriptRunner - INFO - {'loss': 7.3895, 'grad_norm': 1.625, 'learning_rate': 2.1472850170014268e-06, 'epoch': 2.883116883116883}
2025-05-15 18:53:35,506 - TaskScriptRunner - INFO - {'loss': 7.3638, 'grad_norm': 1.5703125, 'learning_rate': 1.947910481112952e-06, 'epoch': 2.888888888888889}
2025-05-15 18:53:36,555 - TaskScriptRunner - INFO - {'loss': 7.3253, 'grad_norm': 1.5, 'learning_rate': 1.7582121545136609e-06, 'epoch': 2.8946608946608947}
2025-05-15 18:53:37,604 - TaskScriptRunner - INFO - {'loss': 7.3448, 'grad_norm': 1.5, 'learning_rate': 1.5781974371037178e-06, 'epoch': 2.9004329004329006}
2025-05-15 18:53:38,652 - TaskScriptRunner - INFO - {'loss': 7.2582, 'grad_norm': 1.453125, 'learning_rate': 1.4078733510375364e-06, 'epoch': 2.9062049062049065}
2025-05-15 18:53:39,700 - TaskScriptRunner - INFO - {'loss': 7.3183, 'grad_norm': 1.515625, 'learning_rate': 1.2472465404498867e-06, 'epoch': 2.911976911976912}
2025-05-15 18:53:40,751 - TaskScriptRunner - INFO - {'loss': 7.2997, 'grad_norm': 1.53125, 'learning_rate': 1.0963232711966309e-06, 'epoch': 2.9177489177489178}
2025-05-15 18:53:41,793 - TaskScriptRunner - INFO - {'loss': 7.2993, 'grad_norm': 1.4140625, 'learning_rate': 9.551094306102793e-07, 'epoch': 2.9235209235209236}
2025-05-15 18:53:42,868 - TaskScriptRunner - INFO - {'loss': 7.3496, 'grad_norm': 1.5390625, 'learning_rate': 8.236105272704242e-07, 'epoch': 2.929292929292929}
2025-05-15 18:53:43,920 - TaskScriptRunner - INFO - {'loss': 7.3241, 'grad_norm': 1.6171875, 'learning_rate': 7.018316907888289e-07, 'epoch': 2.935064935064935}
2025-05-15 18:53:44,972 - TaskScriptRunner - INFO - {'loss': 7.3448, 'grad_norm': 1.5703125, 'learning_rate': 5.897776716092818e-07, 'epoch': 2.940836940836941}
2025-05-15 18:53:46,021 - TaskScriptRunner - INFO - {'loss': 7.3153, 'grad_norm': 1.5078125, 'learning_rate': 4.874528408223e-07, 'epoch': 2.9466089466089467}
2025-05-15 18:53:47,079 - TaskScriptRunner - INFO - {'loss': 7.2916, 'grad_norm': 1.5, 'learning_rate': 3.948611899946553e-07, 'epoch': 2.9523809523809526}
2025-05-15 18:53:48,134 - TaskScriptRunner - INFO - {'loss': 7.2888, 'grad_norm': 1.6015625, 'learning_rate': 3.1200633101366447e-07, 'epoch': 2.958152958152958}
2025-05-15 18:53:49,188 - TaskScriptRunner - INFO - {'loss': 7.3153, 'grad_norm': 1.5625, 'learning_rate': 2.3889149594624736e-07, 'epoch': 2.963924963924964}
2025-05-15 18:53:50,257 - TaskScriptRunner - INFO - {'loss': 7.3966, 'grad_norm': 1.5859375, 'learning_rate': 1.7551953691288813e-07, 'epoch': 2.9696969696969697}
2025-05-15 18:53:51,300 - TaskScriptRunner - INFO - {'loss': 7.285, 'grad_norm': 1.53125, 'learning_rate': 1.2189292597639122e-07, 'epoch': 2.9754689754689756}
2025-05-15 18:53:52,345 - TaskScriptRunner - INFO - {'loss': 7.2693, 'grad_norm': 1.6015625, 'learning_rate': 7.801375504537522e-08, 'epoch': 2.9812409812409815}
2025-05-15 18:53:53,388 - TaskScriptRunner - INFO - {'loss': 7.2985, 'grad_norm': 1.4609375, 'learning_rate': 4.388373579275462e-08, 'epoch': 2.987012987012987}
2025-05-15 18:53:54,442 - TaskScriptRunner - INFO - {'loss': 7.3026, 'grad_norm': 1.53125, 'learning_rate': 1.9504199588932235e-08, 'epoch': 2.9927849927849928}
2025-05-15 18:53:55,498 - TaskScriptRunner - INFO - {'loss': 7.2832, 'grad_norm': 1.5234375, 'learning_rate': 4.876097449896255e-09, 'epoch': 2.9985569985569986}
2025-05-15 18:54:13,504 - TaskScriptRunner - INFO - {'train_runtime': 202.263, 'train_samples_per_second': 102.787, 'train_steps_per_second': 2.566, 'train_loss': 2.4550378455821718, 'epoch': 2.9985569985569986}
2025-05-15 18:54:15,559 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Running quantization...
2025-05-15 18:54:15,560 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Running quantization on 179 variables
2025-05-15 18:54:22,682 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Quantized 179/179 params. Before quantization: 5664.51 MB. After quantization: 2832.25 MB with meta: 0.00 MB.
2025-05-15 18:54:22,684 - ModelQuantizer - INFO - [identity=site-math, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=7079b0b4-abba-4809-8d1a-2f7c36df37f0] - Quantized from {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float32', 'model.model.layers.0.self_attn.k_norm.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float32', 'model.model.layers.1.self_attn.k_norm.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float32', 'model.model.layers.2.self_attn.k_norm.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float32', 'model.model.layers.3.self_attn.k_norm.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float32', 'model.model.layers.4.self_attn.k_norm.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float32', 'model.model.layers.5.self_attn.k_norm.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float32', 'model.model.layers.6.self_attn.k_norm.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float32', 'model.model.layers.7.self_attn.k_norm.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float32', 'model.model.layers.8.self_attn.k_norm.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float32', 'model.model.layers.9.self_attn.k_norm.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float32', 'model.model.layers.10.self_attn.k_norm.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float32', 'model.model.layers.11.self_attn.k_norm.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float32', 'model.model.layers.12.self_attn.k_norm.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float32', 'model.model.layers.13.self_attn.k_norm.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float32', 'model.model.layers.14.self_attn.k_norm.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float32', 'model.model.layers.15.self_attn.k_norm.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'} to float16
2025-05-15 18:56:29,366 - InProcessClientAPI - WARNING - ask to stop job: reason: END_RUN received
2025-05-15 18:56:29,429 - InProcessClientAPI - WARNING - request to stop the job for reason END_RUN received
