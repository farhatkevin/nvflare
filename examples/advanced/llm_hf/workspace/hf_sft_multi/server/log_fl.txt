2025-05-12 18:46:14,449 - driver_manager - WARNING - Driver ignored. Error loading nvflare.fuel.f3.drivers.aio_http_driver: [Errno 2] No such file or directory
2025-05-12 18:46:14,460 - driver_manager - WARNING - Driver ignored. Error loading nvflare.fuel.f3.drivers.aio_http_driver: [Errno 2] No such file or directory
2025-05-12 18:46:18,548 - IntimeModelSelector - INFO - model selection weights control: {}
2025-05-12 18:46:18,607 - ModelQuantizer - INFO - Using model quantizator.
2025-05-12 18:46:18,608 - ModelDequantizer - INFO - Using model dequantizator.
2025-05-12 18:46:18,611 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller] - Initializing BaseModelController workflow.
2025-05-12 18:46:18,612 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller] - Beginning model controller run.
2025-05-12 18:46:18,612 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller] - Start FedAvg.
2025-05-12 18:46:18,612 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller] - loading initial model from persistor
2025-05-12 18:46:18,612 - PTFileModelPersistor - INFO - [identity=simulator_server, run=simulate_job, wf=controller] - Both source_ckpt_file_full_name and ckpt_preload_path are not provided. Using the default model weights initialized on the persistor side.
2025-05-12 18:46:18,613 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller] - Round 0 started.
2025-05-12 18:46:18,614 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller] - Sampled clients: ['site-dolly', 'site-alpaca', 'site-oasst1']
2025-05-12 18:46:18,614 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller] - Sending task train to ['site-dolly', 'site-alpaca', 'site-oasst1']
2025-05-12 18:46:23,958 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, task_name=train, task_id=8cb93d5b-cae6-4b9c-93c7-51fd1979177d] - Running quantization...
2025-05-12 18:46:23,958 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, task_name=train, task_id=8cb93d5b-cae6-4b9c-93c7-51fd1979177d] - Running quantization on 147 variables
2025-05-12 18:46:23,977 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Running quantization...
2025-05-12 18:46:23,978 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Running quantization on 147 variables
2025-05-12 18:46:24,175 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.0.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,176 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.0.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,176 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.0.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,176 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.0.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,176 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.0.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,177 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.0.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,195 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.0.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,195 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.0.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,196 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.1.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,197 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.1.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,197 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.1.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,197 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.1.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,198 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.1.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,217 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.1.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,218 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.1.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,219 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.1.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,219 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.2.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,220 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.2.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,220 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.2.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,220 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.2.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,253 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.2.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,256 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.2.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,256 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.2.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,256 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.3.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,257 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.3.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,257 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.3.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,258 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.3.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,275 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.3.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,288 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.3.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,289 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.3.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,291 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.4.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,292 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.4.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,334 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.4.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,335 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.4.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,336 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.5.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,336 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.5.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,337 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.5.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,337 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.5.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,366 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.5.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,367 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.5.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,368 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.5.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,368 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.6.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,368 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.6.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,369 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.6.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,403 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.6.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,404 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.6.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,404 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.6.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,406 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.7.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,406 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.7.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,451 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.7.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,453 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.7.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,453 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.8.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,453 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.8.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,453 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.8.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,454 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.8.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,469 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.8.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,482 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.8.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,483 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.8.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,483 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.9.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,484 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.9.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,519 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.9.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,520 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.9.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,520 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.9.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,520 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.10.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,521 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.10.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,521 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.10.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,521 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.10.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,557 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.10.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,558 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.10.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,560 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.11.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,560 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.11.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,595 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.11.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,596 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.11.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,596 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.11.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,597 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.12.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,597 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.12.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,597 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.12.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,598 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.12.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,615 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.12.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,629 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.12.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,630 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.12.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,630 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.13.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,630 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.13.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,631 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.13.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,671 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.13.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,672 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.13.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,672 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.14.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,673 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.14.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,673 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.14.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,673 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.14.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,704 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.14.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,704 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.14.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,704 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.14.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,705 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.15.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,705 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.15.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,705 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.15.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,743 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.15.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,743 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.layers.15.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,744 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Skipping quantization for model.model.norm.weight, quantization bit float16 >= source data bit float16
2025-05-12 18:46:24,858 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, task_name=train, task_id=8cb93d5b-cae6-4b9c-93c7-51fd1979177d] - Quantized 147/147 params. Before quantization: 5716.26 MB. After quantization: 2858.13 MB with meta: 0.00 MB.
2025-05-12 18:46:24,859 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, task_name=train, task_id=8cb93d5b-cae6-4b9c-93c7-51fd1979177d] - Quantized from {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.input_layernorm.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.input_layernorm.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.input_layernorm.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'} to float16
2025-05-12 18:46:24,917 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Quantized 48/147 params. Before quantization: 5056.13 MB. After quantization: 2198.00 MB with meta: 0.00 MB.
2025-05-12 18:46:24,969 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Quantized from {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float16', 'model.model.layers.0.self_attn.k_proj.weight': 'float16', 'model.model.layers.0.self_attn.v_proj.weight': 'float16', 'model.model.layers.0.self_attn.o_proj.weight': 'float16', 'model.model.layers.0.mlp.gate_proj.weight': 'float16', 'model.model.layers.0.mlp.up_proj.weight': 'float16', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float16', 'model.model.layers.0.post_attention_layernorm.weight': 'float16', 'model.model.layers.1.self_attn.q_proj.weight': 'float16', 'model.model.layers.1.self_attn.k_proj.weight': 'float16', 'model.model.layers.1.self_attn.v_proj.weight': 'float16', 'model.model.layers.1.self_attn.o_proj.weight': 'float16', 'model.model.layers.1.mlp.gate_proj.weight': 'float16', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float16', 'model.model.layers.1.input_layernorm.weight': 'float16', 'model.model.layers.1.post_attention_layernorm.weight': 'float16', 'model.model.layers.2.self_attn.q_proj.weight': 'float16', 'model.model.layers.2.self_attn.k_proj.weight': 'float16', 'model.model.layers.2.self_attn.v_proj.weight': 'float16', 'model.model.layers.2.self_attn.o_proj.weight': 'float16', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float16', 'model.model.layers.2.input_layernorm.weight': 'float16', 'model.model.layers.2.post_attention_layernorm.weight': 'float16', 'model.model.layers.3.self_attn.q_proj.weight': 'float16', 'model.model.layers.3.self_attn.k_proj.weight': 'float16', 'model.model.layers.3.self_attn.v_proj.weight': 'float16', 'model.model.layers.3.self_attn.o_proj.weight': 'float16', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float16', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float16', 'model.model.layers.3.post_attention_layernorm.weight': 'float16', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float16', 'model.model.layers.4.self_attn.v_proj.weight': 'float16', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float16', 'model.model.layers.4.post_attention_layernorm.weight': 'float16', 'model.model.layers.5.self_attn.q_proj.weight': 'float16', 'model.model.layers.5.self_attn.k_proj.weight': 'float16', 'model.model.layers.5.self_attn.v_proj.weight': 'float16', 'model.model.layers.5.self_attn.o_proj.weight': 'float16', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float16', 'model.model.layers.5.input_layernorm.weight': 'float16', 'model.model.layers.5.post_attention_layernorm.weight': 'float16', 'model.model.layers.6.self_attn.q_proj.weight': 'float16', 'model.model.layers.6.self_attn.k_proj.weight': 'float16', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float16', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float16', 'model.model.layers.6.input_layernorm.weight': 'float16', 'model.model.layers.6.post_attention_layernorm.weight': 'float16', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float16', 'model.model.layers.7.self_attn.v_proj.weight': 'float16', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float16', 'model.model.layers.7.post_attention_layernorm.weight': 'float16', 'model.model.layers.8.self_attn.q_proj.weight': 'float16', 'model.model.layers.8.self_attn.k_proj.weight': 'float16', 'model.model.layers.8.self_attn.v_proj.weight': 'float16', 'model.model.layers.8.self_attn.o_proj.weight': 'float16', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float16', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float16', 'model.model.layers.8.post_attention_layernorm.weight': 'float16', 'model.model.layers.9.self_attn.q_proj.weight': 'float16', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float16', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float16', 'model.model.layers.9.input_layernorm.weight': 'float16', 'model.model.layers.9.post_attention_layernorm.weight': 'float16', 'model.model.layers.10.self_attn.q_proj.weight': 'float16', 'model.model.layers.10.self_attn.k_proj.weight': 'float16', 'model.model.layers.10.self_attn.v_proj.weight': 'float16', 'model.model.layers.10.self_attn.o_proj.weight': 'float16', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float16', 'model.model.layers.10.post_attention_layernorm.weight': 'float16', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float16', 'model.model.layers.11.self_attn.v_proj.weight': 'float16', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float16', 'model.model.layers.11.input_layernorm.weight': 'float16', 'model.model.layers.11.post_attention_layernorm.weight': 'float16', 'model.model.layers.12.self_attn.q_proj.weight': 'float16', 'model.model.layers.12.self_attn.k_proj.weight': 'float16', 'model.model.layers.12.self_attn.v_proj.weight': 'float16', 'model.model.layers.12.self_attn.o_proj.weight': 'float16', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float16', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float16', 'model.model.layers.12.post_attention_layernorm.weight': 'float16', 'model.model.layers.13.self_attn.q_proj.weight': 'float16', 'model.model.layers.13.self_attn.k_proj.weight': 'float16', 'model.model.layers.13.self_attn.v_proj.weight': 'float16', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float16', 'model.model.layers.13.post_attention_layernorm.weight': 'float16', 'model.model.layers.14.self_attn.q_proj.weight': 'float16', 'model.model.layers.14.self_attn.k_proj.weight': 'float16', 'model.model.layers.14.self_attn.v_proj.weight': 'float16', 'model.model.layers.14.self_attn.o_proj.weight': 'float16', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float16', 'model.model.layers.14.input_layernorm.weight': 'float16', 'model.model.layers.14.post_attention_layernorm.weight': 'float16', 'model.model.layers.15.self_attn.q_proj.weight': 'float16', 'model.model.layers.15.self_attn.k_proj.weight': 'float16', 'model.model.layers.15.self_attn.v_proj.weight': 'float16', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float16', 'model.model.layers.15.post_attention_layernorm.weight': 'float16', 'model.model.norm.weight': 'float16', 'model.lm_head.weight': 'float32'} to float16
2025-05-12 19:00:28,758 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Running dequantization...
2025-05-12 19:00:28,759 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Running dequantization on 147 variables
2025-05-12 19:00:32,795 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Dequantized 147/147 params. Before dequantization: 2858.13 MB with meta: 0.00 MB. After dequantization: 5716.26 MB.
2025-05-12 19:00:32,797 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=cd257992-e600-497a-9936-debec6ad5a7d] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.input_layernorm.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.input_layernorm.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.input_layernorm.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'}
2025-05-12 20:05:47,385 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8cb93d5b-cae6-4b9c-93c7-51fd1979177d] - Running dequantization...
2025-05-12 20:05:47,385 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8cb93d5b-cae6-4b9c-93c7-51fd1979177d] - Running dequantization on 147 variables
2025-05-12 20:05:51,392 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8cb93d5b-cae6-4b9c-93c7-51fd1979177d] - Dequantized 147/147 params. Before dequantization: 2858.13 MB with meta: 0.00 MB. After dequantization: 5716.26 MB.
2025-05-12 20:05:51,394 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8cb93d5b-cae6-4b9c-93c7-51fd1979177d] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.input_layernorm.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.input_layernorm.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.input_layernorm.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'}
2025-05-12 20:05:56,437 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=c9a8ad45-9c70-44f0-a864-043cbf65c967] - Running quantization...
2025-05-12 20:05:56,437 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=c9a8ad45-9c70-44f0-a864-043cbf65c967] - Already quantized, skip quantization
2025-05-12 20:10:25,603 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c9a8ad45-9c70-44f0-a864-043cbf65c967] - Running dequantization...
2025-05-12 20:10:25,603 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c9a8ad45-9c70-44f0-a864-043cbf65c967] - Running dequantization on 147 variables
2025-05-12 20:10:29,623 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c9a8ad45-9c70-44f0-a864-043cbf65c967] - Dequantized 147/147 params. Before dequantization: 2858.13 MB with meta: 0.00 MB. After dequantization: 5716.26 MB.
2025-05-12 20:10:29,625 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c9a8ad45-9c70-44f0-a864-043cbf65c967] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.input_layernorm.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.input_layernorm.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.input_layernorm.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'}
2025-05-12 20:10:30,022 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c9a8ad45-9c70-44f0-a864-043cbf65c967] - aggregating 3 update(s) at round 0
2025-05-12 20:10:42,771 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c9a8ad45-9c70-44f0-a864-043cbf65c967] - Start persist model on server.
2025-05-12 20:11:42,802 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c9a8ad45-9c70-44f0-a864-043cbf65c967] - End persist model on server.
2025-05-12 20:11:42,804 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c9a8ad45-9c70-44f0-a864-043cbf65c967] - Round 1 started.
2025-05-12 20:11:42,805 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c9a8ad45-9c70-44f0-a864-043cbf65c967] - Sampled clients: ['site-dolly', 'site-alpaca', 'site-oasst1']
2025-05-12 20:11:42,805 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=c9a8ad45-9c70-44f0-a864-043cbf65c967] - Sending task train to ['site-dolly', 'site-alpaca', 'site-oasst1']
2025-05-12 20:11:44,098 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Running quantization...
2025-05-12 20:11:44,098 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Running quantization on 147 variables
2025-05-12 20:11:47,672 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Running quantization...
2025-05-12 20:11:47,673 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Running quantization on 147 variables
2025-05-12 20:11:47,673 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.embed_tokens.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,673 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.0.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,674 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.0.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,674 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.0.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,674 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.0.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,674 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.0.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,675 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.0.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,675 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.0.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,675 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.0.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,675 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.0.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,676 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.1.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,676 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.1.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,676 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.1.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,676 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.1.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,677 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.1.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,677 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.1.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,677 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.1.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,677 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.1.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,678 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.1.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,678 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.2.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,678 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.2.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,678 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.2.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,679 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.2.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,679 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.2.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,679 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.2.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,679 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.2.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,679 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.2.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,680 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.2.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,680 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.3.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,680 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.3.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,680 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.3.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,681 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.3.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,681 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.3.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,681 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.3.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,681 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.3.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,682 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.3.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,682 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.3.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,682 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.4.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,682 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.4.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,683 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.4.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,683 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.4.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,683 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.4.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,683 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.4.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,684 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.4.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,684 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.4.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,684 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.4.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,684 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.5.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,684 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.5.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,685 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.5.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,685 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.5.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,685 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.5.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,685 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.5.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,686 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.5.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,686 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.5.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,686 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.5.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,710 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.6.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,710 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.6.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,974 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.6.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:47,975 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.6.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:48,267 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.7.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:48,268 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.7.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:48,285 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.8.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:48,286 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.8.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:48,588 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.8.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:48,589 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.8.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:48,589 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.9.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:48,589 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.9.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:48,590 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Skipping quantization for model.model.layers.9.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:48,849 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.9.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:48,850 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.9.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:48,869 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.10.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:49,137 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.10.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:49,137 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.10.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:49,155 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.11.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:49,421 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.11.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:49,421 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.11.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:49,439 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.12.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:49,704 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.12.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:49,704 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.12.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:49,725 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.13.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:49,726 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.13.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:49,988 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.13.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:49,989 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.13.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:50,007 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.14.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:50,274 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.14.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:50,274 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.14.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:50,292 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.15.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:50,293 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.15.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:50,556 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.15.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:50,556 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.layers.15.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:50,557 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Skipping quantization for model.model.norm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:11:51,784 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Quantized 85/147 params. Before quantization: 4503.20 MB. After quantization: 1645.07 MB with meta: 0.00 MB.
2025-05-12 20:11:51,784 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Quantized from {'model.model.embed_tokens.weight': 'float16', 'model.model.layers.0.self_attn.q_proj.weight': 'float16', 'model.model.layers.0.self_attn.k_proj.weight': 'float16', 'model.model.layers.0.self_attn.v_proj.weight': 'float16', 'model.model.layers.0.self_attn.o_proj.weight': 'float16', 'model.model.layers.0.mlp.gate_proj.weight': 'float16', 'model.model.layers.0.mlp.up_proj.weight': 'float16', 'model.model.layers.0.mlp.down_proj.weight': 'float16', 'model.model.layers.0.input_layernorm.weight': 'float16', 'model.model.layers.0.post_attention_layernorm.weight': 'float16', 'model.model.layers.1.self_attn.q_proj.weight': 'float16', 'model.model.layers.1.self_attn.k_proj.weight': 'float16', 'model.model.layers.1.self_attn.v_proj.weight': 'float16', 'model.model.layers.1.self_attn.o_proj.weight': 'float16', 'model.model.layers.1.mlp.gate_proj.weight': 'float16', 'model.model.layers.1.mlp.up_proj.weight': 'float16', 'model.model.layers.1.mlp.down_proj.weight': 'float16', 'model.model.layers.1.input_layernorm.weight': 'float16', 'model.model.layers.1.post_attention_layernorm.weight': 'float16', 'model.model.layers.2.self_attn.q_proj.weight': 'float16', 'model.model.layers.2.self_attn.k_proj.weight': 'float16', 'model.model.layers.2.self_attn.v_proj.weight': 'float16', 'model.model.layers.2.self_attn.o_proj.weight': 'float16', 'model.model.layers.2.mlp.gate_proj.weight': 'float16', 'model.model.layers.2.mlp.up_proj.weight': 'float16', 'model.model.layers.2.mlp.down_proj.weight': 'float16', 'model.model.layers.2.input_layernorm.weight': 'float16', 'model.model.layers.2.post_attention_layernorm.weight': 'float16', 'model.model.layers.3.self_attn.q_proj.weight': 'float16', 'model.model.layers.3.self_attn.k_proj.weight': 'float16', 'model.model.layers.3.self_attn.v_proj.weight': 'float16', 'model.model.layers.3.self_attn.o_proj.weight': 'float16', 'model.model.layers.3.mlp.gate_proj.weight': 'float16', 'model.model.layers.3.mlp.up_proj.weight': 'float16', 'model.model.layers.3.mlp.down_proj.weight': 'float16', 'model.model.layers.3.input_layernorm.weight': 'float16', 'model.model.layers.3.post_attention_layernorm.weight': 'float16', 'model.model.layers.4.self_attn.q_proj.weight': 'float16', 'model.model.layers.4.self_attn.k_proj.weight': 'float16', 'model.model.layers.4.self_attn.v_proj.weight': 'float16', 'model.model.layers.4.self_attn.o_proj.weight': 'float16', 'model.model.layers.4.mlp.gate_proj.weight': 'float16', 'model.model.layers.4.mlp.up_proj.weight': 'float16', 'model.model.layers.4.mlp.down_proj.weight': 'float16', 'model.model.layers.4.input_layernorm.weight': 'float16', 'model.model.layers.4.post_attention_layernorm.weight': 'float16', 'model.model.layers.5.self_attn.q_proj.weight': 'float16', 'model.model.layers.5.self_attn.k_proj.weight': 'float16', 'model.model.layers.5.self_attn.v_proj.weight': 'float16', 'model.model.layers.5.self_attn.o_proj.weight': 'float16', 'model.model.layers.5.mlp.gate_proj.weight': 'float16', 'model.model.layers.5.mlp.up_proj.weight': 'float16', 'model.model.layers.5.mlp.down_proj.weight': 'float16', 'model.model.layers.5.input_layernorm.weight': 'float16', 'model.model.layers.5.post_attention_layernorm.weight': 'float16', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float16', 'model.model.layers.6.self_attn.v_proj.weight': 'float16', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float16', 'model.model.layers.8.post_attention_layernorm.weight': 'float16', 'model.model.layers.9.self_attn.q_proj.weight': 'float16', 'model.model.layers.9.self_attn.k_proj.weight': 'float16', 'model.model.layers.9.self_attn.v_proj.weight': 'float16', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'} to float16
2025-05-12 20:11:51,830 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Quantized 118/147 params. Before quantization: 5696.18 MB. After quantization: 2838.05 MB with meta: 0.00 MB.
2025-05-12 20:11:51,868 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Quantized from {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.input_layernorm.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.input_layernorm.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.input_layernorm.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float16', 'model.model.layers.6.post_attention_layernorm.weight': 'float16', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float16', 'model.model.layers.7.post_attention_layernorm.weight': 'float16', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float16', 'model.model.layers.8.self_attn.v_proj.weight': 'float16', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float16', 'model.model.layers.9.post_attention_layernorm.weight': 'float16', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float16', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float16', 'model.model.layers.10.post_attention_layernorm.weight': 'float16', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float16', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float16', 'model.model.layers.11.post_attention_layernorm.weight': 'float16', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float16', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float16', 'model.model.layers.12.post_attention_layernorm.weight': 'float16', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float16', 'model.model.layers.13.self_attn.v_proj.weight': 'float16', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float16', 'model.model.layers.13.post_attention_layernorm.weight': 'float16', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float16', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float16', 'model.model.layers.14.post_attention_layernorm.weight': 'float16', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float16', 'model.model.layers.15.self_attn.v_proj.weight': 'float16', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float16', 'model.model.layers.15.post_attention_layernorm.weight': 'float16', 'model.model.norm.weight': 'float16', 'model.lm_head.weight': 'float32'} to float16
2025-05-12 20:16:39,703 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Running dequantization...
2025-05-12 20:16:39,704 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Running dequantization on 147 variables
2025-05-12 20:16:43,688 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Dequantized 147/147 params. Before dequantization: 2858.13 MB with meta: 0.00 MB. After dequantization: 5716.26 MB.
2025-05-12 20:16:43,690 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.input_layernorm.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.input_layernorm.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.input_layernorm.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'}
2025-05-12 20:16:43,691 - IntimeModelSelector - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=5e41a66e-d018-44a8-b606-9dc7978ce999] - validation metric -4.820066452026367 from client site-oasst1
2025-05-12 20:16:48,926 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, task_name=train, task_id=8150048a-212c-4fd4-b5d2-280d0a0b12df] - Running quantization...
2025-05-12 20:16:48,926 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, task_name=train, task_id=8150048a-212c-4fd4-b5d2-280d0a0b12df] - Already quantized, skip quantization
2025-05-12 20:23:50,318 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8150048a-212c-4fd4-b5d2-280d0a0b12df] - Running dequantization...
2025-05-12 20:23:50,318 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8150048a-212c-4fd4-b5d2-280d0a0b12df] - Running dequantization on 147 variables
2025-05-12 20:23:54,268 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8150048a-212c-4fd4-b5d2-280d0a0b12df] - Dequantized 147/147 params. Before dequantization: 2858.13 MB with meta: 0.00 MB. After dequantization: 5716.26 MB.
2025-05-12 20:23:54,270 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8150048a-212c-4fd4-b5d2-280d0a0b12df] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.input_layernorm.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.input_layernorm.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.input_layernorm.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'}
2025-05-12 20:23:54,272 - IntimeModelSelector - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8150048a-212c-4fd4-b5d2-280d0a0b12df] - validation metric -4.985183238983154 from client site-dolly
2025-05-12 20:24:03,362 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Running dequantization...
2025-05-12 20:24:03,482 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Running dequantization on 147 variables
2025-05-12 20:24:07,521 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Dequantized 147/147 params. Before dequantization: 2858.13 MB with meta: 0.00 MB. After dequantization: 5716.26 MB.
2025-05-12 20:24:07,523 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.input_layernorm.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.input_layernorm.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.input_layernorm.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'}
2025-05-12 20:24:07,524 - IntimeModelSelector - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - validation metric -3.0921108722686768 from client site-alpaca
2025-05-12 20:24:07,948 - IntimeModelSelector - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - new best validation metric at round 1: -4.299120187759399
2025-05-12 20:24:37,323 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - aggregating 3 update(s) at round 1
2025-05-12 20:24:48,538 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Start persist model on server.
2025-05-12 20:26:06,306 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - End persist model on server.
2025-05-12 20:26:06,402 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Round 2 started.
2025-05-12 20:26:06,403 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Sampled clients: ['site-dolly', 'site-alpaca', 'site-oasst1']
2025-05-12 20:26:06,403 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=7bca828d-fa42-4c46-8050-3ad318ea7fb1] - Sending task train to ['site-dolly', 'site-alpaca', 'site-oasst1']
2025-05-12 20:26:06,812 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Running quantization...
2025-05-12 20:26:06,812 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Running quantization on 147 variables
2025-05-12 20:26:10,298 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Running quantization...
2025-05-12 20:26:10,299 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Running quantization on 147 variables
2025-05-12 20:26:10,300 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.embed_tokens.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,300 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.0.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,300 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.0.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,300 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.0.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,301 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.0.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,301 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.0.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,301 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.0.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,301 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.0.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,302 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.0.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,302 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.0.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,302 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.1.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,302 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.1.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,303 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.1.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,303 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.1.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,303 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.1.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,303 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.1.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,303 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.1.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,304 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.1.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,304 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.1.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,304 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.2.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,304 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.2.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,305 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.2.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,305 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.2.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,305 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.2.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,305 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.2.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,306 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.2.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,306 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.2.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,306 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.2.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,306 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.3.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,307 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.3.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,307 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.3.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,307 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.3.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,307 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.3.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,308 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.3.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,308 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.3.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,308 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.3.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,308 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.3.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,309 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.4.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,309 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.4.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,309 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.4.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,309 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.4.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,310 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.4.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,310 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.4.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,310 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.4.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,310 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.4.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,311 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.4.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,311 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.5.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,311 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.5.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,312 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.5.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,312 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.5.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,312 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.5.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,312 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.5.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,313 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.5.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,313 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.5.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,313 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.5.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,314 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.6.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,314 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.6.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,314 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.6.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,314 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.6.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,315 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.6.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,315 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.6.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,315 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.6.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,315 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.6.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,315 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.6.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,316 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.7.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,316 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.7.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,316 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.7.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,316 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.7.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,317 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.7.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,317 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.7.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,317 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.7.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,317 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.7.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,318 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.7.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,318 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.8.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,318 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.8.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,584 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.8.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,585 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.8.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,868 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.9.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:10,868 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.9.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,211 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.10.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,212 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.10.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,212 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.11.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,212 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.11.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,212 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.11.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,213 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.11.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,454 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.11.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,455 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.11.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,455 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.12.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,720 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.12.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,720 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.12.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,998 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.13.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:11,998 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.13.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:12,283 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.14.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:12,283 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.14.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:12,300 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.15.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:12,301 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Skipping quantization for model.model.layers.15.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:12,559 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.15.input_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:12,560 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.layers.15.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:12,560 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Skipping quantization for model.model.norm.weight, quantization bit float16 >= source data bit float16
2025-05-12 20:26:13,787 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Quantized 131/147 params. Before quantization: 5688.21 MB. After quantization: 2830.09 MB with meta: 0.00 MB.
2025-05-12 20:26:13,788 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Quantized from {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.input_layernorm.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.input_layernorm.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.input_layernorm.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float16', 'model.model.layers.9.post_attention_layernorm.weight': 'float16', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float16', 'model.model.layers.10.post_attention_layernorm.weight': 'float16', 'model.model.layers.11.self_attn.q_proj.weight': 'float16', 'model.model.layers.11.self_attn.k_proj.weight': 'float16', 'model.model.layers.11.self_attn.v_proj.weight': 'float16', 'model.model.layers.11.self_attn.o_proj.weight': 'float16', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float16', 'model.model.layers.11.post_attention_layernorm.weight': 'float16', 'model.model.layers.12.self_attn.q_proj.weight': 'float16', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float16', 'model.model.layers.12.post_attention_layernorm.weight': 'float16', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float16', 'model.model.layers.15.post_attention_layernorm.weight': 'float16', 'model.model.norm.weight': 'float16', 'model.lm_head.weight': 'float32'} to float16
2025-05-12 20:26:13,824 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Quantized 64/147 params. Before quantization: 4273.17 MB. After quantization: 1415.04 MB with meta: 0.00 MB.
2025-05-12 20:26:13,896 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Quantized from {'model.model.embed_tokens.weight': 'float16', 'model.model.layers.0.self_attn.q_proj.weight': 'float16', 'model.model.layers.0.self_attn.k_proj.weight': 'float16', 'model.model.layers.0.self_attn.v_proj.weight': 'float16', 'model.model.layers.0.self_attn.o_proj.weight': 'float16', 'model.model.layers.0.mlp.gate_proj.weight': 'float16', 'model.model.layers.0.mlp.up_proj.weight': 'float16', 'model.model.layers.0.mlp.down_proj.weight': 'float16', 'model.model.layers.0.input_layernorm.weight': 'float16', 'model.model.layers.0.post_attention_layernorm.weight': 'float16', 'model.model.layers.1.self_attn.q_proj.weight': 'float16', 'model.model.layers.1.self_attn.k_proj.weight': 'float16', 'model.model.layers.1.self_attn.v_proj.weight': 'float16', 'model.model.layers.1.self_attn.o_proj.weight': 'float16', 'model.model.layers.1.mlp.gate_proj.weight': 'float16', 'model.model.layers.1.mlp.up_proj.weight': 'float16', 'model.model.layers.1.mlp.down_proj.weight': 'float16', 'model.model.layers.1.input_layernorm.weight': 'float16', 'model.model.layers.1.post_attention_layernorm.weight': 'float16', 'model.model.layers.2.self_attn.q_proj.weight': 'float16', 'model.model.layers.2.self_attn.k_proj.weight': 'float16', 'model.model.layers.2.self_attn.v_proj.weight': 'float16', 'model.model.layers.2.self_attn.o_proj.weight': 'float16', 'model.model.layers.2.mlp.gate_proj.weight': 'float16', 'model.model.layers.2.mlp.up_proj.weight': 'float16', 'model.model.layers.2.mlp.down_proj.weight': 'float16', 'model.model.layers.2.input_layernorm.weight': 'float16', 'model.model.layers.2.post_attention_layernorm.weight': 'float16', 'model.model.layers.3.self_attn.q_proj.weight': 'float16', 'model.model.layers.3.self_attn.k_proj.weight': 'float16', 'model.model.layers.3.self_attn.v_proj.weight': 'float16', 'model.model.layers.3.self_attn.o_proj.weight': 'float16', 'model.model.layers.3.mlp.gate_proj.weight': 'float16', 'model.model.layers.3.mlp.up_proj.weight': 'float16', 'model.model.layers.3.mlp.down_proj.weight': 'float16', 'model.model.layers.3.input_layernorm.weight': 'float16', 'model.model.layers.3.post_attention_layernorm.weight': 'float16', 'model.model.layers.4.self_attn.q_proj.weight': 'float16', 'model.model.layers.4.self_attn.k_proj.weight': 'float16', 'model.model.layers.4.self_attn.v_proj.weight': 'float16', 'model.model.layers.4.self_attn.o_proj.weight': 'float16', 'model.model.layers.4.mlp.gate_proj.weight': 'float16', 'model.model.layers.4.mlp.up_proj.weight': 'float16', 'model.model.layers.4.mlp.down_proj.weight': 'float16', 'model.model.layers.4.input_layernorm.weight': 'float16', 'model.model.layers.4.post_attention_layernorm.weight': 'float16', 'model.model.layers.5.self_attn.q_proj.weight': 'float16', 'model.model.layers.5.self_attn.k_proj.weight': 'float16', 'model.model.layers.5.self_attn.v_proj.weight': 'float16', 'model.model.layers.5.self_attn.o_proj.weight': 'float16', 'model.model.layers.5.mlp.gate_proj.weight': 'float16', 'model.model.layers.5.mlp.up_proj.weight': 'float16', 'model.model.layers.5.mlp.down_proj.weight': 'float16', 'model.model.layers.5.input_layernorm.weight': 'float16', 'model.model.layers.5.post_attention_layernorm.weight': 'float16', 'model.model.layers.6.self_attn.q_proj.weight': 'float16', 'model.model.layers.6.self_attn.k_proj.weight': 'float16', 'model.model.layers.6.self_attn.v_proj.weight': 'float16', 'model.model.layers.6.self_attn.o_proj.weight': 'float16', 'model.model.layers.6.mlp.gate_proj.weight': 'float16', 'model.model.layers.6.mlp.up_proj.weight': 'float16', 'model.model.layers.6.mlp.down_proj.weight': 'float16', 'model.model.layers.6.input_layernorm.weight': 'float16', 'model.model.layers.6.post_attention_layernorm.weight': 'float16', 'model.model.layers.7.self_attn.q_proj.weight': 'float16', 'model.model.layers.7.self_attn.k_proj.weight': 'float16', 'model.model.layers.7.self_attn.v_proj.weight': 'float16', 'model.model.layers.7.self_attn.o_proj.weight': 'float16', 'model.model.layers.7.mlp.gate_proj.weight': 'float16', 'model.model.layers.7.mlp.up_proj.weight': 'float16', 'model.model.layers.7.mlp.down_proj.weight': 'float16', 'model.model.layers.7.input_layernorm.weight': 'float16', 'model.model.layers.7.post_attention_layernorm.weight': 'float16', 'model.model.layers.8.self_attn.q_proj.weight': 'float16', 'model.model.layers.8.self_attn.k_proj.weight': 'float16', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float16', 'model.model.layers.8.post_attention_layernorm.weight': 'float16', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float16', 'model.model.layers.13.post_attention_layernorm.weight': 'float16', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float16', 'model.model.layers.14.post_attention_layernorm.weight': 'float16', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float16', 'model.model.layers.15.self_attn.v_proj.weight': 'float16', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'} to float16
2025-05-12 20:31:08,105 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Running dequantization...
2025-05-12 20:31:08,106 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Running dequantization on 147 variables
2025-05-12 20:31:11,996 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Dequantized 147/147 params. Before dequantization: 2858.13 MB with meta: 0.00 MB. After dequantization: 5716.26 MB.
2025-05-12 20:31:11,998 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.input_layernorm.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.input_layernorm.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.input_layernorm.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'}
2025-05-12 20:31:11,999 - IntimeModelSelector - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-oasst1, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=8d5a9d86-0860-46a4-bc9a-9b1d3dc24caa] - validation metric -4.087799549102783 from client site-oasst1
2025-05-12 20:31:17,129 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, task_name=train, task_id=ffdd954d-f135-44db-8ee6-fb0b4a75c369] - Running quantization...
2025-05-12 20:31:17,130 - ModelQuantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, task_name=train, task_id=ffdd954d-f135-44db-8ee6-fb0b4a75c369] - Already quantized, skip quantization
2025-05-12 20:38:17,613 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=ffdd954d-f135-44db-8ee6-fb0b4a75c369] - Running dequantization...
2025-05-12 20:38:17,614 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=ffdd954d-f135-44db-8ee6-fb0b4a75c369] - Running dequantization on 147 variables
2025-05-12 20:38:21,551 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=ffdd954d-f135-44db-8ee6-fb0b4a75c369] - Dequantized 147/147 params. Before dequantization: 2858.13 MB with meta: 0.00 MB. After dequantization: 5716.26 MB.
2025-05-12 20:38:21,552 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=ffdd954d-f135-44db-8ee6-fb0b4a75c369] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.input_layernorm.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.input_layernorm.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.input_layernorm.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'}
2025-05-12 20:38:21,553 - IntimeModelSelector - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-dolly, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=ffdd954d-f135-44db-8ee6-fb0b4a75c369] - validation metric -4.297403335571289 from client site-dolly
2025-05-12 20:38:30,951 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Running dequantization...
2025-05-12 20:38:30,951 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Running dequantization on 147 variables
2025-05-12 20:38:34,926 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Dequantized 147/147 params. Before dequantization: 2858.13 MB with meta: 0.00 MB. After dequantization: 5716.26 MB.
2025-05-12 20:38:34,928 - ModelDequantizer - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.input_layernorm.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.input_layernorm.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.input_layernorm.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.input_layernorm.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.input_layernorm.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.input_layernorm.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.input_layernorm.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.input_layernorm.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.input_layernorm.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.input_layernorm.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.input_layernorm.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.input_layernorm.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.input_layernorm.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.input_layernorm.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.input_layernorm.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.input_layernorm.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'}
2025-05-12 20:38:34,929 - IntimeModelSelector - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - validation metric -2.5273680686950684 from client site-alpaca
2025-05-12 20:38:35,398 - IntimeModelSelector - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - new best validation metric at round 2: -3.637523651123047
2025-05-12 20:39:15,138 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - aggregating 3 update(s) at round 2
2025-05-12 20:39:26,517 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Start persist model on server.
2025-05-12 20:40:43,166 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - End persist model on server.
2025-05-12 20:40:43,169 - FedAvg - INFO - [identity=simulator_server, run=simulate_job, wf=controller, peer=site-alpaca, peer_run=simulate_job, peer_rc=OK, task_name=train, task_id=db09631b-472e-4fb9-81a3-2dc76d1ebbb2] - Finished FedAvg.
