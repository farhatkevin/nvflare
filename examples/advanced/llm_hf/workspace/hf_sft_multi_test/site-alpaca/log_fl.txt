2025-05-13 17:59:48,085 - ModelDequantizer - INFO - Using model dequantizator.
2025-05-13 17:59:48,086 - ModelQuantizer - INFO - Using model quantizator.
2025-05-13 17:59:48,598 - TaskScriptRunner - INFO - start task run() with full path: /workspace/NVFlare/examples/advanced/llm_hf/workspace/hf_sft_multi_test/site-alpaca/simulate_job/app_site-alpaca/custom/src/hf_sft_peft_fl.py
2025-05-13 17:59:50,874 - TaskScriptRunner - INFO - Dataset size: training 41602, validation 5200
2025-05-13 17:59:50,875 - TaskScriptRunner - INFO - logging_steps: 52
2025-05-13 17:59:54,619 - TaskScriptRunner - INFO -  38           0 BUILD_LIST               0
2025-05-13 17:59:54,621 - TaskScriptRunner - INFO -               2 STORE_FAST               1 (output_texts)
2025-05-13 17:59:54,622 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,624 - TaskScriptRunner - INFO -  39           4 LOAD_GLOBAL              0 (range)
2025-05-13 17:59:54,625 - TaskScriptRunner - INFO -               6 LOAD_GLOBAL              1 (len)
2025-05-13 17:59:54,626 - TaskScriptRunner - INFO -               8 LOAD_FAST                0 (example)
2025-05-13 17:59:54,628 - TaskScriptRunner - INFO -              10 LOAD_CONST               1 ('input')
2025-05-13 17:59:54,629 - TaskScriptRunner - INFO -              12 BINARY_SUBSCR
2025-05-13 17:59:54,630 - TaskScriptRunner - INFO -              14 CALL_FUNCTION            1
2025-05-13 17:59:54,631 - TaskScriptRunner - INFO -              16 CALL_FUNCTION            1
2025-05-13 17:59:54,632 - TaskScriptRunner - INFO -              18 GET_ITER
2025-05-13 17:59:54,632 - TaskScriptRunner - INFO -         >>   20 FOR_ITER                23 (to 68)
2025-05-13 17:59:54,632 - TaskScriptRunner - INFO -              22 STORE_FAST               2 (i)
2025-05-13 17:59:54,632 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,633 - TaskScriptRunner - INFO -  40          24 LOAD_CONST               2 ('### Instruction: Generate Output according to the information and question given by Input. ### Input:')
2025-05-13 17:59:54,633 - TaskScriptRunner - INFO -              26 LOAD_FAST                0 (example)
2025-05-13 17:59:54,634 - TaskScriptRunner - INFO -              28 LOAD_CONST               1 ('input')
2025-05-13 17:59:54,634 - TaskScriptRunner - INFO -              30 BINARY_SUBSCR
2025-05-13 17:59:54,635 - TaskScriptRunner - INFO -              32 LOAD_FAST                2 (i)
2025-05-13 17:59:54,635 - TaskScriptRunner - INFO -              34 BINARY_SUBSCR
2025-05-13 17:59:54,635 - TaskScriptRunner - INFO -              36 FORMAT_VALUE             0
2025-05-13 17:59:54,635 - TaskScriptRunner - INFO -              38 LOAD_CONST               3 (' ### Response: ')
2025-05-13 17:59:54,636 - TaskScriptRunner - INFO -              40 LOAD_FAST                0 (example)
2025-05-13 17:59:54,636 - TaskScriptRunner - INFO -              42 LOAD_CONST               4 ('output')
2025-05-13 17:59:54,637 - TaskScriptRunner - INFO -              44 BINARY_SUBSCR
2025-05-13 17:59:54,637 - TaskScriptRunner - INFO -              46 LOAD_FAST                2 (i)
2025-05-13 17:59:54,638 - TaskScriptRunner - INFO -              48 BINARY_SUBSCR
2025-05-13 17:59:54,638 - TaskScriptRunner - INFO -              50 FORMAT_VALUE             0
2025-05-13 17:59:54,639 - TaskScriptRunner - INFO -              52 BUILD_STRING             4
2025-05-13 17:59:54,639 - TaskScriptRunner - INFO -              54 STORE_FAST               3 (text)
2025-05-13 17:59:54,639 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,639 - TaskScriptRunner - INFO -  41          56 LOAD_FAST                1 (output_texts)
2025-05-13 17:59:54,640 - TaskScriptRunner - INFO -              58 LOAD_METHOD              2 (append)
2025-05-13 17:59:54,640 - TaskScriptRunner - INFO -              60 LOAD_FAST                3 (text)
2025-05-13 17:59:54,640 - TaskScriptRunner - INFO -              62 CALL_METHOD              1
2025-05-13 17:59:54,641 - TaskScriptRunner - INFO -              64 POP_TOP
2025-05-13 17:59:54,642 - TaskScriptRunner - INFO -              66 JUMP_ABSOLUTE           10 (to 20)
2025-05-13 17:59:54,642 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,642 - TaskScriptRunner - INFO -  42     >>   68 LOAD_FAST                1 (output_texts)
2025-05-13 17:59:54,643 - TaskScriptRunner - INFO -              70 RETURN_VALUE
2025-05-13 17:59:54,643 - TaskScriptRunner - INFO - 415           0 LOAD_DEREF               4 (processing_class)
2025-05-13 17:59:54,643 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,644 - TaskScriptRunner - INFO - 416           2 LOAD_DEREF               2 (formatting_func)
2025-05-13 17:59:54,645 - TaskScriptRunner - INFO -               4 LOAD_CONST               0 (None)
2025-05-13 17:59:54,645 - TaskScriptRunner - INFO -               6 IS_OP                    0
2025-05-13 17:59:54,645 - TaskScriptRunner - INFO -               8 POP_JUMP_IF_FALSE        9 (to 18)
2025-05-13 17:59:54,646 - TaskScriptRunner - INFO -              10 LOAD_FAST                0 (element)
2025-05-13 17:59:54,646 - TaskScriptRunner - INFO -              12 LOAD_DEREF               1 (dataset_text_field)
2025-05-13 17:59:54,646 - TaskScriptRunner - INFO -              14 BINARY_SUBSCR
2025-05-13 17:59:54,646 - TaskScriptRunner - INFO -              16 JUMP_FORWARD             3 (to 24)
2025-05-13 17:59:54,647 - TaskScriptRunner - INFO -         >>   18 LOAD_DEREF               2 (formatting_func)
2025-05-13 17:59:54,647 - TaskScriptRunner - INFO -              20 LOAD_FAST                0 (element)
2025-05-13 17:59:54,648 - TaskScriptRunner - INFO -              22 CALL_FUNCTION            1
2025-05-13 17:59:54,648 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,649 - TaskScriptRunner - INFO - 417     >>   24 LOAD_DEREF               0 (add_special_tokens)
2025-05-13 17:59:54,649 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,650 - TaskScriptRunner - INFO - 418          26 LOAD_CONST               1 (True)
2025-05-13 17:59:54,650 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,650 - TaskScriptRunner - INFO - 419          28 LOAD_CONST               2 (False)
2025-05-13 17:59:54,651 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,651 - TaskScriptRunner - INFO - 420          30 LOAD_DEREF               3 (max_seq_length)
2025-05-13 17:59:54,652 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,652 - TaskScriptRunner - INFO - 421          32 LOAD_CONST               2 (False)
2025-05-13 17:59:54,653 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,653 - TaskScriptRunner - INFO - 422          34 LOAD_CONST               2 (False)
2025-05-13 17:59:54,653 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,654 - TaskScriptRunner - INFO - 415          36 LOAD_CONST               3 (('add_special_tokens', 'truncation', 'padding', 'max_length', 'return_overflowing_tokens', 'return_length'))
2025-05-13 17:59:54,654 - TaskScriptRunner - INFO -              38 CALL_FUNCTION_KW         7
2025-05-13 17:59:54,654 - TaskScriptRunner - INFO -              40 STORE_FAST               1 (outputs)
2025-05-13 17:59:54,655 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,655 - TaskScriptRunner - INFO - 425          42 LOAD_DEREF               2 (formatting_func)
2025-05-13 17:59:54,656 - TaskScriptRunner - INFO -              44 LOAD_CONST               0 (None)
2025-05-13 17:59:54,656 - TaskScriptRunner - INFO -              46 IS_OP                    1
2025-05-13 17:59:54,657 - TaskScriptRunner - INFO -              48 POP_JUMP_IF_FALSE       36 (to 72)
2025-05-13 17:59:54,657 - TaskScriptRunner - INFO -              50 LOAD_GLOBAL              0 (isinstance)
2025-05-13 17:59:54,657 - TaskScriptRunner - INFO -              52 LOAD_DEREF               2 (formatting_func)
2025-05-13 17:59:54,658 - TaskScriptRunner - INFO -              54 LOAD_FAST                0 (element)
2025-05-13 17:59:54,658 - TaskScriptRunner - INFO -              56 CALL_FUNCTION            1
2025-05-13 17:59:54,659 - TaskScriptRunner - INFO -              58 LOAD_GLOBAL              1 (list)
2025-05-13 17:59:54,659 - TaskScriptRunner - INFO -              60 CALL_FUNCTION            2
2025-05-13 17:59:54,659 - TaskScriptRunner - INFO -              62 POP_JUMP_IF_TRUE        36 (to 72)
2025-05-13 17:59:54,660 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,660 - TaskScriptRunner - INFO - 426          64 LOAD_GLOBAL              2 (ValueError)
2025-05-13 17:59:54,660 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,660 - TaskScriptRunner - INFO - 427          66 LOAD_CONST               4 ('The `formatting_func` should return a list of processed strings since it can lead to silent bugs.')
2025-05-13 17:59:54,661 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,661 - TaskScriptRunner - INFO - 426          68 CALL_FUNCTION            1
2025-05-13 17:59:54,662 - TaskScriptRunner - INFO -              70 RAISE_VARARGS            1
2025-05-13 17:59:54,662 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,663 - TaskScriptRunner - INFO - 430     >>   72 LOAD_FAST                1 (outputs)
2025-05-13 17:59:54,663 - TaskScriptRunner - INFO -              74 LOAD_CONST               5 ('input_ids')
2025-05-13 17:59:54,664 - TaskScriptRunner - INFO -              76 BINARY_SUBSCR
2025-05-13 17:59:54,664 - TaskScriptRunner - INFO -              78 LOAD_FAST                1 (outputs)
2025-05-13 17:59:54,664 - TaskScriptRunner - INFO -              80 LOAD_CONST               6 ('attention_mask')
2025-05-13 17:59:54,664 - TaskScriptRunner - INFO -              82 BINARY_SUBSCR
2025-05-13 17:59:54,665 - TaskScriptRunner - INFO -              84 LOAD_CONST               7 (('input_ids', 'attention_mask'))
2025-05-13 17:59:54,665 - TaskScriptRunner - INFO -              86 BUILD_CONST_KEY_MAP      2
2025-05-13 17:59:54,665 - TaskScriptRunner - INFO -              88 RETURN_VALUE
2025-05-13 17:59:54,711 - TaskScriptRunner - INFO -  38           0 BUILD_LIST               0
2025-05-13 17:59:54,712 - TaskScriptRunner - INFO -               2 STORE_FAST               1 (output_texts)
2025-05-13 17:59:54,713 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,714 - TaskScriptRunner - INFO -  39           4 LOAD_GLOBAL              0 (range)
2025-05-13 17:59:54,715 - TaskScriptRunner - INFO -               6 LOAD_GLOBAL              1 (len)
2025-05-13 17:59:54,716 - TaskScriptRunner - INFO -               8 LOAD_FAST                0 (example)
2025-05-13 17:59:54,717 - TaskScriptRunner - INFO -              10 LOAD_CONST               1 ('input')
2025-05-13 17:59:54,718 - TaskScriptRunner - INFO -              12 BINARY_SUBSCR
2025-05-13 17:59:54,718 - TaskScriptRunner - INFO -              14 CALL_FUNCTION            1
2025-05-13 17:59:54,719 - TaskScriptRunner - INFO -              16 CALL_FUNCTION            1
2025-05-13 17:59:54,720 - TaskScriptRunner - INFO -              18 GET_ITER
2025-05-13 17:59:54,720 - TaskScriptRunner - INFO -         >>   20 FOR_ITER                23 (to 68)
2025-05-13 17:59:54,720 - TaskScriptRunner - INFO -              22 STORE_FAST               2 (i)
2025-05-13 17:59:54,720 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,721 - TaskScriptRunner - INFO -  40          24 LOAD_CONST               2 ('### Instruction: Generate Output according to the information and question given by Input. ### Input:')
2025-05-13 17:59:54,722 - TaskScriptRunner - INFO -              26 LOAD_FAST                0 (example)
2025-05-13 17:59:54,722 - TaskScriptRunner - INFO -              28 LOAD_CONST               1 ('input')
2025-05-13 17:59:54,722 - TaskScriptRunner - INFO -              30 BINARY_SUBSCR
2025-05-13 17:59:54,723 - TaskScriptRunner - INFO -              32 LOAD_FAST                2 (i)
2025-05-13 17:59:54,723 - TaskScriptRunner - INFO -              34 BINARY_SUBSCR
2025-05-13 17:59:54,723 - TaskScriptRunner - INFO -              36 FORMAT_VALUE             0
2025-05-13 17:59:54,723 - TaskScriptRunner - INFO -              38 LOAD_CONST               3 (' ### Response: ')
2025-05-13 17:59:54,724 - TaskScriptRunner - INFO -              40 LOAD_FAST                0 (example)
2025-05-13 17:59:54,724 - TaskScriptRunner - INFO -              42 LOAD_CONST               4 ('output')
2025-05-13 17:59:54,725 - TaskScriptRunner - INFO -              44 BINARY_SUBSCR
2025-05-13 17:59:54,725 - TaskScriptRunner - INFO -              46 LOAD_FAST                2 (i)
2025-05-13 17:59:54,726 - TaskScriptRunner - INFO -              48 BINARY_SUBSCR
2025-05-13 17:59:54,726 - TaskScriptRunner - INFO -              50 FORMAT_VALUE             0
2025-05-13 17:59:54,726 - TaskScriptRunner - INFO -              52 BUILD_STRING             4
2025-05-13 17:59:54,726 - TaskScriptRunner - INFO -              54 STORE_FAST               3 (text)
2025-05-13 17:59:54,727 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,727 - TaskScriptRunner - INFO -  41          56 LOAD_FAST                1 (output_texts)
2025-05-13 17:59:54,728 - TaskScriptRunner - INFO -              58 LOAD_METHOD              2 (append)
2025-05-13 17:59:54,728 - TaskScriptRunner - INFO -              60 LOAD_FAST                3 (text)
2025-05-13 17:59:54,728 - TaskScriptRunner - INFO -              62 CALL_METHOD              1
2025-05-13 17:59:54,729 - TaskScriptRunner - INFO -              64 POP_TOP
2025-05-13 17:59:54,729 - TaskScriptRunner - INFO -              66 JUMP_ABSOLUTE           10 (to 20)
2025-05-13 17:59:54,730 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,730 - TaskScriptRunner - INFO -  42     >>   68 LOAD_FAST                1 (output_texts)
2025-05-13 17:59:54,730 - TaskScriptRunner - INFO -              70 RETURN_VALUE
2025-05-13 17:59:54,734 - TaskScriptRunner - INFO -  38           0 BUILD_LIST               0
2025-05-13 17:59:54,735 - TaskScriptRunner - INFO -               2 STORE_FAST               1 (output_texts)
2025-05-13 17:59:54,736 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,737 - TaskScriptRunner - INFO -  39           4 LOAD_GLOBAL              0 (range)
2025-05-13 17:59:54,738 - TaskScriptRunner - INFO -               6 LOAD_GLOBAL              1 (len)
2025-05-13 17:59:54,739 - TaskScriptRunner - INFO -               8 LOAD_FAST                0 (example)
2025-05-13 17:59:54,740 - TaskScriptRunner - INFO -              10 LOAD_CONST               1 ('input')
2025-05-13 17:59:54,741 - TaskScriptRunner - INFO -              12 BINARY_SUBSCR
2025-05-13 17:59:54,742 - TaskScriptRunner - INFO -              14 CALL_FUNCTION            1
2025-05-13 17:59:54,743 - TaskScriptRunner - INFO -              16 CALL_FUNCTION            1
2025-05-13 17:59:54,743 - TaskScriptRunner - INFO -              18 GET_ITER
2025-05-13 17:59:54,744 - TaskScriptRunner - INFO -         >>   20 FOR_ITER                23 (to 68)
2025-05-13 17:59:54,744 - TaskScriptRunner - INFO -              22 STORE_FAST               2 (i)
2025-05-13 17:59:54,745 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,745 - TaskScriptRunner - INFO -  40          24 LOAD_CONST               2 ('### Instruction: Generate Output according to the information and question given by Input. ### Input:')
2025-05-13 17:59:54,746 - TaskScriptRunner - INFO -              26 LOAD_FAST                0 (example)
2025-05-13 17:59:54,747 - TaskScriptRunner - INFO -              28 LOAD_CONST               1 ('input')
2025-05-13 17:59:54,747 - TaskScriptRunner - INFO -              30 BINARY_SUBSCR
2025-05-13 17:59:54,748 - TaskScriptRunner - INFO -              32 LOAD_FAST                2 (i)
2025-05-13 17:59:54,749 - TaskScriptRunner - INFO -              34 BINARY_SUBSCR
2025-05-13 17:59:54,749 - TaskScriptRunner - INFO -              36 FORMAT_VALUE             0
2025-05-13 17:59:54,750 - TaskScriptRunner - INFO -              38 LOAD_CONST               3 (' ### Response: ')
2025-05-13 17:59:54,750 - TaskScriptRunner - INFO -              40 LOAD_FAST                0 (example)
2025-05-13 17:59:54,751 - TaskScriptRunner - INFO -              42 LOAD_CONST               4 ('output')
2025-05-13 17:59:54,751 - TaskScriptRunner - INFO -              44 BINARY_SUBSCR
2025-05-13 17:59:54,752 - TaskScriptRunner - INFO -              46 LOAD_FAST                2 (i)
2025-05-13 17:59:54,752 - TaskScriptRunner - INFO -              48 BINARY_SUBSCR
2025-05-13 17:59:54,753 - TaskScriptRunner - INFO -              50 FORMAT_VALUE             0
2025-05-13 17:59:54,754 - TaskScriptRunner - INFO -              52 BUILD_STRING             4
2025-05-13 17:59:54,755 - TaskScriptRunner - INFO -              54 STORE_FAST               3 (text)
2025-05-13 17:59:54,755 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,756 - TaskScriptRunner - INFO -  41          56 LOAD_FAST                1 (output_texts)
2025-05-13 17:59:54,757 - TaskScriptRunner - INFO -              58 LOAD_METHOD              2 (append)
2025-05-13 17:59:54,757 - TaskScriptRunner - INFO -              60 LOAD_FAST                3 (text)
2025-05-13 17:59:54,758 - TaskScriptRunner - INFO -              62 CALL_METHOD              1
2025-05-13 17:59:54,758 - TaskScriptRunner - INFO -              64 POP_TOP
2025-05-13 17:59:54,759 - TaskScriptRunner - INFO -              66 JUMP_ABSOLUTE           10 (to 20)
2025-05-13 17:59:54,759 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,760 - TaskScriptRunner - INFO -  42     >>   68 LOAD_FAST                1 (output_texts)
2025-05-13 17:59:54,761 - TaskScriptRunner - INFO -              70 RETURN_VALUE
2025-05-13 17:59:54,761 - TaskScriptRunner - INFO - 415           0 LOAD_DEREF               4 (processing_class)
2025-05-13 17:59:54,762 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,762 - TaskScriptRunner - INFO - 416           2 LOAD_DEREF               2 (formatting_func)
2025-05-13 17:59:54,763 - TaskScriptRunner - INFO -               4 LOAD_CONST               0 (None)
2025-05-13 17:59:54,764 - TaskScriptRunner - INFO -               6 IS_OP                    0
2025-05-13 17:59:54,764 - TaskScriptRunner - INFO -               8 POP_JUMP_IF_FALSE        9 (to 18)
2025-05-13 17:59:54,765 - TaskScriptRunner - INFO -              10 LOAD_FAST                0 (element)
2025-05-13 17:59:54,766 - TaskScriptRunner - INFO -              12 LOAD_DEREF               1 (dataset_text_field)
2025-05-13 17:59:54,766 - TaskScriptRunner - INFO -              14 BINARY_SUBSCR
2025-05-13 17:59:54,767 - TaskScriptRunner - INFO -              16 JUMP_FORWARD             3 (to 24)
2025-05-13 17:59:54,767 - TaskScriptRunner - INFO -         >>   18 LOAD_DEREF               2 (formatting_func)
2025-05-13 17:59:54,768 - TaskScriptRunner - INFO -              20 LOAD_FAST                0 (element)
2025-05-13 17:59:54,768 - TaskScriptRunner - INFO -              22 CALL_FUNCTION            1
2025-05-13 17:59:54,769 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,769 - TaskScriptRunner - INFO - 417     >>   24 LOAD_DEREF               0 (add_special_tokens)
2025-05-13 17:59:54,770 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,771 - TaskScriptRunner - INFO - 418          26 LOAD_CONST               1 (True)
2025-05-13 17:59:54,772 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,772 - TaskScriptRunner - INFO - 419          28 LOAD_CONST               2 (False)
2025-05-13 17:59:54,773 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,774 - TaskScriptRunner - INFO - 420          30 LOAD_DEREF               3 (max_seq_length)
2025-05-13 17:59:54,775 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,775 - TaskScriptRunner - INFO - 421          32 LOAD_CONST               2 (False)
2025-05-13 17:59:54,776 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,776 - TaskScriptRunner - INFO - 422          34 LOAD_CONST               2 (False)
2025-05-13 17:59:54,777 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,777 - TaskScriptRunner - INFO - 415          36 LOAD_CONST               3 (('add_special_tokens', 'truncation', 'padding', 'max_length', 'return_overflowing_tokens', 'return_length'))
2025-05-13 17:59:54,778 - TaskScriptRunner - INFO -              38 CALL_FUNCTION_KW         7
2025-05-13 17:59:54,779 - TaskScriptRunner - INFO -              40 STORE_FAST               1 (outputs)
2025-05-13 17:59:54,779 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,780 - TaskScriptRunner - INFO - 425          42 LOAD_DEREF               2 (formatting_func)
2025-05-13 17:59:54,781 - TaskScriptRunner - INFO -              44 LOAD_CONST               0 (None)
2025-05-13 17:59:54,781 - TaskScriptRunner - INFO -              46 IS_OP                    1
2025-05-13 17:59:54,782 - TaskScriptRunner - INFO -              48 POP_JUMP_IF_FALSE       36 (to 72)
2025-05-13 17:59:54,782 - TaskScriptRunner - INFO -              50 LOAD_GLOBAL              0 (isinstance)
2025-05-13 17:59:54,783 - TaskScriptRunner - INFO -              52 LOAD_DEREF               2 (formatting_func)
2025-05-13 17:59:54,783 - TaskScriptRunner - INFO -              54 LOAD_FAST                0 (element)
2025-05-13 17:59:54,784 - TaskScriptRunner - INFO -              56 CALL_FUNCTION            1
2025-05-13 17:59:54,785 - TaskScriptRunner - INFO -              58 LOAD_GLOBAL              1 (list)
2025-05-13 17:59:54,785 - TaskScriptRunner - INFO -              60 CALL_FUNCTION            2
2025-05-13 17:59:54,786 - TaskScriptRunner - INFO -              62 POP_JUMP_IF_TRUE        36 (to 72)
2025-05-13 17:59:54,787 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,787 - TaskScriptRunner - INFO - 426          64 LOAD_GLOBAL              2 (ValueError)
2025-05-13 17:59:54,788 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,789 - TaskScriptRunner - INFO - 427          66 LOAD_CONST               4 ('The `formatting_func` should return a list of processed strings since it can lead to silent bugs.')
2025-05-13 17:59:54,789 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,790 - TaskScriptRunner - INFO - 426          68 CALL_FUNCTION            1
2025-05-13 17:59:54,790 - TaskScriptRunner - INFO -              70 RAISE_VARARGS            1
2025-05-13 17:59:54,791 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,792 - TaskScriptRunner - INFO - 430     >>   72 LOAD_FAST                1 (outputs)
2025-05-13 17:59:54,792 - TaskScriptRunner - INFO -              74 LOAD_CONST               5 ('input_ids')
2025-05-13 17:59:54,793 - TaskScriptRunner - INFO -              76 BINARY_SUBSCR
2025-05-13 17:59:54,794 - TaskScriptRunner - INFO -              78 LOAD_FAST                1 (outputs)
2025-05-13 17:59:54,794 - TaskScriptRunner - INFO -              80 LOAD_CONST               6 ('attention_mask')
2025-05-13 17:59:54,795 - TaskScriptRunner - INFO -              82 BINARY_SUBSCR
2025-05-13 17:59:54,796 - TaskScriptRunner - INFO -              84 LOAD_CONST               7 (('input_ids', 'attention_mask'))
2025-05-13 17:59:54,796 - TaskScriptRunner - INFO -              86 BUILD_CONST_KEY_MAP      2
2025-05-13 17:59:54,797 - TaskScriptRunner - INFO -              88 RETURN_VALUE
2025-05-13 17:59:54,849 - TaskScriptRunner - INFO -  38           0 BUILD_LIST               0
2025-05-13 17:59:54,851 - TaskScriptRunner - INFO -               2 STORE_FAST               1 (output_texts)
2025-05-13 17:59:54,852 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,853 - TaskScriptRunner - INFO -  39           4 LOAD_GLOBAL              0 (range)
2025-05-13 17:59:54,855 - TaskScriptRunner - INFO -               6 LOAD_GLOBAL              1 (len)
2025-05-13 17:59:54,856 - TaskScriptRunner - INFO -               8 LOAD_FAST                0 (example)
2025-05-13 17:59:54,858 - TaskScriptRunner - INFO -              10 LOAD_CONST               1 ('input')
2025-05-13 17:59:54,858 - TaskScriptRunner - INFO -              12 BINARY_SUBSCR
2025-05-13 17:59:54,858 - TaskScriptRunner - INFO -              14 CALL_FUNCTION            1
2025-05-13 17:59:54,859 - TaskScriptRunner - INFO -              16 CALL_FUNCTION            1
2025-05-13 17:59:54,859 - TaskScriptRunner - INFO -              18 GET_ITER
2025-05-13 17:59:54,860 - TaskScriptRunner - INFO -         >>   20 FOR_ITER                23 (to 68)
2025-05-13 17:59:54,860 - TaskScriptRunner - INFO -              22 STORE_FAST               2 (i)
2025-05-13 17:59:54,860 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,861 - TaskScriptRunner - INFO -  40          24 LOAD_CONST               2 ('### Instruction: Generate Output according to the information and question given by Input. ### Input:')
2025-05-13 17:59:54,861 - TaskScriptRunner - INFO -              26 LOAD_FAST                0 (example)
2025-05-13 17:59:54,862 - TaskScriptRunner - INFO -              28 LOAD_CONST               1 ('input')
2025-05-13 17:59:54,862 - TaskScriptRunner - INFO -              30 BINARY_SUBSCR
2025-05-13 17:59:54,862 - TaskScriptRunner - INFO -              32 LOAD_FAST                2 (i)
2025-05-13 17:59:54,863 - TaskScriptRunner - INFO -              34 BINARY_SUBSCR
2025-05-13 17:59:54,863 - TaskScriptRunner - INFO -              36 FORMAT_VALUE             0
2025-05-13 17:59:54,863 - TaskScriptRunner - INFO -              38 LOAD_CONST               3 (' ### Response: ')
2025-05-13 17:59:54,864 - TaskScriptRunner - INFO -              40 LOAD_FAST                0 (example)
2025-05-13 17:59:54,864 - TaskScriptRunner - INFO -              42 LOAD_CONST               4 ('output')
2025-05-13 17:59:54,865 - TaskScriptRunner - INFO -              44 BINARY_SUBSCR
2025-05-13 17:59:54,865 - TaskScriptRunner - INFO -              46 LOAD_FAST                2 (i)
2025-05-13 17:59:54,865 - TaskScriptRunner - INFO -              48 BINARY_SUBSCR
2025-05-13 17:59:54,866 - TaskScriptRunner - INFO -              50 FORMAT_VALUE             0
2025-05-13 17:59:54,866 - TaskScriptRunner - INFO -              52 BUILD_STRING             4
2025-05-13 17:59:54,866 - TaskScriptRunner - INFO -              54 STORE_FAST               3 (text)
2025-05-13 17:59:54,867 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,867 - TaskScriptRunner - INFO -  41          56 LOAD_FAST                1 (output_texts)
2025-05-13 17:59:54,867 - TaskScriptRunner - INFO -              58 LOAD_METHOD              2 (append)
2025-05-13 17:59:54,868 - TaskScriptRunner - INFO -              60 LOAD_FAST                3 (text)
2025-05-13 17:59:54,868 - TaskScriptRunner - INFO -              62 CALL_METHOD              1
2025-05-13 17:59:54,869 - TaskScriptRunner - INFO -              64 POP_TOP
2025-05-13 17:59:54,869 - TaskScriptRunner - INFO -              66 JUMP_ABSOLUTE           10 (to 20)
2025-05-13 17:59:54,869 - TaskScriptRunner - INFO - 
2025-05-13 17:59:54,870 - TaskScriptRunner - INFO -  42     >>   68 LOAD_FAST                1 (output_texts)
2025-05-13 17:59:54,870 - TaskScriptRunner - INFO -              70 RETURN_VALUE
2025-05-13 18:00:01,132 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Running dequantization...
2025-05-13 18:00:01,133 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Running dequantization on 179 variables
2025-05-13 18:00:01,181 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.0.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,182 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.0.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,182 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.1.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,183 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.1.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,183 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.1.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,184 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.1.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,185 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.1.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,190 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.1.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,190 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.1.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,191 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.1.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,193 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.2.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,194 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.2.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,194 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.2.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,199 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.2.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,200 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.2.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,200 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.2.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,201 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.3.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,201 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.3.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,202 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.3.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,202 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.3.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,203 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.3.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,203 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.3.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,208 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.3.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,209 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.3.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,209 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.3.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,210 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.4.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,210 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.4.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,211 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.4.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,212 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.4.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,213 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.4.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,218 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.4.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,218 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.4.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,219 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.4.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,219 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.5.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,220 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.5.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,220 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.5.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,221 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.5.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,221 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.5.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,221 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.5.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,229 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.5.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,230 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.5.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,230 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.6.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,231 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.6.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,231 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.6.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,232 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.6.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,232 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.6.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,233 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.6.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,238 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.6.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,239 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.6.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,239 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.6.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,239 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.7.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,240 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.7.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,241 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.7.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,242 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.7.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,242 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.7.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,248 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.7.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,248 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.7.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,249 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.7.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,249 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.8.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,249 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.8.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,250 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.8.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,250 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.8.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,251 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.8.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,251 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.8.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,259 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.8.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,260 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.8.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,260 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.9.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,261 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.9.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,261 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.9.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,262 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.9.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,262 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.9.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,270 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.9.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,271 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.9.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,271 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.10.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,272 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.10.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,272 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.10.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,272 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.10.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,273 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.10.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,273 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.10.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,282 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.10.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,283 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.10.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,283 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.11.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,284 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.11.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,286 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.11.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,286 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.11.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,294 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.11.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,295 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.11.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,295 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.12.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,296 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.12.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,296 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.12.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,296 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.12.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,297 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.12.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,297 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.12.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,303 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.12.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,303 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.12.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,304 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.12.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,304 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.13.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,306 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.13.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,307 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.13.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,307 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.13.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,315 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.13.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,316 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.13.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,316 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.14.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,317 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.14.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,317 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.14.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,318 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.14.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,319 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.14.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,319 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.14.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,327 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.14.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,328 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.14.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,328 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.15.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,329 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.15.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,329 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.15.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,330 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.15.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,331 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.15.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,339 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.15.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,340 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.layers.15.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,340 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Skipping dequantization for model.model.norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:00:01,369 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Dequantized 61/179 params. Before dequantization: 2216.01 MB with meta: 0.00 MB. After dequantization: 4432.02 MB.
2025-05-13 18:00:01,371 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float32', 'model.model.layers.0.self_attn.k_norm.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float16', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.1.self_attn.q_proj.weight': 'float16', 'model.model.layers.1.self_attn.k_proj.weight': 'float16', 'model.model.layers.1.self_attn.v_proj.weight': 'float16', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float16', 'model.model.layers.1.self_attn.k_norm.weight': 'float16', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float16', 'model.model.layers.1.post_attention_layernorm.weight': 'float16', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float16', 'model.model.layers.2.self_attn.q_norm.weight': 'float16', 'model.model.layers.2.self_attn.k_norm.weight': 'float16', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float16', 'model.model.layers.2.post_attention_layernorm.weight': 'float16', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.3.self_attn.q_proj.weight': 'float16', 'model.model.layers.3.self_attn.k_proj.weight': 'float16', 'model.model.layers.3.self_attn.v_proj.weight': 'float16', 'model.model.layers.3.self_attn.o_proj.weight': 'float16', 'model.model.layers.3.self_attn.q_norm.weight': 'float16', 'model.model.layers.3.self_attn.k_norm.weight': 'float16', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float16', 'model.model.layers.3.post_attention_layernorm.weight': 'float16', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.4.self_attn.q_proj.weight': 'float16', 'model.model.layers.4.self_attn.k_proj.weight': 'float16', 'model.model.layers.4.self_attn.v_proj.weight': 'float16', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float16', 'model.model.layers.4.self_attn.k_norm.weight': 'float16', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float16', 'model.model.layers.4.post_attention_layernorm.weight': 'float16', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.5.self_attn.q_proj.weight': 'float16', 'model.model.layers.5.self_attn.k_proj.weight': 'float16', 'model.model.layers.5.self_attn.v_proj.weight': 'float16', 'model.model.layers.5.self_attn.o_proj.weight': 'float16', 'model.model.layers.5.self_attn.q_norm.weight': 'float16', 'model.model.layers.5.self_attn.k_norm.weight': 'float16', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float16', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.6.self_attn.q_proj.weight': 'float16', 'model.model.layers.6.self_attn.k_proj.weight': 'float16', 'model.model.layers.6.self_attn.v_proj.weight': 'float16', 'model.model.layers.6.self_attn.o_proj.weight': 'float16', 'model.model.layers.6.self_attn.q_norm.weight': 'float16', 'model.model.layers.6.self_attn.k_norm.weight': 'float16', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float16', 'model.model.layers.6.post_attention_layernorm.weight': 'float16', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.7.self_attn.q_proj.weight': 'float16', 'model.model.layers.7.self_attn.k_proj.weight': 'float16', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float16', 'model.model.layers.7.self_attn.q_norm.weight': 'float16', 'model.model.layers.7.self_attn.k_norm.weight': 'float16', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float16', 'model.model.layers.7.post_attention_layernorm.weight': 'float16', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.8.self_attn.q_proj.weight': 'float16', 'model.model.layers.8.self_attn.k_proj.weight': 'float16', 'model.model.layers.8.self_attn.v_proj.weight': 'float16', 'model.model.layers.8.self_attn.o_proj.weight': 'float16', 'model.model.layers.8.self_attn.q_norm.weight': 'float16', 'model.model.layers.8.self_attn.k_norm.weight': 'float16', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float16', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.9.self_attn.q_proj.weight': 'float16', 'model.model.layers.9.self_attn.k_proj.weight': 'float16', 'model.model.layers.9.self_attn.v_proj.weight': 'float16', 'model.model.layers.9.self_attn.o_proj.weight': 'float16', 'model.model.layers.9.self_attn.q_norm.weight': 'float32', 'model.model.layers.9.self_attn.k_norm.weight': 'float16', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float16', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.10.self_attn.q_proj.weight': 'float16', 'model.model.layers.10.self_attn.k_proj.weight': 'float16', 'model.model.layers.10.self_attn.v_proj.weight': 'float16', 'model.model.layers.10.self_attn.o_proj.weight': 'float16', 'model.model.layers.10.self_attn.q_norm.weight': 'float16', 'model.model.layers.10.self_attn.k_norm.weight': 'float16', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float16', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.11.self_attn.q_proj.weight': 'float16', 'model.model.layers.11.self_attn.k_proj.weight': 'float16', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float16', 'model.model.layers.11.self_attn.k_norm.weight': 'float16', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float16', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.12.self_attn.q_proj.weight': 'float16', 'model.model.layers.12.self_attn.k_proj.weight': 'float16', 'model.model.layers.12.self_attn.v_proj.weight': 'float16', 'model.model.layers.12.self_attn.o_proj.weight': 'float16', 'model.model.layers.12.self_attn.q_norm.weight': 'float16', 'model.model.layers.12.self_attn.k_norm.weight': 'float16', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float16', 'model.model.layers.12.post_attention_layernorm.weight': 'float16', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.13.self_attn.q_proj.weight': 'float16', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float16', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float16', 'model.model.layers.13.self_attn.k_norm.weight': 'float16', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float16', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.14.self_attn.q_proj.weight': 'float16', 'model.model.layers.14.self_attn.k_proj.weight': 'float16', 'model.model.layers.14.self_attn.v_proj.weight': 'float16', 'model.model.layers.14.self_attn.o_proj.weight': 'float16', 'model.model.layers.14.self_attn.q_norm.weight': 'float16', 'model.model.layers.14.self_attn.k_norm.weight': 'float16', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float16', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.15.self_attn.q_proj.weight': 'float16', 'model.model.layers.15.self_attn.k_proj.weight': 'float16', 'model.model.layers.15.self_attn.v_proj.weight': 'float16', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float16', 'model.model.layers.15.self_attn.k_norm.weight': 'float16', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float16', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float16', 'model.model.norm.weight': 'float16', 'model.lm_head.weight': 'float32'}
2025-05-13 18:00:01,372 - PTInProcessClientAPIExecutor - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - execute for task (train)
2025-05-13 18:00:01,373 - PTInProcessClientAPIExecutor - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - send data to peer
2025-05-13 18:00:01,373 - PTInProcessClientAPIExecutor - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - sending payload to peer
2025-05-13 18:00:01,374 - PTInProcessClientAPIExecutor - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Waiting for result from peer
2025-05-13 18:00:01,548 - TaskScriptRunner - INFO - current_round=0
2025-05-13 18:00:29,040 - TaskScriptRunner - INFO - {'eval_loss': 2.793596029281616, 'eval_model_preparation_time': 0.0025, 'eval_runtime': 26.0912, 'eval_samples_per_second': 199.301, 'eval_steps_per_second': 24.913}
2025-05-13 18:00:29,041 - TaskScriptRunner - INFO - Evaluation metric score: {'eval_loss': 2.793596029281616, 'eval_model_preparation_time': 0.0025, 'eval_runtime': 26.0912, 'eval_samples_per_second': 199.301, 'eval_steps_per_second': 24.913}
2025-05-13 18:01:22,466 - TaskScriptRunner - INFO - {'loss': 2.2603, 'grad_norm': 1.8984375, 'learning_rate': 0.0005, 'epoch': 0.049997596269410124}
2025-05-13 18:02:14,076 - TaskScriptRunner - INFO - {'loss': 2.1828, 'grad_norm': 2.046875, 'learning_rate': 0.0005, 'epoch': 0.09999519253882025}
2025-05-13 18:03:05,538 - TaskScriptRunner - INFO - {'loss': 2.2098, 'grad_norm': 2.546875, 'learning_rate': 0.0005, 'epoch': 0.1499927888082304}
2025-05-13 18:03:57,320 - TaskScriptRunner - INFO - {'loss': 2.2048, 'grad_norm': 1.5, 'learning_rate': 0.0005, 'epoch': 0.1999903850776405}
2025-05-13 18:04:49,067 - TaskScriptRunner - INFO - {'loss': 2.1925, 'grad_norm': 1.421875, 'learning_rate': 0.0005, 'epoch': 0.24998798134705064}
2025-05-13 18:05:40,260 - TaskScriptRunner - INFO - {'loss': 2.1853, 'grad_norm': 1.5546875, 'learning_rate': 0.0005, 'epoch': 0.2999855776164608}
2025-05-13 18:06:31,769 - TaskScriptRunner - INFO - {'loss': 2.1697, 'grad_norm': 2.921875, 'learning_rate': 0.0005, 'epoch': 0.34998317388587086}
2025-05-13 18:07:23,976 - TaskScriptRunner - INFO - {'loss': 2.17, 'grad_norm': 1.4765625, 'learning_rate': 0.0005, 'epoch': 0.399980770155281}
2025-05-13 18:08:16,028 - TaskScriptRunner - INFO - {'loss': 2.1632, 'grad_norm': 1.265625, 'learning_rate': 0.0005, 'epoch': 0.44997836642469113}
2025-05-13 18:09:07,818 - TaskScriptRunner - INFO - {'loss': 2.1394, 'grad_norm': 1.21875, 'learning_rate': 0.0005, 'epoch': 0.4999759626941013}
2025-05-13 18:10:00,038 - TaskScriptRunner - INFO - {'loss': 2.1166, 'grad_norm': 2.25, 'learning_rate': 0.0005, 'epoch': 0.5499735589635114}
2025-05-13 18:10:51,874 - TaskScriptRunner - INFO - {'loss': 2.1231, 'grad_norm': 1.2734375, 'learning_rate': 0.0005, 'epoch': 0.5999711552329215}
2025-05-13 18:11:43,546 - TaskScriptRunner - INFO - {'loss': 2.1179, 'grad_norm': 1.2109375, 'learning_rate': 0.0005, 'epoch': 0.6499687515023316}
2025-05-13 18:12:35,901 - TaskScriptRunner - INFO - {'loss': 2.0974, 'grad_norm': 1.2734375, 'learning_rate': 0.0005, 'epoch': 0.6999663477717417}
2025-05-13 18:13:28,032 - TaskScriptRunner - INFO - {'loss': 2.0937, 'grad_norm': 1.2421875, 'learning_rate': 0.0005, 'epoch': 0.7499639440411519}
2025-05-13 18:14:20,211 - TaskScriptRunner - INFO - {'loss': 2.0681, 'grad_norm': 1.1640625, 'learning_rate': 0.0005, 'epoch': 0.799961540310562}
2025-05-13 18:15:12,406 - TaskScriptRunner - INFO - {'loss': 2.0757, 'grad_norm': 1.2421875, 'learning_rate': 0.0005, 'epoch': 0.8499591365799721}
2025-05-13 18:16:04,660 - TaskScriptRunner - INFO - {'loss': 2.0879, 'grad_norm': 1.390625, 'learning_rate': 0.0005, 'epoch': 0.8999567328493823}
2025-05-13 18:16:56,905 - TaskScriptRunner - INFO - {'loss': 2.0585, 'grad_norm': 1.1640625, 'learning_rate': 0.0005, 'epoch': 0.9499543291187924}
2025-05-13 18:17:49,416 - TaskScriptRunner - INFO - {'loss': 2.0673, 'grad_norm': 1.1796875, 'learning_rate': 0.0005, 'epoch': 0.9999519253882025}
2025-05-13 18:18:05,612 - TaskScriptRunner - INFO - {'train_runtime': 1056.3267, 'train_samples_per_second': 39.384, 'train_steps_per_second': 0.985, 'train_loss': 2.1392099087054914, 'epoch': 0.9999519253882025}
2025-05-13 18:18:07,296 - ModelQuantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Running quantization...
2025-05-13 18:18:07,296 - ModelQuantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Running quantization on 179 variables
2025-05-13 18:18:13,913 - ModelQuantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Quantized 179/179 params. Before quantization: 5664.51 MB. After quantization: 2832.25 MB with meta: 0.00 MB.
2025-05-13 18:18:13,915 - ModelQuantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=f4aeca21-1f4b-4377-8126-e81ab7ac9d17] - Quantized from {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float32', 'model.model.layers.0.self_attn.k_norm.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float32', 'model.model.layers.1.self_attn.k_norm.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float32', 'model.model.layers.2.self_attn.k_norm.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float32', 'model.model.layers.3.self_attn.k_norm.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float32', 'model.model.layers.4.self_attn.k_norm.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float32', 'model.model.layers.5.self_attn.k_norm.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float32', 'model.model.layers.6.self_attn.k_norm.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float32', 'model.model.layers.7.self_attn.k_norm.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float32', 'model.model.layers.8.self_attn.k_norm.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float32', 'model.model.layers.9.self_attn.k_norm.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float32', 'model.model.layers.10.self_attn.k_norm.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float32', 'model.model.layers.11.self_attn.k_norm.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float32', 'model.model.layers.12.self_attn.k_norm.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float32', 'model.model.layers.13.self_attn.k_norm.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float32', 'model.model.layers.14.self_attn.k_norm.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float32', 'model.model.layers.15.self_attn.k_norm.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'} to float16
2025-05-13 18:19:59,498 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Running dequantization...
2025-05-13 18:19:59,499 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Running dequantization on 179 variables
2025-05-13 18:19:59,499 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.embed_tokens.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,500 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.0.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,500 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.0.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,500 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.0.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,501 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.0.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,501 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.0.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,501 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.0.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,502 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.0.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,502 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.0.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,502 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.0.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,502 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.0.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,503 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.0.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,503 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.1.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,503 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.1.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,504 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.1.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,504 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.1.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,504 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.1.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,505 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.1.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,505 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.1.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,505 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.1.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,505 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.1.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,506 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.1.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,506 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.1.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,506 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.2.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,507 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.2.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,507 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.2.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,507 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.2.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,508 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.2.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,508 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.2.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,508 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.2.mlp.gate_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,508 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.2.mlp.up_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,509 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.2.mlp.down_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,509 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.2.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,509 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.2.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,510 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.3.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,510 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.3.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,510 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.3.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,510 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.3.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,511 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.3.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,511 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.3.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,616 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.3.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,617 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.3.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,617 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.4.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,618 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.4.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,627 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.4.self_attn.o_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,627 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.4.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,628 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.4.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,734 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.4.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,735 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.4.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,744 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.5.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,762 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.5.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,762 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.5.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,899 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.5.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,900 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.5.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,909 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.6.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,927 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.6.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:19:59,927 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.6.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,064 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.6.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,065 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.6.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,106 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.7.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,107 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.7.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,242 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.7.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,243 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.7.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,283 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.8.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,284 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.8.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,419 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.8.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,420 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.8.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,420 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.9.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,450 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.9.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,450 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.9.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,587 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.9.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,588 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.9.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,630 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.10.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,630 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.10.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,768 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.10.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,768 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.10.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,810 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.11.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,810 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.11.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,946 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.11.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,947 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.11.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,988 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.12.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:00,988 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.12.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,124 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.12.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,125 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.12.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,146 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.13.self_attn.v_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,158 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.13.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,158 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.13.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,293 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.13.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,294 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.13.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,335 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.14.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,336 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.14.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,471 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.14.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,472 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.14.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,513 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.15.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,513 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.15.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,649 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.15.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,650 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.layers.15.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:01,650 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Skipping dequantization for model.model.norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:20:02,203 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Dequantized 81/179 params. Before dequantization: 1968.00 MB with meta: 0.00 MB. After dequantization: 3936.00 MB.
2025-05-13 18:20:02,204 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Dequantized back to {'model.model.embed_tokens.weight': 'float16', 'model.model.layers.0.self_attn.q_proj.weight': 'float16', 'model.model.layers.0.self_attn.k_proj.weight': 'float16', 'model.model.layers.0.self_attn.v_proj.weight': 'float16', 'model.model.layers.0.self_attn.o_proj.weight': 'float16', 'model.model.layers.0.self_attn.q_norm.weight': 'float16', 'model.model.layers.0.self_attn.k_norm.weight': 'float16', 'model.model.layers.0.mlp.gate_proj.weight': 'float16', 'model.model.layers.0.mlp.up_proj.weight': 'float16', 'model.model.layers.0.mlp.down_proj.weight': 'float16', 'model.model.layers.0.post_attention_layernorm.weight': 'float16', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.1.self_attn.q_proj.weight': 'float16', 'model.model.layers.1.self_attn.k_proj.weight': 'float16', 'model.model.layers.1.self_attn.v_proj.weight': 'float16', 'model.model.layers.1.self_attn.o_proj.weight': 'float16', 'model.model.layers.1.self_attn.q_norm.weight': 'float16', 'model.model.layers.1.self_attn.k_norm.weight': 'float16', 'model.model.layers.1.mlp.gate_proj.weight': 'float16', 'model.model.layers.1.mlp.up_proj.weight': 'float16', 'model.model.layers.1.mlp.down_proj.weight': 'float16', 'model.model.layers.1.post_attention_layernorm.weight': 'float16', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.2.self_attn.q_proj.weight': 'float16', 'model.model.layers.2.self_attn.k_proj.weight': 'float16', 'model.model.layers.2.self_attn.v_proj.weight': 'float16', 'model.model.layers.2.self_attn.o_proj.weight': 'float16', 'model.model.layers.2.self_attn.q_norm.weight': 'float16', 'model.model.layers.2.self_attn.k_norm.weight': 'float16', 'model.model.layers.2.mlp.gate_proj.weight': 'float16', 'model.model.layers.2.mlp.up_proj.weight': 'float16', 'model.model.layers.2.mlp.down_proj.weight': 'float16', 'model.model.layers.2.post_attention_layernorm.weight': 'float16', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.3.self_attn.q_proj.weight': 'float16', 'model.model.layers.3.self_attn.k_proj.weight': 'float16', 'model.model.layers.3.self_attn.v_proj.weight': 'float16', 'model.model.layers.3.self_attn.o_proj.weight': 'float16', 'model.model.layers.3.self_attn.q_norm.weight': 'float16', 'model.model.layers.3.self_attn.k_norm.weight': 'float16', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float16', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.4.self_attn.q_proj.weight': 'float16', 'model.model.layers.4.self_attn.k_proj.weight': 'float16', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float16', 'model.model.layers.4.self_attn.q_norm.weight': 'float16', 'model.model.layers.4.self_attn.k_norm.weight': 'float16', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float16', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float16', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float16', 'model.model.layers.5.self_attn.k_norm.weight': 'float16', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float16', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float16', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float16', 'model.model.layers.6.self_attn.k_norm.weight': 'float16', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float16', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float16', 'model.model.layers.7.self_attn.k_norm.weight': 'float16', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float16', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float16', 'model.model.layers.8.self_attn.k_norm.weight': 'float16', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float16', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.9.self_attn.q_proj.weight': 'float16', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float16', 'model.model.layers.9.self_attn.k_norm.weight': 'float16', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float16', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float16', 'model.model.layers.10.self_attn.k_norm.weight': 'float16', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float16', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float16', 'model.model.layers.11.self_attn.k_norm.weight': 'float16', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float16', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float16', 'model.model.layers.12.self_attn.k_norm.weight': 'float16', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float16', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float16', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float16', 'model.model.layers.13.self_attn.k_norm.weight': 'float16', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float16', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float16', 'model.model.layers.14.self_attn.k_norm.weight': 'float16', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float16', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float16', 'model.model.layers.15.self_attn.k_norm.weight': 'float16', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float16', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float16', 'model.model.norm.weight': 'float16', 'model.lm_head.weight': 'float32'}
2025-05-13 18:20:02,205 - PTInProcessClientAPIExecutor - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - execute for task (train)
2025-05-13 18:20:02,207 - PTInProcessClientAPIExecutor - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - send data to peer
2025-05-13 18:20:02,208 - PTInProcessClientAPIExecutor - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - sending payload to peer
2025-05-13 18:20:02,208 - PTInProcessClientAPIExecutor - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Waiting for result from peer
2025-05-13 18:20:02,554 - TaskScriptRunner - INFO - current_round=1
2025-05-13 18:20:29,622 - TaskScriptRunner - INFO - {'eval_loss': 1.7901445627212524, 'eval_model_preparation_time': 0.0025, 'eval_runtime': 25.9265, 'eval_samples_per_second': 200.567, 'eval_steps_per_second': 25.071, 'epoch': 0.9999519253882025}
2025-05-13 18:20:29,623 - TaskScriptRunner - INFO - Evaluation metric score: {'eval_loss': 1.7901445627212524, 'eval_model_preparation_time': 0.0025, 'eval_runtime': 25.9265, 'eval_samples_per_second': 200.567, 'eval_steps_per_second': 25.071, 'epoch': 0.9999519253882025}
2025-05-13 18:20:38,313 - TaskScriptRunner - INFO - Increment num_train_epochs to 2
2025-05-13 18:21:38,569 - TaskScriptRunner - INFO - {'loss': 1.3787, 'grad_norm': 1.3125, 'learning_rate': 0.0005, 'epoch': 1.0499975962694101}
2025-05-13 18:22:30,048 - TaskScriptRunner - INFO - {'loss': 1.5033, 'grad_norm': 1.2265625, 'learning_rate': 0.0005, 'epoch': 1.0999951925388203}
2025-05-13 18:23:21,444 - TaskScriptRunner - INFO - {'loss': 1.5607, 'grad_norm': 1.21875, 'learning_rate': 0.0005, 'epoch': 1.1499927888082304}
2025-05-13 18:24:12,705 - TaskScriptRunner - INFO - {'loss': 1.5911, 'grad_norm': 1.171875, 'learning_rate': 0.0005, 'epoch': 1.1999903850776406}
2025-05-13 18:25:04,147 - TaskScriptRunner - INFO - {'loss': 1.6339, 'grad_norm': 1.1484375, 'learning_rate': 0.0005, 'epoch': 1.2499879813470507}
2025-05-13 18:25:55,442 - TaskScriptRunner - INFO - {'loss': 1.6877, 'grad_norm': 1.1640625, 'learning_rate': 0.0005, 'epoch': 1.2999855776164608}
2025-05-13 18:26:46,604 - TaskScriptRunner - INFO - {'loss': 1.6846, 'grad_norm': 1.28125, 'learning_rate': 0.0005, 'epoch': 1.349983173885871}
2025-05-13 18:27:38,676 - TaskScriptRunner - INFO - {'loss': 1.6835, 'grad_norm': 1.1484375, 'learning_rate': 0.0005, 'epoch': 1.399980770155281}
2025-05-13 18:28:30,622 - TaskScriptRunner - INFO - {'loss': 1.72, 'grad_norm': 1.2890625, 'learning_rate': 0.0005, 'epoch': 1.4499783664246912}
2025-05-13 18:29:22,325 - TaskScriptRunner - INFO - {'loss': 1.72, 'grad_norm': 1.125, 'learning_rate': 0.0005, 'epoch': 1.4999759626941014}
2025-05-13 18:30:13,345 - TaskScriptRunner - INFO - {'loss': 1.7027, 'grad_norm': 1.0703125, 'learning_rate': 0.0005, 'epoch': 1.5499735589635115}
2025-05-13 18:31:04,584 - TaskScriptRunner - INFO - {'loss': 1.7336, 'grad_norm': 1.2109375, 'learning_rate': 0.0005, 'epoch': 1.5999711552329217}
2025-05-13 18:31:55,920 - TaskScriptRunner - INFO - {'loss': 1.724, 'grad_norm': 1.1484375, 'learning_rate': 0.0005, 'epoch': 1.6499687515023316}
2025-05-13 18:32:47,135 - TaskScriptRunner - INFO - {'loss': 1.7253, 'grad_norm': 1.1171875, 'learning_rate': 0.0005, 'epoch': 1.6999663477717417}
2025-05-13 18:33:38,918 - TaskScriptRunner - INFO - {'loss': 1.7427, 'grad_norm': 1.109375, 'learning_rate': 0.0005, 'epoch': 1.7499639440411519}
2025-05-13 18:34:30,509 - TaskScriptRunner - INFO - {'loss': 1.7456, 'grad_norm': 1.015625, 'learning_rate': 0.0005, 'epoch': 1.799961540310562}
2025-05-13 18:35:21,885 - TaskScriptRunner - INFO - {'loss': 1.7328, 'grad_norm': 1.125, 'learning_rate': 0.0005, 'epoch': 1.8499591365799721}
2025-05-13 18:36:13,518 - TaskScriptRunner - INFO - {'loss': 1.7721, 'grad_norm': 1.09375, 'learning_rate': 0.0005, 'epoch': 1.8999567328493823}
2025-05-13 18:37:05,176 - TaskScriptRunner - INFO - {'loss': 1.7784, 'grad_norm': 1.0703125, 'learning_rate': 0.0005, 'epoch': 1.9499543291187924}
2025-05-13 18:37:56,810 - TaskScriptRunner - INFO - {'loss': 1.7531, 'grad_norm': 1.2265625, 'learning_rate': 0.0005, 'epoch': 1.9999519253882025}
2025-05-13 18:38:14,290 - TaskScriptRunner - INFO - {'train_runtime': 1046.9304, 'train_samples_per_second': 79.474, 'train_steps_per_second': 1.987, 'train_loss': 0.8393464271838849, 'epoch': 1.9999519253882025}
2025-05-13 18:38:16,141 - ModelQuantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Running quantization...
2025-05-13 18:38:16,142 - ModelQuantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Running quantization on 179 variables
2025-05-13 18:38:22,421 - ModelQuantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Quantized 179/179 params. Before quantization: 5664.51 MB. After quantization: 2832.25 MB with meta: 0.00 MB.
2025-05-13 18:38:22,422 - ModelQuantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=bdb3b4e2-6871-4c3d-89c5-967c7dcafb76] - Quantized from {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float32', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float32', 'model.model.layers.0.self_attn.k_norm.weight': 'float32', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float32', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.1.self_attn.q_proj.weight': 'float32', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float32', 'model.model.layers.1.self_attn.k_norm.weight': 'float32', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float32', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.2.self_attn.q_proj.weight': 'float32', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float32', 'model.model.layers.2.self_attn.k_norm.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float32', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float32', 'model.model.layers.3.self_attn.k_norm.weight': 'float32', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float32', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.4.self_attn.q_proj.weight': 'float32', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float32', 'model.model.layers.4.self_attn.k_norm.weight': 'float32', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float32', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.5.self_attn.q_proj.weight': 'float32', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float32', 'model.model.layers.5.self_attn.k_norm.weight': 'float32', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float32', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.6.self_attn.q_proj.weight': 'float32', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float32', 'model.model.layers.6.self_attn.k_norm.weight': 'float32', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float32', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float32', 'model.model.layers.7.self_attn.k_norm.weight': 'float32', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float32', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.8.self_attn.q_proj.weight': 'float32', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float32', 'model.model.layers.8.self_attn.k_norm.weight': 'float32', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float32', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.9.self_attn.q_proj.weight': 'float32', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float32', 'model.model.layers.9.self_attn.k_norm.weight': 'float32', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float32', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.10.self_attn.q_proj.weight': 'float32', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float32', 'model.model.layers.10.self_attn.k_norm.weight': 'float32', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float32', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.11.self_attn.q_proj.weight': 'float32', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float32', 'model.model.layers.11.self_attn.k_norm.weight': 'float32', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float32', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.12.self_attn.q_proj.weight': 'float32', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float32', 'model.model.layers.12.self_attn.k_norm.weight': 'float32', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float32', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.13.self_attn.q_proj.weight': 'float32', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float32', 'model.model.layers.13.self_attn.k_norm.weight': 'float32', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float32', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.14.self_attn.q_proj.weight': 'float32', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float32', 'model.model.layers.14.self_attn.k_norm.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float32', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float32', 'model.model.layers.15.self_attn.q_proj.weight': 'float32', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float32', 'model.model.layers.15.self_attn.k_norm.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float32', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float32', 'model.model.norm.weight': 'float32', 'model.lm_head.weight': 'float32'} to float16
2025-05-13 18:40:30,759 - Communicator - WARNING - Failed to get_task from server. Will try it again.
2025-05-13 18:40:34,409 - Cell - WARNING - Receiving unknown req_id='c50349a7-1a74-489f-a53a-698f2a1d99de', discarded: 'c50349a7-1a74-489f-a53a-698f2a1d99de' headers: {'cn__return_code': 'ok', 'cn__req_id': '', 'cn__msg_type': 'req', 'sm__ri': 'c50349a7-1a74-489f-a53a-698f2a1d99de', 'sm__pe': 'fobs', 'cn__payload_len': 476, 'sm__ch': 'return_only', 'sm__tp': 'server_command:get_task', 'sm__sz': 476, 'sm__id': 1747458710923950, 'sm__dt': 2, 'sm__sq': 0, 'sm__os': 0, 'sm__op': True, 'cn__reply_expected': False, 'cn__optional': True, 'cn__secure': False, 'cn__topic': 'sm__DATA', 'cn__channel': 'sm__STREAM', 'cn__destination': 'site-alpaca.simulate_job', 'cn__from': 'server', 'cn__to': 'site-alpaca.simulate_job', 'cn__origin': 'server.simulate_job', 'cn__route': [['server.simulate_job', 1747161634.4083421], ['server', 1747161634.408413], ('site-alpaca.simulate_job', 1747161634.40883)], 'cn__send_time': 1747161634.4084153}
2025-05-13 18:40:54,496 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Running dequantization...
2025-05-13 18:40:54,497 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Running dequantization on 179 variables
2025-05-13 18:40:55,056 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.0.self_attn.k_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,087 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.0.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,088 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.0.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,193 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.0.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,193 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.0.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,194 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.1.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,227 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.1.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,227 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.1.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,333 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.1.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,333 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.1.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,334 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.2.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,504 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.2.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,505 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.2.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,552 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.3.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,553 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.3.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,688 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.3.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,688 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.3.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,689 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.4.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,724 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.4.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,725 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.4.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,859 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.4.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,860 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.4.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,861 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.5.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,896 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.5.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:55,897 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.5.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,033 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.5.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,033 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.5.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,034 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.6.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,069 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.6.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,070 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.6.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,204 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.6.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,204 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.6.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,252 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.7.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,252 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.7.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,387 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.7.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,388 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.7.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,388 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.8.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,423 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.8.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,424 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.8.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,569 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.8.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,569 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.8.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,570 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.9.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,625 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.9.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,626 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.9.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,797 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.9.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,798 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.9.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,798 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.10.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,835 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.10.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,836 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.10.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,980 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.10.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,980 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.10.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:56,981 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.11.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,017 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.11.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,018 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.11.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,161 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.11.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,162 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.11.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,162 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.12.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,199 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.12.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,200 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.12.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,359 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.12.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,360 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.12.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,360 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.13.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,396 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.13.self_attn.q_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,396 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.13.self_attn.k_norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,532 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.13.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,532 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.13.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,533 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.14.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,703 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.14.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,704 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.14.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,704 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.15.self_attn.q_proj.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,873 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.15.post_attention_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,874 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.layers.15.post_feedforward_layernorm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:57,874 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Skipping dequantization for model.model.norm.weight, quantization bit float16 >= source data bit float16
2025-05-13 18:40:58,421 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Dequantized 106/179 params. Before dequantization: 2720.02 MB with meta: 0.00 MB. After dequantization: 5440.05 MB.
2025-05-13 18:40:58,422 - ModelDequantizer - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Dequantized back to {'model.model.embed_tokens.weight': 'float32', 'model.model.layers.0.self_attn.q_proj.weight': 'float32', 'model.model.layers.0.self_attn.k_proj.weight': 'float16', 'model.model.layers.0.self_attn.v_proj.weight': 'float32', 'model.model.layers.0.self_attn.o_proj.weight': 'float32', 'model.model.layers.0.self_attn.q_norm.weight': 'float16', 'model.model.layers.0.self_attn.k_norm.weight': 'float16', 'model.model.layers.0.mlp.gate_proj.weight': 'float32', 'model.model.layers.0.mlp.up_proj.weight': 'float32', 'model.model.layers.0.mlp.down_proj.weight': 'float32', 'model.model.layers.0.post_attention_layernorm.weight': 'float16', 'model.model.layers.0.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.1.self_attn.q_proj.weight': 'float16', 'model.model.layers.1.self_attn.k_proj.weight': 'float32', 'model.model.layers.1.self_attn.v_proj.weight': 'float32', 'model.model.layers.1.self_attn.o_proj.weight': 'float32', 'model.model.layers.1.self_attn.q_norm.weight': 'float16', 'model.model.layers.1.self_attn.k_norm.weight': 'float16', 'model.model.layers.1.mlp.gate_proj.weight': 'float32', 'model.model.layers.1.mlp.up_proj.weight': 'float32', 'model.model.layers.1.mlp.down_proj.weight': 'float32', 'model.model.layers.1.post_attention_layernorm.weight': 'float16', 'model.model.layers.1.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.2.self_attn.q_proj.weight': 'float16', 'model.model.layers.2.self_attn.k_proj.weight': 'float32', 'model.model.layers.2.self_attn.v_proj.weight': 'float32', 'model.model.layers.2.self_attn.o_proj.weight': 'float32', 'model.model.layers.2.self_attn.q_norm.weight': 'float32', 'model.model.layers.2.self_attn.k_norm.weight': 'float32', 'model.model.layers.2.mlp.gate_proj.weight': 'float32', 'model.model.layers.2.mlp.up_proj.weight': 'float32', 'model.model.layers.2.mlp.down_proj.weight': 'float32', 'model.model.layers.2.post_attention_layernorm.weight': 'float16', 'model.model.layers.2.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.3.self_attn.q_proj.weight': 'float32', 'model.model.layers.3.self_attn.k_proj.weight': 'float32', 'model.model.layers.3.self_attn.v_proj.weight': 'float32', 'model.model.layers.3.self_attn.o_proj.weight': 'float32', 'model.model.layers.3.self_attn.q_norm.weight': 'float16', 'model.model.layers.3.self_attn.k_norm.weight': 'float16', 'model.model.layers.3.mlp.gate_proj.weight': 'float32', 'model.model.layers.3.mlp.up_proj.weight': 'float32', 'model.model.layers.3.mlp.down_proj.weight': 'float32', 'model.model.layers.3.post_attention_layernorm.weight': 'float16', 'model.model.layers.3.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.4.self_attn.q_proj.weight': 'float16', 'model.model.layers.4.self_attn.k_proj.weight': 'float32', 'model.model.layers.4.self_attn.v_proj.weight': 'float32', 'model.model.layers.4.self_attn.o_proj.weight': 'float32', 'model.model.layers.4.self_attn.q_norm.weight': 'float16', 'model.model.layers.4.self_attn.k_norm.weight': 'float16', 'model.model.layers.4.mlp.gate_proj.weight': 'float32', 'model.model.layers.4.mlp.up_proj.weight': 'float32', 'model.model.layers.4.mlp.down_proj.weight': 'float32', 'model.model.layers.4.post_attention_layernorm.weight': 'float16', 'model.model.layers.4.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.5.self_attn.q_proj.weight': 'float16', 'model.model.layers.5.self_attn.k_proj.weight': 'float32', 'model.model.layers.5.self_attn.v_proj.weight': 'float32', 'model.model.layers.5.self_attn.o_proj.weight': 'float32', 'model.model.layers.5.self_attn.q_norm.weight': 'float16', 'model.model.layers.5.self_attn.k_norm.weight': 'float16', 'model.model.layers.5.mlp.gate_proj.weight': 'float32', 'model.model.layers.5.mlp.up_proj.weight': 'float32', 'model.model.layers.5.mlp.down_proj.weight': 'float32', 'model.model.layers.5.post_attention_layernorm.weight': 'float16', 'model.model.layers.5.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.6.self_attn.q_proj.weight': 'float16', 'model.model.layers.6.self_attn.k_proj.weight': 'float32', 'model.model.layers.6.self_attn.v_proj.weight': 'float32', 'model.model.layers.6.self_attn.o_proj.weight': 'float32', 'model.model.layers.6.self_attn.q_norm.weight': 'float16', 'model.model.layers.6.self_attn.k_norm.weight': 'float16', 'model.model.layers.6.mlp.gate_proj.weight': 'float32', 'model.model.layers.6.mlp.up_proj.weight': 'float32', 'model.model.layers.6.mlp.down_proj.weight': 'float32', 'model.model.layers.6.post_attention_layernorm.weight': 'float16', 'model.model.layers.6.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.7.self_attn.q_proj.weight': 'float32', 'model.model.layers.7.self_attn.k_proj.weight': 'float32', 'model.model.layers.7.self_attn.v_proj.weight': 'float32', 'model.model.layers.7.self_attn.o_proj.weight': 'float32', 'model.model.layers.7.self_attn.q_norm.weight': 'float16', 'model.model.layers.7.self_attn.k_norm.weight': 'float16', 'model.model.layers.7.mlp.gate_proj.weight': 'float32', 'model.model.layers.7.mlp.up_proj.weight': 'float32', 'model.model.layers.7.mlp.down_proj.weight': 'float32', 'model.model.layers.7.post_attention_layernorm.weight': 'float16', 'model.model.layers.7.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.8.self_attn.q_proj.weight': 'float16', 'model.model.layers.8.self_attn.k_proj.weight': 'float32', 'model.model.layers.8.self_attn.v_proj.weight': 'float32', 'model.model.layers.8.self_attn.o_proj.weight': 'float32', 'model.model.layers.8.self_attn.q_norm.weight': 'float16', 'model.model.layers.8.self_attn.k_norm.weight': 'float16', 'model.model.layers.8.mlp.gate_proj.weight': 'float32', 'model.model.layers.8.mlp.up_proj.weight': 'float32', 'model.model.layers.8.mlp.down_proj.weight': 'float32', 'model.model.layers.8.post_attention_layernorm.weight': 'float16', 'model.model.layers.8.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.9.self_attn.q_proj.weight': 'float16', 'model.model.layers.9.self_attn.k_proj.weight': 'float32', 'model.model.layers.9.self_attn.v_proj.weight': 'float32', 'model.model.layers.9.self_attn.o_proj.weight': 'float32', 'model.model.layers.9.self_attn.q_norm.weight': 'float16', 'model.model.layers.9.self_attn.k_norm.weight': 'float16', 'model.model.layers.9.mlp.gate_proj.weight': 'float32', 'model.model.layers.9.mlp.up_proj.weight': 'float32', 'model.model.layers.9.mlp.down_proj.weight': 'float32', 'model.model.layers.9.post_attention_layernorm.weight': 'float16', 'model.model.layers.9.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.10.self_attn.q_proj.weight': 'float16', 'model.model.layers.10.self_attn.k_proj.weight': 'float32', 'model.model.layers.10.self_attn.v_proj.weight': 'float32', 'model.model.layers.10.self_attn.o_proj.weight': 'float32', 'model.model.layers.10.self_attn.q_norm.weight': 'float16', 'model.model.layers.10.self_attn.k_norm.weight': 'float16', 'model.model.layers.10.mlp.gate_proj.weight': 'float32', 'model.model.layers.10.mlp.up_proj.weight': 'float32', 'model.model.layers.10.mlp.down_proj.weight': 'float32', 'model.model.layers.10.post_attention_layernorm.weight': 'float16', 'model.model.layers.10.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.11.self_attn.q_proj.weight': 'float16', 'model.model.layers.11.self_attn.k_proj.weight': 'float32', 'model.model.layers.11.self_attn.v_proj.weight': 'float32', 'model.model.layers.11.self_attn.o_proj.weight': 'float32', 'model.model.layers.11.self_attn.q_norm.weight': 'float16', 'model.model.layers.11.self_attn.k_norm.weight': 'float16', 'model.model.layers.11.mlp.gate_proj.weight': 'float32', 'model.model.layers.11.mlp.up_proj.weight': 'float32', 'model.model.layers.11.mlp.down_proj.weight': 'float32', 'model.model.layers.11.post_attention_layernorm.weight': 'float16', 'model.model.layers.11.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.12.self_attn.q_proj.weight': 'float16', 'model.model.layers.12.self_attn.k_proj.weight': 'float32', 'model.model.layers.12.self_attn.v_proj.weight': 'float32', 'model.model.layers.12.self_attn.o_proj.weight': 'float32', 'model.model.layers.12.self_attn.q_norm.weight': 'float16', 'model.model.layers.12.self_attn.k_norm.weight': 'float16', 'model.model.layers.12.mlp.gate_proj.weight': 'float32', 'model.model.layers.12.mlp.up_proj.weight': 'float32', 'model.model.layers.12.mlp.down_proj.weight': 'float32', 'model.model.layers.12.post_attention_layernorm.weight': 'float16', 'model.model.layers.12.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.13.self_attn.q_proj.weight': 'float16', 'model.model.layers.13.self_attn.k_proj.weight': 'float32', 'model.model.layers.13.self_attn.v_proj.weight': 'float32', 'model.model.layers.13.self_attn.o_proj.weight': 'float32', 'model.model.layers.13.self_attn.q_norm.weight': 'float16', 'model.model.layers.13.self_attn.k_norm.weight': 'float16', 'model.model.layers.13.mlp.gate_proj.weight': 'float32', 'model.model.layers.13.mlp.up_proj.weight': 'float32', 'model.model.layers.13.mlp.down_proj.weight': 'float32', 'model.model.layers.13.post_attention_layernorm.weight': 'float16', 'model.model.layers.13.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.14.self_attn.q_proj.weight': 'float16', 'model.model.layers.14.self_attn.k_proj.weight': 'float32', 'model.model.layers.14.self_attn.v_proj.weight': 'float32', 'model.model.layers.14.self_attn.o_proj.weight': 'float32', 'model.model.layers.14.self_attn.q_norm.weight': 'float32', 'model.model.layers.14.self_attn.k_norm.weight': 'float32', 'model.model.layers.14.mlp.gate_proj.weight': 'float32', 'model.model.layers.14.mlp.up_proj.weight': 'float32', 'model.model.layers.14.mlp.down_proj.weight': 'float32', 'model.model.layers.14.post_attention_layernorm.weight': 'float16', 'model.model.layers.14.post_feedforward_layernorm.weight': 'float16', 'model.model.layers.15.self_attn.q_proj.weight': 'float16', 'model.model.layers.15.self_attn.k_proj.weight': 'float32', 'model.model.layers.15.self_attn.v_proj.weight': 'float32', 'model.model.layers.15.self_attn.o_proj.weight': 'float32', 'model.model.layers.15.self_attn.q_norm.weight': 'float32', 'model.model.layers.15.self_attn.k_norm.weight': 'float32', 'model.model.layers.15.mlp.gate_proj.weight': 'float32', 'model.model.layers.15.mlp.up_proj.weight': 'float32', 'model.model.layers.15.mlp.down_proj.weight': 'float32', 'model.model.layers.15.post_attention_layernorm.weight': 'float16', 'model.model.layers.15.post_feedforward_layernorm.weight': 'float16', 'model.model.norm.weight': 'float16', 'model.lm_head.weight': 'float32'}
2025-05-13 18:40:58,423 - PTInProcessClientAPIExecutor - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - execute for task (train)
2025-05-13 18:40:58,425 - PTInProcessClientAPIExecutor - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - send data to peer
2025-05-13 18:40:58,425 - PTInProcessClientAPIExecutor - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - sending payload to peer
2025-05-13 18:40:58,426 - PTInProcessClientAPIExecutor - INFO - [identity=site-alpaca, run=simulate_job, peer=simulator_server, peer_run=simulate_job, task_name=train, task_id=9461cf67-c688-44dc-9ccd-022b266ad0ff] - Waiting for result from peer
2025-05-13 18:40:58,555 - TaskScriptRunner - INFO - current_round=2
2025-05-13 18:41:25,625 - TaskScriptRunner - INFO - {'eval_loss': 1.7836012840270996, 'eval_model_preparation_time': 0.0025, 'eval_runtime': 26.071, 'eval_samples_per_second': 199.455, 'eval_steps_per_second': 24.932, 'epoch': 1.9999519253882025}
2025-05-13 18:41:25,626 - TaskScriptRunner - INFO - Evaluation metric score: {'eval_loss': 1.7836012840270996, 'eval_model_preparation_time': 0.0025, 'eval_runtime': 26.071, 'eval_samples_per_second': 199.455, 'eval_steps_per_second': 24.932, 'epoch': 1.9999519253882025}
2025-05-13 18:41:34,924 - TaskScriptRunner - INFO - Increment num_train_epochs to 3
2025-05-13 18:42:35,662 - TaskScriptRunner - INFO - {'loss': 0.989, 'grad_norm': 1.0, 'learning_rate': 0.0005, 'epoch': 2.04999759626941}
2025-05-13 18:43:27,607 - TaskScriptRunner - INFO - {'loss': 1.0924, 'grad_norm': 0.953125, 'learning_rate': 0.0005, 'epoch': 2.0999951925388203}
